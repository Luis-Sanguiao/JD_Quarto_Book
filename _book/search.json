[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JDemetra+ documentation",
    "section": "",
    "text": "Preface\nWelcome to the JDemetra+ on-line documentation.\nJDemetra+ is an open-source software for seasonal adjustment and time series analysis, developed in the framework of Eurostat’s “Centre of Excellence on Statistical Methods and Tools” by the National Bank of Belgium with the support of the Bundesbank and Insee.\nTo learn more about this project you can visit Eurostat CROS Portal.\nTo keep up with all JDemetra+ related news head to the JDemetra+ Universe Blog\nThis website is under construction, in the meantime you can fill a large number of the gaps by referring to the previous version of the on-line documentation, coordinated by Sylwia Grudkowska-Kubik(National Bank of Poland).\nEurostat’s recommendations on the statistical processes described in this documentation are outlined in:\n\nEurostat’s Guidelines on seasonal adjustment (2015)\nEurostat’s Guidelines on temporal disaggregation, benchmarking and reconcilation (2018)\n\nKey methodological explanations and state-of-the-art description and references can be found in:\n\nHandbook on seasonal adjustment (2018)\nHandbook on rapid estimates (2017)"
  },
  {
    "objectID": "G-what-is-jd.html#introduction",
    "href": "G-what-is-jd.html#introduction",
    "title": "JDemetra+ Software",
    "section": "Introduction",
    "text": "Introduction\nJDemetra+ is an open source software for seasonal adjustment and time series analysis. It has been officially recommended by Eurostat to the European Statistical System members since 2015. It is unique in its combination of very fast Java routines, a graphical user interface and a family of R packages. The graphical interface offers a structured and visual feedback, suitable for refined analysis and training. R tools allow the user to mix the capabilities of JDemetra+ with the versatility of the R world, be it for mathematical functions or data wrangling.\nVersion 2.x and version 3\nVersion 3.0 to be released by the summer of 2023, fills several critical gaps in the tool box of a time series analyst providing extended features for seasonal adjustment and trend estimation, including high frequency data and production tools."
  },
  {
    "objectID": "G-what-is-jd.html#structure-of-this-book",
    "href": "G-what-is-jd.html#structure-of-this-book",
    "title": "JDemetra+ Software",
    "section": "Structure of this book",
    "text": "Structure of this book\nThis book is divided in 3 parts, allowing the user to access the resources from different perspectives.\n\nAlgorithms\nThis part provides a step by step guidance for using of all the algorithms featured in JDemetra+:\n\nSeasonal Adjustment\nSeasonal Adjustment of high-frequency data\nReg-Arima modelling\nOutlier detection\nGenerating Calendar regressors and input variables\nBenchmarking and temporal disaggregation\nTrend-Cycle estimation\nNowcasting\n\nOutput series, diagnostics, as well as parameters (automatically estimated or user-defined) are detailed in the relevant chapters.\n\n\nTools\nThis part describes the tools allowing to access JDemetra+ algorithms:\n\nGraphical User Interface GUI\n…enhanced with additional plug-ins\n..and a Cruncher for mass production\nR packages\n\n\n\nMethods\nThis part describes in greater detail the core algorithms and their underlying statistical methods:\n\nReg-Arima modelling\nX-11: moving average based decomposition\nSEATS: Arima model based decomposition\nSTL: Loess based decomposition\nBenchmarking and temporal disaggregation\nSpectral analysis tools\nTrend Estimation\nTests for seasonality and residuals\nStructural time series and state space framework"
  },
  {
    "objectID": "G-jd-history.html#in-this-chapter",
    "href": "G-jd-history.html#in-this-chapter",
    "title": "How JDemetra+ came to be",
    "section": "In this chapter",
    "text": "In this chapter\n\nhistory of the project, people who built the software\nevolution of the software\n\n\nTime line"
  },
  {
    "objectID": "P_Algorithms.html",
    "href": "P_Algorithms.html",
    "title": "Algorithms",
    "section": "",
    "text": "This part describes the algorithms featured in JDemetra+:\n\nSeasonal Adjustment\nSeasonal Adjustment of high-frequency data\nReg-Arima modelling\nOutlier detection\nGenerating Calendar regressors and input variables\nBenchmarking and temporal disaggregation\nTrend-Cycle estimation\nNowcasting"
  },
  {
    "objectID": "A-sa.html#overview",
    "href": "A-sa.html#overview",
    "title": "Seasonal Adjustment",
    "section": "Overview",
    "text": "Overview\nThe goal of seasonal adjustment is to remove seasonal fluctuations a time series. Seasonal fluctuations are quasi-periodic infra-annual movements. They can mask evolution of greater interest for the user such as short term evolutions or long time trends.\nThis chapter focuses on the practical step by step use of JDemetra+ algorithms, restricted to monthly and quarterly series. For intra-monthly data see the following chapter. The use of graphical user interface and R packages are described simultaneously whenever relevant.\nIn-depth methodological explanations of the algorithms are covered in separated chapters, in the Methods part.\nThis chapter is under construction, missing parts will be updated in the coming months.\nMore information on the steps and best practices of a seasonal adjustment process can be found in the Eurostat guidelines on seasonal adjustment\nFor an overview on the algorithms and methodological issues, please refer to the Handbook on Seasonal Adjustment\n\nIn this chapter\n\ncalendar correction steps\n\n\n\nSeasonal Adjustment Algorithms\n\nX13-Arima and Tramo-Seats are two-step algorithms with a pre-treatment phase (Reg-Arima or Tramo) and a decomposition phase (X11 and Seats). STL is a local regression (Loess) based decomposition, without pre-treatment. In a Structural Time Series approach pre-treatment and decomposition are done simultaneously in a State Space Framework (SSF).\n\n\nAlgorithm\nAccess in GUI\nAccess in R (v2)\nAccess in R v3\n\n\n\n\nX-13 Arima\nyes\nRJDemetra\nrjd3x13\n\n\nReg-Arima only\nyes\nRJDemetra\nrjd3x13\n\n\nX11 decomposition only\nyes\nRJDemetra\nrjd3x13\n\n\nTramo-Seats\nyes\nRJDemetra\nrjd3tramoseats\n\n\nTramo only\nyes\nRJDemetra\nrjd3tramoseats\n\n\nSeats only\n-\n-\n-\n\n\nSTL\nno\nno\nrjd3stl\n\n\nSTS\nno\nno\nrjd3sts\n\n\n\n\n\nDecomposition in unobserved components\nTo seasonally adjust a series, seasonal factors \\(S_{t}\\) will be estimated and removed from the original raw series: \\(Y_{sa}=Y_{t}/S_{t}\\) or \\(Y_{sa}=Y_{t}-S_{t}\\). To do so the series is first decomposed into unobservable components. Two decomposition models:\n\nThe additive model: \\(X_{t} = T_{t} + S_{t} + I_{t}\\);\nThe multiplicative model: \\(X_{t} = T_{t} \\times S_{t} \\times I_{t}\\).\n\nThe main components, each representing the impact of certain types of phenomena on the time series (\\(X_{t}\\)), are:\n\nThe trend (\\(T_{t}\\)) that captures long-term and medium-term behaviour;\nThe seasonal component (\\(S_{t}\\)) representing intra-year fluctuations, monthly or quarterly, that are repeated more or less regularly year after year;\nThe irregular component (\\(I_{t}\\)) combining all the other more or less erratic fluctuations not covered by the previous components.\n\nIn general, the trend consists of 2 sub-components:\n\nThe long-term evolution of the series;\nThe cycle, that represents the smooth, almost periodic movement around the long-term evolution of the series. It reveals a succession of phases of growth and recession. Trend and cycle are not separated in SA algorithms.\n\n\n\nPre-treatment principles\nThe goal of this step is to remove deterministic effects (calendar and outliers) in order to improve the decomposition. \\[\nY_t = \\sum {\\alpha}_i O_{it} + \\sum\\beta_j C_{jt} + \\sum {\\gamma}_i U_{it} + Y_{lin,t}\n\\]\n\n\\(O_{it}\\) are the \\(i\\) final outliers (AO, LS, TC)\n\\(C_{it}\\) are the calendar regressors (automatic or user-defined) (link to calendar chap)\n\\(U_{it}\\) are all the other user-defined regressors (link to outliers and regressors chap)\n\\(Y_{lin,t} \\sim ARIMA(p,d,q)(P,D,Q)\\)\n\n\n\nDetecting seasonal patterns\nA large number of seasonality tests are available in JDemetra+. They can be accessed in the graphical user interface or via R.\nIn rjd3toolkit package:\n\nCanova-Hansen (seasonality.canovahansen())\n\nIn rjd3toolkit package:\n\nX-12 combined test (seasonality.combined())\nF-test on seasonal dummies (seasonality.f())\nFriedman Seasonality Test (seasonality.friedman())\nKruskall-Wallis Seasonality Test (seasonality.kruskalwallis())\nPeriodogram Seasonality Test (seasonality.periodogram())\nQS Seasonality Test (seasonality.qs())"
  },
  {
    "objectID": "A-sa.html#pre-treatment-reg-arima-or-tramo",
    "href": "A-sa.html#pre-treatment-reg-arima-or-tramo",
    "title": "Seasonal Adjustment",
    "section": "Pre-treatment: Reg-Arima or Tramo",
    "text": "Pre-treatment: Reg-Arima or Tramo\nThe following sections cover how to perform pre-treatment with Reg-ARIMA (or Tramo) algorithms. Tramo and the Reg-Arima part of X13-Arima rely on very similar principles: Reg-Arima modelling. Thus Tramo will be mentioned only to highlight differences with the Reg-Arima part of X13-Arima. Reg-Arima modelling part can be of a seasonal adjustment process or run on its own, we focus first on launching pre-treatment as part of a SA processing.\n\nDefault Specifications\nDefault specifications are set for the whole SA procedure, pre-treatment and decomposition. They are slightly different for X13-ARIMA and Tramo-Seats and can be modified with user defined parameters.\n\nStarting point for X13-ARIMA\n\n\n\n\n\n\n\n\n\n\nSpec identifier\nLog/level detection\nOutliers detection\nCalendar effects\nARIMA\n\n\n\n\nRSA0\nNA\nNA\nNA\nAirline(+mean)\n\n\nRSA1\nautomatic\nAO/LS/TC\nNA\nAirline(+mean)\n\n\nRSA2c\nautomatic\nAO/LS/TC\n2 TD vars+Easter\nAirline(+mean)\n\n\nRSA3\nautomatic\nAO/LS/TC\nNA\nautomatic\n\n\nRSA4c\nautomatic\nAO/LS/TC\n2 TD vars+Easter\nautomatic\n\n\nRSA5\nautomatic\nAO/LS/TC\n7 TD vars+Easter\nautomatic\n\n\nX-11\nNA\nNA\nNA\nNA\n\n\n\nexplanations:\n\nNA: non applied, for example in RSA3 there is no calendar effect correction\nautomatic: test is performed\n\noutliers detection: AO/LS/TC type of outliers automatically detected under a critical T-Stat value (default value=4)\ncalendar:\n\n2 regressors: weekdays vs week-ends + LY\n7 regressors: each week day vs Sundays + LY\nalways tested\neaster tested (default length = 6 days in Tramo, 8 days in X13-Arima)\n\n\n\nStarting point for Tramo-Seats\n\n\n\n\n\n\n\n\n\n\nSpec identifier\nLog/level detection\nOutliers detection\nCalendar effects\nARIMA\n\n\n\n\nRSA0\nNA\nNA\nNA\nAirline(+mean)\n\n\nRSA1\nautomatic\nAO/LS/TC\nNA\nAirline(+mean)\n\n\nRSA2\nautomatic\nAO/LS/TC\n2 TD vars+Easter\nAirline(+mean)\n\n\nRSA3\nautomatic\nAO/LS/TC\nNA\nautomatic\n\n\nRSA5\nautomatic\nAO/LS/TC\n6 TD vars+Easter\nautomatic\n\n\nRSAfull\nautomatic\nAO/LS/TC\nautomatic\nautomatic\n\n\n\nPrinciple of user setting parameters: can be done from one of the default specifications or any specification in a “save” as” mode very similar in GUI and R, see below.\n\n\n\nSpans\n\nEstimation span\nSpecifies the span (data interval) of the time series to be used in the seasonal adjustment process. The user can restrict the span\nCommon settings\n\n\n\n\n\n\n\n\nOption\nDescription (expected format)\n\n\n\n\n\nAll\ndefault\n\n\n\nFrom\nfirst observation included (yyyy-mm-dd)\n\n\n\nTo\nlast observation included (yyyy-mm-dd)\n\n\n\nBetween\ninterval [from ; to] included (yyyy-mm-dd to yyyy-mm-dd)\n\n\n\nFirst\nnumber of obs from the beginning of the series included (dynamic) (integer)\n\n\n\nLast\nnumber of obs from the end of the series (dynamic)(integer)\n\n\n\nExcluding\nexcluding N first obs and P last obs from the computation,dynamic) (integer)\n\n\n\nPreliminary check\ncheck to exclude highly problematic series e.g. the series with a number of identical observations and/or missing values above pre-specified threshold values. (True/False)\n\n\n\n\nSetting series span in GUI\nUse the specification window for a given series and expand the nodes.\n\nSetting series span in R\nx13 in version 2\n\nlibrary(RJDemetra)\n# estimation interval: option with static dates\nuser_spec_1&lt;-x13_spec(spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \n                               \"RSA3\", \"RSA4c\", \"X11\"), \npreliminary.check = TRUE, \nestimate.from = \"2012-06-01\", \nestimate.to = \"2019-12-01\") \n\n# estimation interval: option with dynamic numbers of observations\n\n# \n# spec can be applied on different series and therefore exclude different dates\nuser_spec_2&lt;-x13_spec(spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"), \nestimate.first = 12) \n\n# eestimation on the last 120 obs\nuser_spec_3&lt;-x13_spec(spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"), \nestimate.last = 120)\n\n#excluding first 24 and last 36 observations\nuser_spec_4&lt;-x13_spec(spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"), \nestimate.exclFirst = 24, \nestimate.exclLast = 36)\n\n# Retrieve settings\n\nFor comprehensive details about x13_spec function see RJDemetra R help pages.\nTramo-Seats in version 2\n\n#excluding first 24 and last 36 observations\nuser_spec_1&lt;-tramoseats_spec( spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),  \nestimate.exclFirst = 24, \nestimate.exclLast = 36)\n\nFor comprehensive details about tramoseats_spec function see RJDemetra R help pages.\n\n\nSetting model span\nThe user can also specify the span (data interval) of the time series to be used for the estimation of the Reg-ARIMA model coefficients. It allows to impede a chosen part of the data from influencing the regression estimates. Setting works the same way as setting series (estimation) span described above.\nAdditional (vs series span setting) parameters are described below:\n\n\n\n\n\n\n\nTolerance\nConvergence tolerance for the non-linear estimation.\nThe absolute changes in the log-likelihood are compared to Tolerance to check the convergence of the estimation iterations.\nThe default setting is 0.0000001.\n\n\nTramo specific parameters\n\n\n\nExact ML\nWhen this option is marked, an exact maximum likelihood estimation is performed.\nAlternatively, the Unconditional Least Squares method is used.\nHowever, in the current version of JDemetra+ it is not recommended to change this parameter’s value\n\n\nUnit Root Limit\nLimit for the autoregressive roots. If the inverse of a real root of the autoregressive polynomial of the\nARIMA model is higher than this limit, the root is set equal to 1. The default parameter value is 0.96.\n\n\n\nSetting model span in GUI:\nUse the specification window\n\nSetting in R\nTramo example in version 2\n\n#excluding first 24 and last 36 observations\nuser_spec_1&lt;-tramoseats_spec( spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),  \nestimate.tol = 0.0000001, \nestimate.eml = FALSE, \nestimate.urfinal = 0.98)\n\n\n\n\nDecomposition Scheme\n\nParameters\nTransformation test: a test is performed to choose between an additive decomposition (no transformation) (link to reg A chap to detail this)\nSettings\nFunction\ntransform {function=}\nTransformation of data. 2 The user can choose between:\nNone – no transformation of the data;\nLog – takes logs of the data;\nAuto – the program tests for the log-level specification. This option is recommended for automatic modelling of many series.\nThe default setting is Auto.\nReg-Arima specific settings\nAIC difference\ntransform {aicdiff=}\nDefines the difference in AICC needed to accept no transformation over a log transformation when the automatic transformation\nselection option is invoked. The option is disabled when Function is not set to Auto. The default AIC difference value is -2.\nAdjust\ntransform {adjust=}\nOptions for proportional adjustment for the leap year effect. The option is available when Function is set to Log. Adjust can be set to:\nLeapYear – performs a leap year adjustment of monthly or quarterly data;\nLengthofPeriod – performs a length-of-month adjustment on monthly data or length-of-quarter adjustment on quarterly data;\nNone – does not include a correction for the length of the period.\nThe default setting is None\nTramo specific settings\nFct\nTransformation; fct\nControls the bias in the log/level pre-test (the function is active when Function is set to Auto); Fct &gt; 1 favours levels, Fct &lt; 1 favors logs. The default setting is 0.95.\nSet in GUI\n\n\n\nModel span setting\n\n\nSet and in R\nX13\n\n#excluding first 24 and last 36 observations\nuser_spec &lt;-x13_spec(spec = c(\"RSA5c\", \"RSA0\", \"RSA1\", \"RSA2c\", \"RSA3\", \"RSA4c\", \"X11\"), \ntransform.function =\"Log\", # choose from: c(NA, \"Auto\", \"None\", \"Log\"),\ntransform.adjust = \"LeapYear\", #c(NA, \"None\", \"LeapYear\", \"LengthOfPeriod\"),\ntransform.aicdiff = -3)\n#Retrieve settings: to complete*\n\nTramo-Seats settings\n\n#transfo\nuser_spec_1&lt;-tramoseats_spec( spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),  \ntransform.function = \"Auto\", #c(NA, \"Auto\", \"None\", \"Log\"), \ntransform.fct = 0.5)\n# Retrieve settings: to complete \n\n\n\n\nCalendar correction\nSome calendar correction options included in the starting specifications for X13-Arima or Tramo-Seats, they can be fine-tuned and user-defined by modifying specifications. The following section lists all the available options, illustrates how to set them in GUI or R and shows have to retrieve used parameters, regressors as well as results.\nJDemetra+ offers two default options for calendar correction working days regressors and trading days regressors, with Leap-year effect if needed. Those options don’t take into account national calendars (link) and their specific holidays. There are two ways to change this:\n\nuser-defined regressors (link)\ncustomized calendars (link)\n\nOverview: what you can do\nNeed 1: correct for working days, trading days (+ easter) not taking national calendars\nNeed 2: taking national calendar into account Solutions\n\nadd a work of means of allocating regressors to the calendar component\n\n\nAvailable Options\n\nTrading Days\n“Trading Days” has two meanings: general calendar correction process (here without easter effect) and one of the options of this correction (see below)\n-    \"None\": no correction for trading days and working days effects\n\n-    \"Default\": JDemetra + built regressors (xorking days or trading days)\n\n-    \"Holidays\": same as above but taking into accoutn a national calendar,                  available on ly in GUI, R interface requires direct use of pre-built                   regressors \n\n-     \"UserDefined\": user-defined trading days regressors (see below)\n\n-    (if NONE) indicating the day of the month when inventories and other stock are reported (to denote the last day of the month, set the variable to 31). \n\n\nLeap Year effect\nAutoadjust\nIf enabled, the program corrects automatically for the leap year effect. when is the option available Modifications of this variable are taken into account only when transform.function is set to “Auto”.\nLeapyear\nto specify whether or not to include the leap-year effect in the model: - “LeapYear”: leap year effect; - “LengthOfPeriod”: length of period, - “None” = no effect included.\nThe leap-year effect can be pre-specified in the model only if the input series hasn’t been pre-adjusted (transform.adjust set to “None”) and if the automatic correction for the leap-year effect isn’t selected (tradingdays.autoadjust set to FALSE).\n\n\n\nTest\nTest: defines the pre-tests for the significance of the trading day regression variables based on the AICC statistics: “Add” = the trading day variables are not included in the initial regression model but can be added to the RegARIMA model after the test; “Remove” = the trading day variables belong to the initial regression model but can be removed from the RegARIMA model after the test; “None” = the trading day variables are not pre-tested and are included in the model.\n\nEaster\nEaster.enabled a logical. If TRUE, the program considers the Easter effect in the model.\neaster.Julian a logical. If TRUE, the program uses the Julian Easter (expressed in Gregorian calendar).\neaster.duration a numeric indicating the duration of the Easter effect (length in days, between 1 and 20).\neaster.test defines the pre-tests for the significance of the Easter effect based on the t-statistic (the Easter effect is considered as significant if the t-statistic is greater than 1.96): “Add” = the Easter effect variable is not included in the initial regression model but can be added to the RegARIMA model after the test; “Remove” = the Easter effect variable belongs to the initial regression model but can be removed from the RegARIMA model after the test; “None” = the Easter effect variable is not pre-tested and is included in the model.\nA user-defined regressor can also be used, see chapter on calendar correction\n(to be added: additional options in Tramo)\n\n\n\nSetting Calendar correction in GUI\n\nUsing default options (without national calendars)\nIn GUI Use the specification window\nCalendar effects\nSTEP 1: Selection from JDemetra+ Default…or User_defined\n\nSA_REGA_calendar_options.png\nSTEP2: Calendar effects minus Easter are labeled trading days\n\n\n\nHolidays option\nusing a customized calendar just show how to fetch it building process in calendar chapter\n\nMissing: stock td option, length-of-period\nUser-defined regressors: adding see below\nLink to Import data Once data imported: here explain how to link variables\n\n\nEaster\n\n\n\n\nSetting Calendar correction in R\nIn version 2\n\n# Parameter choice NA=...\n  tradingdays.option = c(NA, \"TradingDays\", \"WorkingDays\", \"UserDefined\", \"None\"),\n  tradingdays.autoadjust = NA,\n  tradingdays.leapyear = c(NA, \"LeapYear\", \"LengthOfPeriod\", \"None\"),\n  tradingdays.stocktd = NA_integer_,\n  tradingdays.test = c(NA, \"Remove\", \"Add\", \"None\"),\n  easter.enabled = NA,\n  easter.julian = NA,\n  easter.duration = NA_integer_,\n  easter.test = c(NA, \"Add\", \"Remove\", \"None\"),\n# example \n\nIn version 3 (Under construction)\n\n\nUser defined regressors\nIf User Defined options is used for trading days, regressors have to be provided by the user.\nBuilding Regressors The underlying methodology and implementation in JDemetra+ to build these regression variables are provided here\n\nAdding Regressors in GUI\nStep 1: import data set containing the regressors, general procedure explained here\nStep 2: Link the regressors to the workspace, procedure detailed here\nStep 3: Modify specifications Modifications are done the same way in a global specification (whole SAP) or series by series.\n\nselect trading days User-defined option and select variables\n\nIn the specification window, click right from “userVariables” on “Unused” to open the variable selection window\n\nMove right the chosen regressors\n\n\nset TEST option (expl)\n\n\n\n\nAdding Regressors in R\n“UserDefined” = user-defined trading days regressors (regressors must be defined by the usrdef.var argument with usrdef.varType set to “Calendar” and usrdef.varEnabled = TRUE).\n\n# example \nspec_4 &lt;- x13_spec(spec = spec_1, \n                   tradingdays.option = \"UserDefined\", \n                   tradingdays.test = \"None\", \n                   usrdef.varEnabled = TRUE, \n                   usrdef.varType = \"Calendar\", \n                   usrdef.var = reg3) # set of regressors in TS format\n\n\n\n\nRetrieving Results\nThe following section details how to retrieve results (parameters, regressors, regression coefficients and tests) when using GUI or R interface.\n\nParameters\nParameters are regressors used in fine. If non test options, parameters are known If test options are selected by the algorithm.\nIn GUI\nAutomatically chosen or user-defined calendar options (as well as other pre-adjustment options) are displayed at the top of the MAIN Results NODE displayed by clicking on a given series name in the SAProcessing panel.\n\nIn R\n(to be added)\nversion 2: RJDemetra\nversion 3: rjd3x13 or rjd3tramoseats\n\n\nRegressors\nIn GUI All regressors in the pre-adjustment phase (calendar, outliers, external) are displayed in the pre-processing-regressors node.\n\nIn R\n(to be added)\nVersion 2\nversion 3\n\n\nRegression results\nRegressions results\nIn GUI\nThe results of the whole Reg-Arima regression (link to last section) including calendar effects (below) are displayed in the pre-processing panel.\n\nIn R\n\n\nTest for residual trading-days effects\nResidual calendar effects are tested with A F-Test 7 regressors and no national calendar, on sa final series and on irregular component (link to calendar chapter for test details)\nIn GUI\nF-Test results are displayed at the bottom of Main Results NODE in the SAProcessing panel\n\nIn R\n\n\n\nCustomizing Calendars\nThe following describes how to take a national calendar into account.\nSolution 1: if working with GUI build a new calendar in GUI (here\n(to be added: GUI: how to use it or customize HTML file structure explanation)\nset this option in GUI\n(to be added: image: spec window calendar / holidays / choice of calendars)\nset this option in R (to be added) version 2:\nversion 3:\nsolution 2: import external regressors, which can be built with rjd3toolkit (link) which can then be used in via are or imported via GUI\nset this option in GUI how to import variables into JD+ / set utility (in interface chapter) classical user defined\nset this option in R version 2:\nversion 3\nOnce the calendar regressors are set, the RegArima (tramo) model will be estimated globally with all the other regression variables and taking into account Arima model specificities as well. That is why diagnostics are all jointly displayed at the end of the process. (link)\n(to be added: worked example: french calendar in R)\n\n\n\nOutliers\n(to be added) overview: why use outliers and what happens ? Effects reallocation\nMore in depth method outline will be available in outliers chapter what will be available\n\nAvailable outliers\n(this part might be migrated to outlier chapter, leaving just the last settings in SA process) The following outliers are available for automatic detection\n\n\n\n\nOptions for automatic detection\n*Is enabled** outliers; iatip\n  Enables/disables the automatic detection of outliers in the span determined by the **Detection span** option. By default, the checkbox is marked, which implies that the automatic identification of outliers is enabled.\n\nUse default critical value outliers; va\nThe critical value is automatically determined by the number of observations in the interval specified by the Detection span option. When Use default critical value is disabled, the procedure uses the critical value inputted in the Critical value item (see below). Otherwise, the default value is used (the first case corresponds to “critical = xxx”; the second corresponds to a specification without the critical argument). It should be noted that it is not possible to define a separate critical value for each outlier type. By default, the checkbox is marked, which implies that the automatic determination of the critical value is enabled.\n\nCritical value outliers; va\nThe critical value used in the outlier detection procedure. The option is active once Use default critical value is disabled. By default, it is set to 3.5.\nDetection span $$ type outliers; int1, int2*\nA span of the time series to be searched for outliers. The possible values of the parameter are:\n\nAll – full time series span is considered in the modelling;\nFrom – date of the first time series observation included in the pre-processing model;\nTo – date of the last time series observation included in the pre-processing model;\nBetween – date of the first and the last time series observations included in the pre-processing model;\nLast – number of observations from the end of the time series included in the pre-processing model;\nFirst – number of observations from the beginning of the time series included in the pre-processing model;\nExcluding – number of observations excluded from the beginning (specified in the first field) and/or end of the time series (specified in the last field) of the pre-processing model.\n\nWith the options Last, First, Excluding the span can be computed dynamically on the series. The default setting is All.\nAdditive outliers; aio*\nAutomatic identification of additive outliers. By default, this option is enabled.\n\nLevel shift outliers; aio*\nAutomatic identification of level shifts. By default, this option is enabled.\nTransitory change outliers; aio*\nAutomatic identification of transitory changes. By default, this option is enabled.\nSeasonal outlier outliers; aio*\nAutomatic identification of seasonal outliers. By default, this option is disabled. Tramo specific\nEML estimation outliers; imvx\nThe estimation method used in the automatic model identification procedure. By default, the fast method of Hannan-Rissanen is used for parameter estimation in the intermediate steps of the automatic detection and correction of outliers. When the checkbox is marked the exact maximum likelihood estimation method is used.\nTC rateoutliers; deltatc\nThe rate of decay for the transitory change outlier. It takes values between 0 and 1. The default value is 0.7.\n\n\n\nOptions for pre-specified outliers\nUser-defined outliers are used when prior knowledge suggests that certain effects exist at known time points[^14]. Four pre-defined outlier types, which are simple forms of intervention variables, are implemented: * Additive Outlier (AO); * Level shift (LS); * Temporary change[^15] (TC); * Seasonal outliers (SO).\n\n\nSetting in GUI\nAutomatic detection\n\n\nPre-specified\n\n\n\nSetting in R\n(to be added)\n\n\nRetrieving results\n\nParameters\nIn GUI\nIn main results NODE (same info at top of pre-processing NODE)\n\n\n\nRegressors\nIn GUI\n\nIn R\n(to be added)\n\n\nRegression details\nIn GUI\n\nIn R\n(to be added)\n\n\n\n\nUser-defined regressors\n(to be added)\n\nrationale\nparameters: assign to a component\n\nPre-treatment regression with additional outliers\n\\[\nY_t = \\sum \\hat{\\alpha}_i O_{it} + \\sum\\hat\\beta_j C_{jt} + \\sum\\hat\\gamma_k Reg_{kt} + y_{lin_t}\n\\]\n\nAllocation to components\n\\(reg= reg_{i}+reg_{t}+reg_{s}+...\\) The user-defined regression variable associated to a specific component should not contain effects that have to be associated with another component. Therefore, the following rules should be observed: * The variable assigned to the trend or to the seasonally adjusted series should not contain a seasonal pattern; * The variable assigned to the seasonal should not contain a trend (or level); * The variable assigned to the irregular should contain neither a seasonal pattern nor a trend (or level). - no external regressors can be assigned to calendar component. It has to be be done via user defined calendar regressors specific part (link)\nRamps and intervention variables are Specific cases of external regressors\n\n\nSetting in GUI\nUser-defined variables\nStep 1: import data set containing the regressors, general procedure explained here\nStep 2: Link the regressors to the workspace, procedure detailed here\nStep 3: Modify specifications via window\nModifications are done the same way in a global specification (whole SAP) or series by series.\n\n\n\nSetting in R\n(to be added)\n\n\nSpecial case 1: Ramp effects\nA ramp effect means a linear increase or decrease in the level of the series over a specified time interval \\(t_{0}\\) to \\(\\ t_{1}\\). All dates of the ramps must occur within the time series span. (tested: not true). Ramps can overlap other ramps, additive outliers and level shifts.\n\nCreation in GUI\n\n\n\nCreation in R\n(to be added)\n\n\nAllocation to components\nallocation when intervention or ramps ? in test allocated to trend ? (reg)\nimpossible (?) to create several intervention variables\n\n\n\nSpecial case 2: Intervention variables\nIntervention variables: Intervention variables are modeled as any possible sequence of ones and zeros, on which some operators may be applied. Intervention variables are built as combinations of the following basic structures[^16]: * Dummy variables[^17]; * Any possible sequence of ones and zeros; * \\(\\frac{1}{(1 - \\delta B)}\\), * \\((0 &lt; \\delta \\leq 1)\\); * \\(\\frac{1}{(1 - \\delta_{s}B^{s })}\\), * \\((0 &lt; \\delta_{s} \\leq 1)\\); * \\(\\frac{1}{(1 - B)(1 - B^{s})}\\); where \\(B\\) is backshift operator (i.e. \\(B^{k}X_{t} = X_{t - k}\\)) and \\(s\\) is frequency of the time series ($s = 12$for a monthly time series, $s = 4$for a quarterly time series).\nThese basic structures enable the generation of not only AO, LS, TC, SO and RP outliers but also sophisticated intervention variables that are well-adjusted to the particular case.\nRamp Effects:\nAs they are the most common external regressors, JDemetra+ offers functionalities to build them directly\n\nCreation in GUI\nstep 1 \nStep 2:\n\nstep 3: \n\n\nCreation in R\n(to be added)\n\n\nAllocation to components\nallocation (to be added)\nfixed coefficient options\n\nFixed regression coefficients regression variables; –\nFor the pre-specified regression variables this option specifies the parameter estimates that will be held fixed at the values provided by the user. To fix a coefficient the user should undertake the following actions:\n\nChoose the transformation (log or none).\nDefine some regression variables in the Regressors specification.\nPush on the fixed regression coefficients editor button in the User-defined variables row.\nSelect the regression variable from the list for which the coefficient will be fixed.\nSave the new setting with the Done button.\n\n\nOverview: differences GUI set up vs R set up\n\n\n\nRetrieving Results\nFor all types of external regressors: user-defined, ramps or intervention variables.\n\nRegressors\nIn GUI\nTo retrieve regressors that were actually used, expand pre-processing NODE and click on Regressors pane.\n\nIn R\n(to be added )\n\n\nRegression details\nIn GUI\nRegression details are in the pre-processing pane.\n\nIN R\n\n\n\n\nArima Model\nKey specifications on Arima modelling are embedded in default specifications: airline (default model) or full automatic research.(links)\nTwo kinds of interventions are available to the user\n\nmodify automatic detection parameters\nset a user defined Arima model\n\nIn both cases forecast horizon can also be set (link)\n\nOptions for modifying automatic detection\nautomdl.enabled If TRUE, the automatic modelling of the ARIMA model is enabled. (If FALSE, the parameters of the ARIMA model can be specified, see below)\nControl variables for the automatic modelling of the ARIMA model (when automdl.enabled is set to TRUE):\nautomdl.acceptdefault a logical. If TRUE, the default model (ARIMA(0,1,1)(0,1,1)) may be chosen in the first step of the automatic model identification. If the Ljung-Box Q statistics for the residuals is acceptable, the default model is accepted and no further attempt will be made to identify another model.\nautomdl.cancel the cancellation limit (numeric). If the difference in moduli of an AR and an MA roots (when estimating ARIMA(1,0,1)(1,0,1) models in the second step of the automatic identification of the differencing orders) is smaller than the cancellation limit, the two roots are assumed equal and cancel out.\nautomdl.ub1 the first unit root limit (numeric). It is the threshold value for the initial unit root test in the automatic differencing procedure. When one of the roots in the estimation of the ARIMA(2,0,0)(1,0,0) plus mean model, performed in the first step of the automatic model identification procedure, is larger than the first unit root limit in modulus, it is set equal to unity.\nautomdl.ub2 the second unit root limit (numeric). When one of the roots in the estimation of the ARIMA(1,0,1)(1,0,1) plus mean model, which is performed in the second step of the automatic model identification procedure, is larger than second unit root limit in modulus, it is checked if there is a common factor in the corresponding AR and MA polynomials of the ARMA model that can be cancelled (see automdl.cancel). If there is no cancellation, the AR root is set equal to unity (i.e. the differencing order changes).\nautomdl.mixed a logical. This variable controls whether ARIMA models with non-seasonal AR and MA terms or seasonal AR and MA terms will be considered in the automatic model identification procedure. If FALSE, a model with AR and MA terms in both the seasonal and non-seasonal parts of the model can be acceptable, provided there are no AR or MA terms in either the seasonal or non-seasonal terms.\nautomdl.balanced a logical. If TRUE, the automatic model identification procedure will have a preference for balanced models (i.e. models for which the order of the combined AR and differencing operator is equal to the order of the combined MA operator).\nautomdl.armalimit the ARMA limit (numeric). It is the threshold value for t-statistics of ARMA coefficients and constant term used for the final test of model parsimony. If the highest order ARMA coefficient has a t-value smaller than this value in magnitude, the order of the model is reduced. If the constant term t-value is smaller than the ARMA limit in magnitude, it is removed from the set of regressors.\nautomdl.reducecv numeric, ReduceCV. The percentage by which the outlier’s critical value will be reduced when an identified model is found to have a Ljung-Box statistic with an unacceptable confidence coefficient. The parameter should be between 0 and 1, and will only be active when automatic outlier identification is enabled. The reduced critical value will be set to (1-ReduceCV)*CV, where CV is the original critical value.\nautomdl.ljungboxlimit the Ljung Box limit (numeric). Acceptance criterion for the confidence intervals of the Ljung-Box Q statistic. If the LjungBox Q statistics for the residuals of a final model is greater than the Ljung Box limit, then the model is rejected, the outlier critical value is reduced and model and outlier identification (if specified) is redone with a reduced value.\nautomdl.ubfinal numeric, final unit root limit. The threshold value for the final unit root test. If the magnitude of an AR root for the final model is smaller than the final unit root limit, then a unit root is assumed, the order of the AR polynomial is reduced by one and the appropriate order of the differencing (non-seasonal, seasonal) is increased. The parameter value should be greater than one.\n(for both options) fcst.horizon the forecasting horizon (numeric). The forecast length generated by the Reg-Arima model in periods (positive values) or years (negative values). By default, the program generates a two-year forecast (fcst.horizon set to -2). Defaults different in GUI and R.\nSetting in GUI \nForecast horizon when using tramo seats Is set in the decomposition part of the specification in GUI.\n\nForecast horizon when using X13-ARIMA \nSetting in R (first template, then worked example) X13-Arima template in version 2\n\nspec_2 &lt;- x13_spec(spec = spec_1,\nautomdl.enabled = NA,\n  automdl.acceptdefault = NA,\n  automdl.cancel = NA_integer_,\n  automdl.ub1 = NA_integer_,\n  automdl.ub2 = NA_integer_,\n  automdl.mixed = NA,\n  automdl.balanced = NA,\n  automdl.armalimit = NA_integer_,\n  automdl.reducecv = NA_integer_,\n  automdl.ljungboxlimit = NA_integer_,\n  automdl.ubfinal = NA_integer_)\n\nadd worked example in version 2\nin version 3\nadd worked example in version 3\n\n\nOptions for setting a user-defined Arima model\nControl variables for the non-automatic modelling of the ARIMA model (when automdl.enabled is set to FALSE):\narima.mu logical. If TRUE, the mean is considered as part of the ARIMA model.\narima.p numeric. The order of the non-seasonal autoregressive (AR) polynomial.\narima.d numeric. The regular differencing order.\narima.q numeric. The order of the non-seasonal moving average (MA) polynomial.\narima.bp numeric. The order of the seasonal autoregressive (AR) polynomial.\narima.bd numeric. The seasonal differencing order.\narima.bq numeric. The order of the seasonal moving average (MA) polynomial.\nControl variables for the user-defined ARMA coefficients. Coefficients can be defined for the regular and seasonal autoregressive (AR) polynomials and moving average (MA) polynomials. The model considers the coefficients only if the procedure for their estimation (arima.coefType) is provided, and the number of provided coefficients matches the sum of (regular and seasonal) AR and MA orders (p,q,bp,bq).\narima.coefEnabled logical. If TRUE, the program uses the user-defined ARMA coefficients.\narima.coef a vector providing the coefficients for the regular and seasonal AR and MA polynomials. The vector length must be equal to the sum of the regular and seasonal AR and MA orders. The coefficients shall be provided in the following order: regular AR (Phi; p elements), regular MA (Theta; q elements), seasonal AR (BPhi; bp elements) and seasonal MA (BTheta; bq elements). E.g.: arima.coef=c(0.6,0.7) with arima.p=1, arima.q=0,arima.bp=1 and arima.bq=0.\narima.coefType a vector defining the ARMA coefficients estimation procedure. Possible procedures are: “Undefined” = no use of any user-defined input (i.e. coefficients are estimated), “Fixed” = the coefficients are fixed at the value provided by the user, “Initial” = the value defined by the user is used as the initial condition. For orders for which the coefficients shall not be defined, the arima.coef can be set to NA or 0, or the arima.coefType can be set to “Undefined”. E.g.: arima.coef = c(-0.8,-0.6,NA), arima.coefType = c(“Fixed”,“Fixed”,“Undefined”).\nSetting in GUI \nFixing coefficients \nSetting in R\nX13-Arima template in version 2\n\nspec_2 &lt;- x13_spec(spec = spec_1, \nautomdl.enabled = FALSE,\n\n  arima.mu = NA,\n  arima.p = NA_integer_,\n  arima.d = NA_integer_,\n  arima.q = NA_integer_,\n  arima.bp = NA_integer_,\n  arima.bd = NA_integer_,\n  arima.bq = NA_integer_,\n  arima.coefEnabled = NA,\n  arima.coef = NA,\n  arima.coefType = NA,\n  fcst.horizon = NA_integer_)\n\nin version 3\n\n\n\nReg-Arima model Results and Diagnostics\nType of results (including Tramo addenda)\n\nall regressors used (shown above)\nregression details: explanatory variables (above)\nArima model specific results\nadditional diagnostics on residuals\nlikelihood\nseasonality tests on residuals\n\n\nDisplay in GUI\nReg-Arima model detail with other regression results in pre-processing pane. with number of observations.. parameters \nMore details in Pre-processing/Arima Node\n\nIn residual Node\n\n\n\n\n\n\n Seasonality tests on residuals in the Diagnostics NODE\n(link to test chapter for tests details)\n\n\n\nRetrieve in R\n(to be added)"
  },
  {
    "objectID": "A-sa.html#x-11-decomposition",
    "href": "A-sa.html#x-11-decomposition",
    "title": "Seasonal Adjustment",
    "section": "X-11 Decomposition",
    "text": "X-11 Decomposition\nThis part explains how to use X-11 decomposition algorithm, via R as well as via GUI. The algorithm itself is explained in more details here\nIn a nutshell, X-11 will de decompose the linearized series using iteratively different moving averages. The effects of pre-treatment will be reallocated at the end.\nThe sections below (will) describe\n\nspecifications needed to run X-11\ngenerated output\nseries\ndiagnostics\nfinal parameters\nuser-defined parameters\n\n\nDefault specifications\nThe default specifications for X-11 must be chosen at the starting of the SA processing. They are detailed in the Reg-Arima part. X-11 can be run without pre-treatment\n\n\nQuick Launch\n\nFrom GUI\nWith a workspace open, an SAProcessing created and open data provider:\n\nchoose a default specification\ndrop your data and press green arrow\n\n\n\nIn R\nIn version 2\n\nlibrary(RJDemetra)\nmodel_sa&lt;-x13(raw_series, spec =\"RSA5c\")\n\nThe model_sa R object (list of lists) contains all parameters and results. It will be progressively detailed below.\n\n\n\nRetrieve series\n\nDisplay in GUI\nMain results \n(forecasts glued, values in italic)\nX-11 Tables\n\n\n\nText\n\n\nOutput series can be exported out of GUI by two means:\n\ngenerating output files\nrunning the cruncher to generate those files as described here\n\n\n\nRetrieve in R\nIn version 2\n\n# final components\nmodel_sa$final$series\n# final forecasts y_f sa_f s_f t_f i_f\nmodel_sa$final$forecasts\n# from user defined output \n\n\n\n\nRetrieve Diagnostics\nX11 produces the following type diagnostics or quality measures\n\nSI-ratios\n\nDisplay in GUI\nNODE Main Results &gt; SI-Ratios SA_MainResults_SI_ratios.png\n\n\n\nText\n\n\nIn GUI all values cannot be retrieved\n\n\nRetrieve in R\nIn version 2\n\n# data frame with values \nmodel_sa$decomposition$si_ratio\n# customizable plot\nplot(model_sa, type= \"cal-seas-irr\",first_date = c(2015, 1))\n\n\n\n\nM-statistics\nAt the end of the decomposition, X-11 algorithm provides quality measure of the decomposition called “M statistics”: 11 statistics (M1 to M11) and 2 summary indicators (Q et Q-M2). By design \\(0&lt;M_x&lt;3\\) and acceptance region is \\(M_x \\leq 1\\)\n\nM1 The relative contribution of the irregular over three months span\nM2 The relative contribution of the irregular component to the stationary portion of the variance\nM3 The amount of month to month change in the irregular component as compared to the amount of month to month change in the trend-cycle (I/C-ratio)\nM5 MCD (Months for Cyclical Dominance): The number of months it takes the change in the trend-cycle to surpass the amount of change in the irregular\nM6 The amount of year to year change in the irregular as compared to the amount of year to year change in the seasonal (only valid for 3x5 seasonal filter)\nM7 The amount of moving seasonality present relative to the amount of stable seasonality\nM8 The size of the fluctuations in the seasonal component throughout the whole series\nM9 The average linear movement in the seasonal component throughout the whole series\nM10 Same as 8, calculated for recent years only (4 years, N-2 to N-5)\nM11 Same as 9, calculated for recent years only\n\nThe \\(Q\\) statistic is a composite indicator calculated from the \\(M\\) statistics.\n\\[Q = \\frac{10M1 + 11M2 + 10M3 + 8M4 + 11M5 + 10M6 + 18M7 + 7M8 + 7M9 + 4M10 + 4M11}{100}\\]\n\\(Q = Q - M2\\) (also called \\(Q2\\)) is the \\(Q\\) statistic for which the \\(M2\\) statistics was excluded from the formula, i.e.:\n\\[Q - M2 = \\frac{10M1 + 10M3 + 8M4 + 11M5 + 10M6 + 18M7 + 7M8 + 7M9 + 4M10 + 4M11}{89}\\]\nIf a time series does not cover at least 6 years, the \\(M8\\), \\(M9\\), \\(M10\\) and \\(M11\\) statistics cannot be calculated. In this case the \\(Q\\) statistic is computed as:\n\\[Q = \\frac{14M1 + 15M2 + 10M3 + 8M4 + 11M5 + 10M6 + 32M7}{100}\\]\nThe model has a satisfactory quality if the \\(Q\\) statistic is lower than 1.\n\nDisplay in GUI\nTo display results in GUI, expand NODE\nDecomposition(X-11) &gt; Quality Measures &gt; Summary\nResults displayed in red indicate that the test failed.\n\n\n\nText\n\n\n\n\nRetrieve in R\nIn version 2\n\n# this code snippet is not self-sufficient \nmodel_sa$decomposition$mstats\n\n\n\n\nDetailed Quality measures\nIn GUI all the diagnostics below can be displayed expanding the NODE\nDecomposition(X-11) &gt; Quality Measures &gt; Details\nThey are detailed in the X-11 method chapter\nIn R (to be added)\n\n\n\nRetrieve final parameters\nThis section describes the parameters which are automatically chosen by the software as a result of the estimation process. They have no default value.\nFinal trend filter: length of Henderson filter applied for final estimation (in the second part of the D step).\nFinal seasonal filer: length of Henderson filter applied for final estimation (in the second part of the D step).\n\nDisplay in GUI\nNode Decomposition(X11) &gt; Final Filters\n\n\nRetrieve in R\nIn version 2\n\nmodel_sa$decomposition$s_filter\nmodel_sa$decomposition$t_filter\n\n\n\n\nUser-defined parameters\nThe following sections describe how to change default values or automatic choices.\n\nGeneral settings\n\nMode\nSeasonal component\nForecasts horizon\n\nLength of the forecasts generated by the Reg-Arima model - in months (positive values) - years (negative values) - if set to is set to 0, the X-11 procedure does not use any model-based forecasts but the original X-11 type forecasts for one year. - default value: -1, thus one year from the Arima model\n\nBackcasts horizon\n\nLength of the backcasts generated by the Reg-Arima model - in months (positive values) - years (negative values) - default value: 0\n\n\nIrregular correction\n\nLSigma\n\nsets lower sigma (standard deviation) limit used to down-weight the extreme irregular values in the internal seasonal adjustment iterations\nvalues in \\([0,Usigma]\\)\ndefault value is 1.5\n\nUSigma\n\nsets upper sigma (standard deviation)\nvalues in \\([Lsigma,+\\infty]\\)\ndefault value is 2.5\n\nCalendarsigma\n\nallows to set different LSigma and USigma for each period\nvalues\n\nNone (default)\nAll: standard errors used for the extreme values detection and adjustment computed separately for each calendar month/quarter\nSignif: groups determined by Cochran test (check)\nSigmavec: set two customized groups of periods\n\n\nExcludeforecasts\n\nticked: forecasts and backcasts from the Reg-Arima model not used in Irregular Correction\nunticked (default): forecasts and backcasts used\n\n\n\n\nSeasonality extraction filters choice\nSpecifies which be used to estimate the seasonal factors for the entire series.\n\nSeasonal filter\ndefault value: MSR (Moving seasonality ratio), automatic choice of final seasonal filter, initial filters are \\(3\\times 3\\)\nchoices: \\(3\\times 1\\), \\(3\\times 3\\), \\(3\\times 5\\), \\(3\\times 9\\), \\(3\\times 15\\) or Stable\n“Stable”: constant factor for each calendar period (simple moving average of a all \\(S+I\\) values for each period)\n\nUser choices will be applied to final phase D step.\nThe seasonal filters can be selected for the entire series, or for a particular month or quarter.\n\nDetails on seasonal filters\n\nSets different seasonal filters by period in order to account for seasonal heteroskedasticity (link to M chapter)\n\ndefault value: empty\n\n\n\nTrend estimation filters\n\nAutomatic Henderson filter our user-defined\n\ndefault: length 13\nunticked: user defined length choice\n\nHenderson filter length choice\n\nvalues: odd number in \\([3,101]\\)\ndefault value: 13\n\n\nCheck: will user choice be applied to all steps or only to final phase D step\n\n\nParameter setting in GUI\nAll the parameters above can be set with in the specification box.\n\n\nParameter setting in R packages\nIn version 2\n\n#Creating a modified specification, customizing all available X11 parameters\nmodified_spec&lt;- x13_spec(current_sa_model,\n    #x11.mode=\"?\",\n    #x11.seasonalComp = \"?\",\n    x11.fcasts = -2,\n    x11.bcasts = -1,\n    x11.lsigma = 1.2,\n    x11.usigma = 2.8,\n    x11.calendarSigma = NA, \n      x11.sigmaVector = NA,\n    x11.excludeFcasts = NA\n    # filters \n    x11.trendAuto = NA, \n    x11.trendma = 23,\n    x11.seasonalma = \"S3X9)\n\n#New SA estimation: apply modified_spec\n\nmodified_sa_model&lt;-x13(raw_series,modified_spec)"
  },
  {
    "objectID": "A-sa.html#seats-decomposition",
    "href": "A-sa.html#seats-decomposition",
    "title": "Seasonal Adjustment",
    "section": "SEATS Decomposition",
    "text": "SEATS Decomposition\nSEATS algorithm will decompose the linearized series, in level or in logarithm, using the Arima model fitted by Tramo in the pre-treatment phase.\nThe sections below will describe\n\nspecifications needed to run SEATS\ngenerated output\nseries\ndiagnostics\nfinal parameters\nuser-defined parameters\n\n\nDefault specifications\nThe default specifications for SEATS must be chosen at the starting of the SA processing. They are detailed in the RegArima part Starting point for Tramo-Seats\n\n\nQuick Launch\n\nFrom GUI\nWith a workspace open, an SAProcessing created and open data provider:\n\nchoose a default specification (link)\ndrop your data and press green arrow (link)\n\n\n\nIn R\nIn version 2\n\nlibrary(RJDemetra)\nmodel_sa&lt;-tramoseats(raw_series, spec =\"RSAfull\")\n\nThe model_sa R object (list of lists) contains all parameters and results. It will be progressively detailed below.\nIn version 3\n\n\n\nRetrieve Series\nThis section outlines how to retrieve the different kids of output series via GUI or R. - final components (including reallocation of pre-adjustment effects) - components in level - components in level or log\n\nStochastic series\nDecomposition of the linearized series or of its logarithm (in case of a multiplicative model)\ny_lin is split into components: t_lin, s_lin, i_lin\nsuffixes: - _f stands for forecast - _e stands for - _ef stands for\n\nDisplay in GUI\nNODE Decomposition&gt;Stochastic series - Table with series and its standard error image\n\nPlot of Trend with confidence interval image\nPlot of Seasonal component with confidence interval image\n\n\n\nRetrieve from GUI\nGenerating output from GUI (link) or from Cruncher (link), stochastic series, their standard errors, forecasts and forecasts errors can be accessed with the following names\n\n\n\nSeries Name\nMeaning\n\n\n\n\ndecomposition.y_lin\n\n\n\ndecomposition.y_lin_f\n\n\n\ndecomposition.y_lin_ef\n\n\n\ndecomposition.t_lin\n\n\n\ndecomposition.t_lin_f\n\n\n\ndecomposition.t_lin_e\n\n\n\ndecomposition.t_lin_f\n\n\n\ndecomposition.sa_lin\n\n\n\ndecomposition.sa_lin_f\n\n\n\ndecomposition.sa_lin_e\n\n\n\ndecomposition.sa_lin_ef\n\n\n\ndecomposition.s_lin\n\n\n\ndecomposition.s_lin_f\n\n\n\ndecomposition.s_lin_e\n\n\n\ndecomposition.s_lin_ef\n\n\n\ndecomposition.i_lin\n\n\n\ndecomposition.i_lin_f\n\n\n\ndecomposition.i_lin_e\n\n\n\ndecomposition.i_lin_ef\n\n\n\n\n\n\nRetrieve in R\n(to be added) version 2\nversion 3\n\n\n\nComponents (Level)\nDecomposition of the linearized series, back to level in case of a multiplicative model.\ny_lin is split into components: t_lin, s_lin, i_lin\nsuffixes: - _f stands for forecast - _e stands for - _ef stands for\n\nDisplayed in GUI\nNODE Decomposition&gt;Components - Table with series and its standard error image\n\n\nRetrieve from GUI\nGenerating output from GUI (link) or from Cruncher (link), component series, their standard errors, forecasts and forecasts errors can be accessed with the following names\n\n\n\nSeries Name\nMeaning\n\n\n\n\ndecomposition.y_cmp\n\n\n\ndecomposition.y_cmp_f\n\n\n\ndecomposition.y_cmp_ef\n\n\n\ndecomposition.t_cmp\n\n\n\ndecomposition.t_cmp_f\n\n\n\ndecomposition.t_cmp_e\n\n\n\ndecomposition.t_cmp_f\n\n\n\ndecomposition.sa_cmp\n\n\n\ndecomposition.sa_cmp_f\n\n\n\ndecomposition.sa_cmp_e\n\n\n\ndecomposition.sa_cmp_ef\n\n\n\ndecomposition.s_cmp\n\n\n\ndecomposition.s_cmp_f\n\n\n\ndecomposition.s_cmp_e\n\n\n\ndecomposition.s_cmp_ef\n\n\n\ndecomposition.i_cmp\n\n\n\ndecomposition.i_cmp_f\n\n\n\ndecomposition.i_cmp_e\n\n\n\ndecomposition.i_cmp_ef\n\n\n\n\n\n\nRetrieve in R\nversion 2\nversion 3\n\n\nBias correction\n\n\n\nFinal series\n\n\n\n\n\n\n\n\n\nSeries\nFinal SEATS components\nFinal Results\nReallocation of pre-adjustment effects\n\n\n\n\nRaw series (forecasts)\n\ny (y_f)\n\n\n\nLinearized series\nB1\n\nnone\n\n\nFinal seasonal component\nD16\ns (s_f)\n\n\n\nFinal trend\nD12\nt (t_f)\n\n\n\nFinal irregular\nD13\ni (i_f)\n\n\n\nCalendar component\n\n\n\n\n\nSeasonal without calendar\nD10\n\n\n\n\n\n(to be added: reallocation of outliers effects)\n\nDisplay in GUI\nFinal results are displayed for each series in the NODE MAIN&gt;Table\n\n\n\nText\n\n\nForecasts are glued at the end it italic\nWhat can be done with this table (exapandable note ?) - charts container (link) - single series contextual menu (link)\n\n\nRetrieve from GUI\nGenerating outout from GUI (link) or from Cruncher (link), component series, their standard errors, forecasts and forecasts errors can be acessed with the following names\n\n\n\nSeries Name\nMeaning\n\n\n\n\ny\n\n\n\ny_f\n\n\n\nt\n\n\n\nt_f\n\n\n\nsa\n\n\n\nsa_f\n\n\n\ns\n\n\n\ns_f\n\n\n\ni\n\n\n\ni_f\n\n\n\n\n\n\nRetrieve in R\nversion 2\nversion 3\n\n\n\n\nRetrieve Diagnostics\n\nWK analysis\n\ncomponents final estimators\n\nError analysis autocorrelation of the errors (sa, trend) revisions of the errors\nGrowth rates\nModel based tests\nSignificant seasonality\nStationary variance decomposition\n\n\n\nRetrieve Final Parameters\nThis section describes what is chosen automatically or default.\nRelevant if parameters not set manually, or any parameters automatically selected by the software without having a fixed default value. (The rest of the parameters is set in the spec) To manually set hose parameters and see all the fixed default values see Specifications / parameters section\nhere all have a default value, nothing to be automatically selected ?\n\nArima Models for components\nbrief description\n\nDisplay in GUI\nClick on the Decomposition NODE\n\n\n\nRetrieve from GUI\n(add names for output and cruncher)\n\n\nDisplay in R\n(display or retrieve)\nversion 2\nversion 3\n\n\n\nOther final parameters\nFinal parameters which can be fine-tuned be the user are described in User-defined specifications section below\n\n\n\nSetting user-defined parameters\nThe section below explains how the user can fine-tune some seats parameters, which are put in context in the corresponding method chapter.the default value is indicated ().\n\nPrediction length\n\nForecast span used in the decomposition default: one year (-1) (years are set in negative values, positive values indicate number of periods)\n\nApproximation Mode\n\nModification type for inadmissible models None (default) Legacy Noisy\n\nMA unit root boundary\n\nModulus threshold for resetteing MA “near-unit” roots [0,1] default (0.95)\n\nTrend Boundary Modulus thershold for assingning positive real AR Roots [0,1] default (0.5)\nSeasonal Tolerance Degree threshold for assigning complex AR roots [0,10] default (2)\nSeasonal Boundary (unique) Modulus threshold for assigning negative real AR roots [0,1] default (0.8)\nSeasonal Boundary (unique) Same modulus threshold unique seasonal AR roots [0,1] default (0.8)\nMethod\n\nAlgorithm used for estimation of unobserved componements\nBurman (default)\nKalmanSmoother\nMcEllroyMatrix\n\nSeting parameters in GUI\nIn specification window (link) corresponding to a given series:\n\n\n\nText\n\n\n\n\nSet in R\nversion 2 (RJDemetra)\n\ntramoseats_spec(\n spec = c(\"RSAfull\", \"RSA0\", \"RSA1\", \"RSA2\", \"RSA3\", \"RSA4\", \"RSA5\"),\n  fcst.horizon = NA_integer_,\n  seats.predictionLength = NA_integer_,\n  seats.approx = c(NA, \"None\", \"Legacy\", \"Noisy\"),\n  seats.trendBoundary = NA_integer_,\n  seats.seasdBoundary = NA_integer_,\n  seats.seasdBoundary1 = NA_integer_,\n  seats.seasTol = NA_integer_,\n  seats.maBoundary = NA_integer_,\n  seats.method = c(NA, \"Burman\", \"KalmanSmoother\", \"McElroyMatrix\")\n)\n\nin version 3 with {rjd3tramoseats} (to be added)"
  },
  {
    "objectID": "A-sa.html#stl",
    "href": "A-sa.html#stl",
    "title": "Seasonal Adjustment",
    "section": "STL",
    "text": "STL\nLoess based decomposition algorithm used on linearized data data, no pre-adjustment.\nNot currently available. Under construction."
  },
  {
    "objectID": "A-sa.html#basic-structural-models",
    "href": "A-sa.html#basic-structural-models",
    "title": "Seasonal Adjustment",
    "section": "Basic Structural Models",
    "text": "Basic Structural Models\nNot currently available. Under construction."
  },
  {
    "objectID": "A-sa-hf.html#in-this-chapter",
    "href": "A-sa-hf.html#in-this-chapter",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "In this chapter",
    "text": "In this chapter"
  },
  {
    "objectID": "A-sa-hf.html#overview",
    "href": "A-sa-hf.html#overview",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Overview",
    "text": "Overview\nThis chapter provides guidance on seasonal adjustment of high-frequency (HF) data with JDemetra+ tailored algorithms.\nCurrently available topics:\n\ndescription of high frequency data specificities\nR functions for pre-treatment, extended X-11 and extended Seats\n\nTopics under construction\n\ngraphical user interface 3.0 functionalities for HF data\nSTL functions\nState space framework"
  },
  {
    "objectID": "A-sa-hf.html#data-specificities",
    "href": "A-sa-hf.html#data-specificities",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Data specificities",
    "text": "Data specificities\nIntra-monthly data displays multiple and non-integer periodicities which cannot be dealt with classical versions of SA algorithms. JD+ provides tailored versions of these algorithms.\n\nPeriodicities (number of observations per cycle)\n\n\nData\nDay\nWeek\nMonth\nQuarter\nYear\n\n\n\n\nquarterly\n\n\n\n\n4\n\n\nmonthly\n\n\n\n3\n12\n\n\nweekly\n\n\n4.3481\n13.0443\n52.1775\n\n\ndaily\n\n7\n30.4368\n91.3106\n365.2425\n\n\nhourly\n24\n168\n730.485\n2191.4550\n8765.82"
  },
  {
    "objectID": "A-sa-hf.html#tailored-algorithms-in-jdemetra",
    "href": "A-sa-hf.html#tailored-algorithms-in-jdemetra",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Tailored algorithms in JDemetra+",
    "text": "Tailored algorithms in JDemetra+\n\n\n\n\n\n\n\n\n\nCol1\nAlgorithm\nGUI v 3.0\nR package\n\n\n\n\nPre-treatment\nExtended Airline Model\nyes\nrjd3highfreq\n\n\nDecomposition\nExtended SEATS Extended Airline Model\nyes\nrjd3highfreq\n\n\n\nExtended X-11\nyes\nrjd3highfreq\n\n\n\nExtended STL\nno\nrjd3stl\n\n\nOne-Step\nSSF Framework\nno\nrjd3sts"
  },
  {
    "objectID": "A-sa-hf.html#unobserved-components",
    "href": "A-sa-hf.html#unobserved-components",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Unobserved Components",
    "text": "Unobserved Components\n\nRaw series decomposition\n\n\n\nMultiple seasonal patterns\nFor HF data multiple seasonal patterns might be taken into account. \\[S_{t}= S_{t,7} \\circ S_{t,30.44} \\circ S_{t,365.25}\\]\nThe decomposition is done iteratively periodicity by periodicity starting with the smallest one (highest frequency) as:\n\nhighest frequencies usually display the biggest and most stable variations\ncycles of highest frequencies can mix up with lower ones"
  },
  {
    "objectID": "A-sa-hf.html#identifying-seasonal-patterns",
    "href": "A-sa-hf.html#identifying-seasonal-patterns",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Identifying seasonal patterns",
    "text": "Identifying seasonal patterns\nJDemetra+ provides the Canova-Hansen test in rjd3toolkit package."
  },
  {
    "objectID": "A-sa-hf.html#pre-adjustment",
    "href": "A-sa-hf.html#pre-adjustment",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Pre-adjustment",
    "text": "Pre-adjustment\nIn classical X13-Arima and Tramo-Seats, a pre-adjustment step is performed to remove deterministic effects, such as outliers and calendar effects, with a Reg-Arima model. In the extended version for HF data, it is also the case with an extended Airline model.\nA general Reg-ARIMA model is written as follows: \\[\n\\left(Y_t - \\sum {\\alpha_i}X_{it}\\right) \\sim ARIMA(p,d,q)(P,D,Q)\n\\] These models contain seasonal backshift operators \\(B^{s}(y_t)=y_{t-s}\\). Here \\(s\\) can be non-integer. JDemetra+ will rely on a modified version of a frequently used Arima model: the “Airline” model:\n\\[\n(1-B)(1-B^{s})y_t=(1-\\theta_1 B)(1-\\theta_2 B^{s}) \\epsilon_t \\text{~~~~} \\epsilon_t \\sim \\text{NID}(0,\\sigma^2_{\\epsilon})  \n\\]\nFor HF data potentially non-integer \\(s\\) will be written: \\(s=s' + \\alpha\\), with \\(\\alpha\\) real number i \\(]0,1[\\) (for example \\(52.18 = 52 +0.18\\) is the yearly periodicity for weekly data)\nTaylor development around 1 of \\(f(x)=x^\\alpha\\) \\[\n\\begin{array}{lll}\nx^\\alpha &=& 1 + \\alpha (x-1) + \\frac{\\alpha (\\alpha+1)}{2!} (x-1)^2 + \\frac{\\alpha (\\alpha+1) (\\alpha+2)}{3!} (x-1)^3 +\\cdots \\\\\n            B^\\alpha &\\cong& (1 - \\alpha)+ \\alpha B     \n\\end{array}\n\\] Approximation of \\(B^{s+\\alpha}\\) in an extended Airline model\n\\[\n\\begin{array}{lll}\nB^{s+\\alpha} &\\cong& (1 - \\alpha)B^s+ \\alpha B^{s+1}                \n\\end{array}\n\\] Example for a daily series displaying two periodicities \\(p_{1}=7\\) and \\(p_{2}=365.25\\):\n\\[\n(1-B)(1-B^{7})(1-B^{365.25)}(Y_t - \\sum {\\alpha_i}X_{it})=(1-\\theta_1 B)(1-\\theta_2 B^{7})(1-\\theta_3 B^{365.25}) \\epsilon_t\n\\] \\[\n\\epsilon_t \\sim \\text{NID}(0,\\sigma^2_{\\epsilon})\n\\]\nwith \\[\n1-B^{365.25}=(1 - 0.75B^{365} - 0.25B^{366})\n\\]\n\nCalendar correction\nCalendar regressors can be defined with rjd3toolkit package and added to pre-treatment function as a matrix.\n\n#setting calendar variables\n## define a calendar\nfrenchCalendar &lt;- rjd3toolkit::calendar.new()\nrjd3toolkit::calendar.holiday(frenchCalendar, \"NEWYEAR\")\n#rjd3toolkit::calendar.holiday(frenchCalendar, \"GOODFRIDAY\")\nrjd3toolkit::calendar.holiday(frenchCalendar, \"EASTERMONDAY\") # Lundi de Pâques\nrjd3toolkit::calendar.holiday(frenchCalendar, \"MAYDAY\") # 1er mai\nrjd3toolkit::calendar.fixedday(frenchCalendar, 5, 8,start=\"1982-05-08\") # since 1982, 2nd world war \nrjd3toolkit::calendar.easter(frenchCalendar,offset = 39) ## ascension\nrjd3toolkit::calendar.holiday(frenchCalendar, \"WHITMONDAY\") # Lundi de Pentecôte\nrjd3toolkit::calendar.fixedday(frenchCalendar, 7, 14)  # national holiday\nrjd3toolkit::calendar.holiday(frenchCalendar, \"ASSUMPTION\") # Assomption\nrjd3toolkit::calendar.holiday(frenchCalendar, \"ALLSAINTSDAY\") # Toussaint\nrjd3toolkit::calendar.holiday(frenchCalendar, \"ARMISTICE\") # first world war\nrjd3toolkit::calendar.holiday(frenchCalendar, \"CHRISTMAS\") #  25th December\n\n## extract regressors: here daily series \nq&lt;-rjd3toolkit::holidays(frenchCalendar, \"1968-01-01\", \n                           length = length(y_raw_daily), type=\"All\",\n                           nonworking = as.integer(7))\n\n\n\nOutliers and intervention variables\nOutliers detection is available in the pre-treatment function. Detected outliers are AO, LS and WO. Critical value can be computed by the algorithm or user-defined.\n\n\nLinearization\nExample using rjd3highfreq::fractionalAirlineEstimation function:\n\npre_adjustment&lt;- rjd3highfreq::fractionalAirlineEstimation(y_raw,\n                x = q, # q= calendar regressors\n                periods = c(7,365.25)\n                ndiff = 2, ar = FALSE, mean = FALSE,\n                outliers = c(\"ao\",\"ls\", \"wo\"), \n                criticalValue = 0, # computed in the algorithm\n                precision = 1e-9, approximateHessian = TRUE)\n\n“pre_adjustment” R object is a list of lists in which the user can retrieve input series, parameters and output series. For more details see chapter on R packages and rjd3highfreq help pages R, where all parameters are listed."
  },
  {
    "objectID": "A-sa-hf.html#decomposition",
    "href": "A-sa-hf.html#decomposition",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Decomposition",
    "text": "Decomposition\n\nExtended X-11\nX-11 is the decomposition module of X-13-Arima, the linearized series from the pre-adjustment step is split into seasonal (\\(S\\)), trend (\\(T\\)) and irregular (\\(I\\)) components. In case of multiple periodicities the decomposition is done periodicity by periodicity starting with the smallest one. Global structure of the iterations is the same as in “classical” X-11 but modifications were introduced for tackling non-integer periodicities. They rely on the Taylor approximation for the seasonal backshift operator:\n\\[\n\\begin{array}{lll}\nB^{s+\\alpha} &\\cong& (1 - \\alpha)B^s+ \\alpha B^{s+1}                \n\\end{array}\n\\]\n\nModification of the first trend filter for removing seasonality\nThe first trend estimation is thanks to a generalization of the centred and symmetrical moving averages with an order equal to the periodicity \\(p\\).\n\nfilter length \\(l\\): smallest odd integer greater than \\(p\\)\nex : p=7, l=7, p=12 l=13, p=365,25, l=367, p=52.18 l=53\ncentral coefficients \\(1/p\\) (1/12,1/7, 1/365.25)\nend-point coefficients \\(\\mathbb{I} \\{\\text{$E(p)$ even}\\} +(p-E(p)) /2p\\)\nexample for p=12: (1/12 and 1/24) (we fall back on \\(M_{2\\times12}\\) of the monthly case\nexample for p=365.25: (1/365.25 and 0.25/(2*365.25)\n\n\n\nModification of seasonality extraction filters\nComputation is done on a given period\nExample \\(M_{3\\times3}\\)\n\\[\nM_{3\\times3}X = \\frac{1}{9}(X_{t-2p})+\\frac{2}{9}(X_{t-p})+\\frac{3}{9}(X_{t})+\\frac{2}{9}(X_{t+p})+\\frac{1}{9}(X_{t+2p})\n\\]\nif \\(p\\) integer: no changes needed\nif \\(p\\) non-integer: Taylor approximation of the backshift operator\n\n\nModification of final trend estimation filter\nAs seasonality has been removed in the first step, there is no non-integer periodicity issue in the final trend estimation, but extended X-11 offers additional features vs genuine X-11, in which final trend is estimated with Henderson filters and Musgrave asymmetrical surrogates. In extended in X-11, a generalization of this method with local polynomial approximation is available.\n\n\nExample of decomposition\nHere the raw series is daily and displays two periodicities \\(p=7\\) and \\(p=365.25\\)\n\n# extraction of day-of-the-week pattern (dow)\nx11.dow &lt;- rjd3highfreq::x11(y_linearized,\n        period = 7,                 # DOW pattern\n        mul = TRUE,                              \n        trend.horizon = 9,  # 1/2 Filter length : not too long vs p\n        trend.degree = 3,                         # Polynomial degree\n        trend.kernel = \"Henderson\",               # Kernel function\n        trend.asymmetric = \"CutAndNormalize\",     # Truncation method\n        seas.s0 = \"S3X9\", seas.s1 = \"S3X9\",       # Seasonal filters\n        extreme.lsig = 1.5, extreme.usig = 2.5)   # Sigma-limits\n\n\n# extraction of day-of-the-week pattern (doy)\n\nx11.doy &lt;- rjd3highfreq::x11(x11.dow$decomposition$sa,  # previous sa\n                    period = 365.2425,         # DOY pattern\n                    mul = TRUE, \n                    trend.horizon = 371, # 1/2 final filter length \n                    trend.degree = 3,\n                    trend.kernel = \"Henderson\", \n                    trend.asymmetric = \"CutAndNormalize\",\n                    seas.s0 = \"S3X15\", seas.s1 = \"S3X5\",\n                    extreme.lsig = 1.5, extreme.usig = 2.5)\n\n\n\n\nArima Model Based (AMB) Decomposition (Extended Seats)\nExample\n\n# extracting doy pattern\n\namb.doy &lt;- rjd3highfreq::fractionalAirlineDecomposition(\n  amb.dow$decomposition$sa,  # DOW-adjusted linearised data\n  period = 365.2425,         # DOY pattern\n  sn = FALSE,                # Signal (SA)-noise decomposition \n  stde = FALSE,              # Calculate standard deviations\n  nbcasts = 0, nfcasts = 0)  # Numbers of back- and forecasts\n\n\n\nSummary of the process\nFor the time being, seasonal adjustment processing in rjd3highfreq cannot be encompassed by one function like for lower frequency, e.g rjd3x13::x13(y_raw)\nThe user has to run the steps one by one, here is an example with \\(p=7\\) and \\(p=365.25\\)\n\ncomputation of the linearized series \\(Y_{lin}=FracAirline(Y)\\)\ncomputation of the calendar corrected series \\(Y_{cal}\\)\ncomputation of \\(S_{7}\\) by decomposition of the linearized series\ncomputation of \\(S_{365.25}\\) by decomposition of the seasonally adjusted series with \\(p=7\\)\nfinally adjusted series \\(sa_{final} = Y_{cal}/S_{7}/S_{365.25}\\) (if multiplicative model)\n\n\n\nSTL decomposition\nNot currently available. Under construction."
  },
  {
    "objectID": "A-sa-hf.html#state-space-framework",
    "href": "A-sa-hf.html#state-space-framework",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "State Space framework",
    "text": "State Space framework\nNot currently available. Under construction."
  },
  {
    "objectID": "A-sa-hf.html#quality-assessment",
    "href": "A-sa-hf.html#quality-assessment",
    "title": "Seasonal adjustment of high-frequency data",
    "section": "Quality assessment",
    "text": "Quality assessment\n\nResidual seasonality\nJDemetra+ provides the Canova-Hansen test in rjd3toolkit package which allows to check for any remaining seasonal periodicity in the final SA data."
  },
  {
    "objectID": "A-outlier-detection.html#overview",
    "href": "A-outlier-detection.html#overview",
    "title": "Outlier detection and Intervention variables",
    "section": "Overview",
    "text": "Overview\n\nExternal regressors and their use\n2 types of external regressors equations on allocation to components\n\ncalendar very specific issue, specific chapter\nothers : outliers,…\n\n\nHere construction of variables for quarterly and monthly data quid about HF ? bilan à faire\nin R once a regressor is defined, it can be used as an external regressor: more possibilities of allocation and fixing coeffs\nJDemetra+ provides outlier detection routines which can be used stand alone or as part of a seasonal adjustment process. They can be accessed via GUI or R packages."
  },
  {
    "objectID": "A-outlier-detection.html#in-this-chapter",
    "href": "A-outlier-detection.html#in-this-chapter",
    "title": "Outlier detection and Intervention variables",
    "section": "In this chapter",
    "text": "In this chapter\n\ngeneration\nplug in into algos : in relevant chapters : key = allocation to components ? automatic or not ? specify for each type\ndetection"
  },
  {
    "objectID": "A-outlier-detection.html#generating-regressors-for-outliers",
    "href": "A-outlier-detection.html#generating-regressors-for-outliers",
    "title": "Outlier detection and Intervention variables",
    "section": "Generating regressors for outliers",
    "text": "Generating regressors for outliers\n\nAvailable types of outiers\nif smth else needed (intervention variables or ramps) pull out from R doc + Sa chapter - names - equations - explanations"
  },
  {
    "objectID": "A-outlier-detection.html#generating-regressors-for-outliers-1",
    "href": "A-outlier-detection.html#generating-regressors-for-outliers-1",
    "title": "Outlier detection and Intervention variables",
    "section": "Generating regressors for outliers",
    "text": "Generating regressors for outliers\nuse cases allocation to components: pre-defined in the type, not user customizable\n\nGeneration in GUI\nregressors are notre really generated but pre-specified v2 calendar (fixing coefficients impossible ?)\nV3 calendar or different window, allowing to fix coefficients\n\n\nGeneration in R\nv2 regressors couldn’t be generated but directly implemented in spec link to SA chap\nv3 outliers can be directly implemented in a spec link to SA chap\nbut regressors can also be generated with rjd3toolkit(link to R pack chap) for an independent use\n\n#Outliers in February 2002\nao &lt;- ao_variable(12, c(2000,1), length = 12*4, date = \"2002-02-01\")\nls &lt;- ls_variable(12, c(2000,1), length = 12*4, date = \"2002-02-01\")\ntc &lt;- tc_variable(12, c(2000,1), length = 12*4, date = \"2002-02-01\")\nso &lt;- so_variable(12, c(2000,1), length = 12*4, date = \"2002-02-01\")\n\nMore details rjd3toolkit help (how to set a link) pages and vignette\n\n\nadding outliers to specification\n\n\nin GUI\n\n\nin R\nv2\nV3 pb : add outlier and set outlier"
  },
  {
    "objectID": "A-outlier-detection.html#generating-ramp-regressors",
    "href": "A-outlier-detection.html#generating-ramp-regressors",
    "title": "Outlier detection and Intervention variables",
    "section": "Generating ramp regressors",
    "text": "Generating ramp regressors\nwhy ? what is different from outliers (and i variables ) how can they be allocated dans GUI ramp se voir dans reg_t, pas de choix d’allocation voir si idem en r\ncan coefficient be fixed in GUI separated window\n\nGeneration in GUI\nv2 calendar (fixing coefficients impossible ?)\nV3 calendar or different window, allowing to fix coefficients\n\n\nGeneration in R\nv2 regressors couldn’t be generated but directly implemented in spec link to SA chap\nv3 outliers can be directly implemented in a spec link to SA chap\nbut regressors can also be generated with rjd3toolkit for an independent use\n\n# Ramp variable from January 2001 to September 2001\nrp &lt;- ramp_variable(12, c(2000,1), length = 12*4, range = c(13, 21))\n# Or equivalently\nrp&lt;-ramp_variable(12, c(2000,1), length = 12*4, range = c(\"2001-01-01\", \"2001-09-02\"))\nplot.ts(rp)\n\nMore details rjd3toolkit help (how to set a link) pages and vignette\n\n\nadding ramps to specification\n\n\nin GUI\n\n\nin R\nv2\nV3"
  },
  {
    "objectID": "A-outlier-detection.html#generating-intervention-variable",
    "href": "A-outlier-detection.html#generating-intervention-variable",
    "title": "Outlier detection and Intervention variables",
    "section": "Generating intervention variable",
    "text": "Generating intervention variable\nwhy ? what is different from outliers (and ramps) how can they be allocated details in component very important cf JP\ndans GUI intervention va dans reg_i\ncan coefficient be fixes je ne comprends pas fenetre dans GUI\n\nGeneration in GUI\nv2 calendar (fixing coefficients impossible ?)\nV3 calendar or different window, allowing to fix coefficients\n\n\nGeneration in R\nv2 regressors couldn’t be generated but directly implemented in spec link to SA chap\nv3 outliers can be directly implemented in a spec link to SA chap\nbut regressors can also be generated with rjd3toolkit for an independent use\n\niv&lt;-intervention_variable(frequency=12, start=c(2000, 1), length=60,\n                      starts = \"2001-01-01\", ends = \"2001-12-01\")\niv\nplot(iv)\n\niv&lt;-intervention_variable(12, c(2000, 1), 60,\n                      starts = \"2001-01-01\", ends = \"2001-12-01\", delta = 1)\niv\nplot(iv)\n\niv&lt;-intervention_variable(12, c(2000, 1), 60,\n                          starts = \"2001-01-01\", ends = \"2001-12-01\",\n                          delta =0, seasonaldelta=1)\niv\nplot(iv)\n\nMore details rjd3toolkit help (how to set a link) pages and vignette\n\n\nadding intervention variable to specification\n\n\nin GUI\n\n\nin R\nv2\nV3"
  },
  {
    "objectID": "A-outlier-detection.html#generating-periodic-dummies-and-contrasts",
    "href": "A-outlier-detection.html#generating-periodic-dummies-and-contrasts",
    "title": "Outlier detection and Intervention variables",
    "section": "Generating periodic dummies and contrasts",
    "text": "Generating periodic dummies and contrasts\nwhy ? use case ?\nin GUI not possible\n\nIn R\ndummies :as many time series as type of periods in a year (4,12) periodic contrasts; objectif\n\n## periodic dummies : add explanations and examples\np&lt;-periodic.dummies(4, c(2000,1), 60)\nhead(p)\nclass(p)\nq&lt;-periodic.contrasts(4, c(2000,1), 60) # erreur to be checked ?\nq[1:9,]\n\ncontrasts"
  },
  {
    "objectID": "A-outlier-detection.html#generating-trigonometric-variables",
    "href": "A-outlier-detection.html#generating-trigonometric-variables",
    "title": "Outlier detection and Intervention variables",
    "section": "Generating trigonometric variables",
    "text": "Generating trigonometric variables\nuse case: stable seaso in what kind of model ? allocation fixed coeff in GUI not possible (different algo)\n\nin R\nMore details rjd3toolkit help (how to set a link) pages and vignette"
  },
  {
    "objectID": "A-outlier-detection.html#adding-user-defined-variables-to-specification",
    "href": "A-outlier-detection.html#adding-user-defined-variables-to-specification",
    "title": "Outlier detection and Intervention variables",
    "section": "adding user defined variables to specification",
    "text": "adding user defined variables to specification\n\nallocation to component\ncoefficient"
  },
  {
    "objectID": "A-outlier-detection.html#outlier-detection-parameters-in-a-sa-processing",
    "href": "A-outlier-detection.html#outlier-detection-parameters-in-a-sa-processing",
    "title": "Outlier detection and Intervention variables",
    "section": "Outlier detection Parameters in a SA processing",
    "text": "Outlier detection Parameters in a SA processing\ncf function set outlier"
  },
  {
    "objectID": "A-outlier-detection.html#outlier-detection-with-reg-arima-models",
    "href": "A-outlier-detection.html#outlier-detection-with-reg-arima-models",
    "title": "Outlier detection and Intervention variables",
    "section": "Outlier Detection With Reg Arima models",
    "text": "Outlier Detection With Reg Arima models\nhere we are talking detection outside of an SA process\n\nIn R\nindependent function in\n\nrjd3x13\n\n\nregarima_outliers(rjd3toolkit::ABS$X0.2.09.10.M, order=c(1,1,1), seasonal=c(0,1,1), \n                  mean=F,\n                  X=NULL, X.td=NULL, \n                  ao=T, ls=F, tc=T, so=T, cv=4)\n\n\nrjd3tramoseats"
  },
  {
    "objectID": "A-outlier-detection.html#specific-terror-tool",
    "href": "A-outlier-detection.html#specific-terror-tool",
    "title": "Outlier detection and Intervention variables",
    "section": "Specific TERROR tool",
    "text": "Specific TERROR tool"
  },
  {
    "objectID": "A-outlier-detection.html#with-structural-models-bsm",
    "href": "A-outlier-detection.html#with-structural-models-bsm",
    "title": "Outlier detection and Intervention variables",
    "section": "With structural models (BSM)",
    "text": "With structural models (BSM)"
  },
  {
    "objectID": "A-calendar-correction.html#in-this-chapter",
    "href": "A-calendar-correction.html#in-this-chapter",
    "title": "Calendar and user-defined corrections",
    "section": "In this chapter",
    "text": "In this chapter\nThis chapter describes: theory - underlying principles and concepts of calendar correction\npractice - generating process of calendars, calendar regressors,\nHow to use these variables inside a seasonal adjustment process is detailed in chapters on SA or SA of HF data.\nProcess: - default calendars are not suited for the situation otherwise nothing to do: cf sa chapter..?\n\nNEED = customized regressors. What does it mean ? Steps to define them ?\nStep 1 define a calendar\nStep 2 generate sets of regressors at different data frequencies : q, monthly, weekly ? daily\n\nnormal calendar effects\nesater (effect: completely different to be explained above)\n\nStep 3 plug in sa algo (cf sa chapter: check if well explained)"
  },
  {
    "objectID": "A-calendar-correction.html#overview-of-calendar-effects-in-jdemetra",
    "href": "A-calendar-correction.html#overview-of-calendar-effects-in-jdemetra",
    "title": "Calendar and user-defined corrections",
    "section": "Overview of Calendar effects in JDemetra",
    "text": "Overview of Calendar effects in JDemetra\nA natural way for modelling calendar effects consists of distributing the days of each period into different groups. The regression variable corresponding to a type of day (a group) is simply defined by the number of days it contains for each period. Usual classifications are:\n\nTrading days (7 groups): each day of the week defines a group (Mondays,...,Sundays);\nWorking days (2 groups): week days and weekends.\n\nThe definition of a group could involve partial days. For instance, we could consider that one half of Saturdays belong to week days and the second half to weekends.\nUsually, specific holidays are handled as Sundays and they are included in the group corresponding to “non-working days”. This approach assumes that the economic activity on national holidays is the same (or very close to) the level of activity that is typical for Sundays. Alternatively, specific holidays can be considered separately, e.g. by the specification that divided days into three groups:\n\nWorking days (Mondays to Fridays, except for specific holidays),\nNon-working days (Saturdays and Sundays, except for specific holidays),\nSpecific holidays.\n\n\nSummary of the method used in JDemetra+ to compute trading day and working day effects\nThe computation of trading day and working days effects is performed in four steps:\n\nComputation of the number of each weekday performed for all periods.\nCalculation of the usual contrast variables for trading day and working day.\nCorrection of the contrast variables with specific holidays (for each holiday add +1 to the number of Sundays and subtract 1 from the number of days of the holiday). The correction is not performed if the holiday falls on a Sunday, taking into account the validity period of the holiday.\nCorrection of the constant variables for long term mean effects, &gt; taking into account the validity period of the holiday; see below &gt; for the different cases.\n\nThe corrections of the constant variables may receive a weight corresponding to the part of the holiday considered as a Sunday.\nAn example below illustrates the application of the above algorithm for the hypothetical country in which three holidays are celebrated:\n\nNew Year (a fixed holiday, celebrated on 01 January);\nShrove Tuesday (a moving holiday, which falls 47 days before Easter Sunday, celebrated until the end of 2012);\nFreedom day (a fixed holiday, celebrated on 25 April).\n\nThe consecutive steps in calculation of the calendar for 2012 and 2013 years are explained below.\nFirst, the number of each day of the week in the given month is calculated as it is shown in table below.\nNumber of each weekday in different months\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth\nMon\nTue\nWed\nThu\nFri\nSat\nSun\n\n\n\n\nJan-12\n5\n5\n4\n4\n4\n4\n5\n\n\nFeb-12\n4\n4\n5\n4\n4\n4\n4\n\n\nMar-12\n4\n4\n4\n5\n5\n5\n4\n\n\nApr-12\n5\n4\n4\n4\n4\n4\n5\n\n\nMay-12\n4\n5\n5\n5\n4\n4\n4\n\n\nJun-12\n4\n4\n4\n4\n5\n5\n4\n\n\nJul-12\n5\n5\n4\n4\n4\n4\n5\n\n\nAug-12\n4\n4\n5\n5\n5\n4\n4\n\n\nSep-12\n4\n4\n4\n4\n4\n5\n5\n\n\nOct-12\n5\n5\n5\n4\n4\n4\n4\n\n\nNov-12\n4\n4\n4\n5\n5\n4\n4\n\n\nDec-12\n5\n4\n4\n4\n4\n5\n5\n\n\nJan-13\n4\n5\n5\n5\n4\n4\n4\n\n\nFeb-13\n4\n4\n4\n4\n4\n4\n4\n\n\nMar-13\n4\n4\n4\n4\n5\n5\n5\n\n\nApr-13\n5\n5\n4\n4\n4\n4\n4\n\n\nMay-13\n4\n4\n5\n5\n5\n4\n4\n\n\nJun-13\n4\n4\n4\n4\n4\n5\n5\n\n\nJul-13\n5\n5\n5\n4\n4\n4\n4\n\n\nAug-13\n4\n4\n4\n5\n5\n5\n4\n\n\nSep-13\n5\n4\n4\n4\n4\n4\n5\n\n\nOct-13\n4\n5\n5\n5\n4\n4\n4\n\n\nNov-13\n4\n4\n4\n4\n5\n5\n4\n\n\nDec-13\n5\n5\n4\n4\n4\n4\n5\n\n\n\nNext, the contrast variables are calculated (table below) as a result of the linear transformation applied to the variables presented in table below.\nContrast variables (series corrected for leap year effects)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth\nMon\nTue\nWed\nThu\nFri\nSat\nLength\n\n\n\n\nJan-12\n0\n0\n-1\n-1\n-1\n-1\n0\n\n\nFeb-12\n0\n0\n1\n0\n0\n0\n0.75\n\n\nMar-12\n0\n0\n0\n1\n1\n1\n0\n\n\nApr-12\n0\n-1\n-1\n-1\n-1\n-1\n0\n\n\nMay-12\n0\n1\n1\n1\n0\n0\n0\n\n\nJun-12\n0\n0\n0\n0\n1\n1\n0\n\n\nJul-12\n0\n0\n-1\n-1\n-1\n-1\n0\n\n\nAug-12\n0\n0\n1\n1\n1\n0\n0\n\n\nSep-12\n-1\n-1\n-1\n-1\n-1\n0\n0\n\n\nOct-12\n1\n1\n1\n0\n0\n0\n0\n\n\nNov-12\n0\n0\n0\n1\n1\n0\n0\n\n\nDec-12\n0\n-1\n-1\n-1\n-1\n0\n0\n\n\nJan-13\n0\n1\n1\n1\n0\n0\n0\n\n\nFeb-13\n0\n0\n0\n0\n0\n0\n-0.25\n\n\nMar-13\n-1\n-1\n-1\n-1\n0\n0\n0\n\n\nApr-13\n1\n1\n0\n0\n0\n0\n0\n\n\nMay-13\n0\n0\n1\n1\n1\n0\n0\n\n\nJun-13\n-1\n-1\n-1\n-1\n-1\n0\n0\n\n\nJul-13\n1\n1\n1\n0\n0\n0\n0\n\n\nAug-13\n0\n0\n0\n1\n1\n1\n0\n\n\nSep-13\n0\n-1\n-1\n-1\n-1\n-1\n0\n\n\nOct-13\n0\n1\n1\n1\n0\n0\n0\n\n\nNov-13\n0\n0\n0\n0\n1\n1\n0\n\n\nDec-13\n5\n5\n4\n4\n4\n4\n0\n\n\n\nIn the next step the corrections for holidays is done in the following way:\n\nNew Year: In 2012 it falls on a Sunday. Therefore no correction is applied. In 2013 it falls on a Tuesday. Consequently, the following corrections are applied to the number of each weekday in January: Tuesday -1, Sunday +1, so the following corrections are applied to the contrast variables: -2 for Tuesday and -1 for the other contrast variables.\nShrove Tuesday: It is a fixed day of the week holiday that always falls on Tuesday. For this reason in 2012 the following corrections are applied to the number of each weekday in February: Tuesday -1, Sunday +1, so the following corrections are applied to the contrast variables: -2 for the contrast variable associated with Tuesday, and -1 for the other contrast variables. The holiday expires at the end of 2012. Therefore no corrections are made for 2013.\nFreedom Day: In 2012 it falls on a Wednesday. Consequently, the following corrections are applied to the number of each weekday in April: Wednesday -1, Sunday +1, so the following corrections are applied to the contrast variables: -2 for Wednesday and -1 for the other contrast variables. In 2013 it falls on Thursday. Therefore, the following corrections are applied to the number of each weekday in April: Thursday -1, Sunday +1, so the following corrections are applied to the contrast variables: -2 for Thursday, and -1 for the other contrast variables.\n\nThe result of these corrections is presented in table below.\nContrast variables corrected for holidays\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth\nMon\nTue\nWed\nThu\nFri\nSat\nLength\n\n\n\n\nJan-12\n0\n0\n-1\n-1\n-1\n-1\n0\n\n\nFeb-12\n-1\n-2\n0\n-1\n-1\n-1\n0.75\n\n\nMar-12\n0\n0\n0\n1\n1\n1\n0\n\n\nApr-12\n-1\n-2\n-3\n-2\n-2\n-2\n0\n\n\nMay-12\n0\n1\n1\n1\n0\n0\n0\n\n\nJun-12\n0\n0\n0\n0\n1\n1\n0\n\n\nJul-12\n0\n0\n-1\n-1\n-1\n-1\n0\n\n\nAug-12\n0\n0\n1\n1\n1\n0\n0\n\n\nSep-12\n-1\n-1\n-1\n-1\n-1\n0\n0\n\n\nOct-12\n1\n1\n1\n0\n0\n0\n0\n\n\nNov-12\n0\n0\n0\n1\n1\n0\n0\n\n\nDec-12\n0\n-1\n-1\n-1\n-1\n0\n0\n\n\nJan-13\n-1\n-1\n0\n0\n-1\n-1\n0\n\n\nFeb-13\n0\n0\n0\n0\n0\n0\n-0.25\n\n\nMar-13\n-1\n-1\n-1\n-1\n0\n0\n0\n\n\nApr-13\n0\n0\n-1\n-2\n-1\n-1\n0\n\n\nMay-13\n0\n0\n1\n1\n1\n0\n0\n\n\nJun-13\n-1\n-1\n-1\n-1\n-1\n0\n0\n\n\nJul-13\n1\n1\n1\n0\n0\n0\n0\n\n\nAug-13\n0\n0\n0\n1\n1\n1\n0\n\n\nSep-13\n0\n-1\n-1\n-1\n-1\n-1\n0\n\n\nOct-13\n0\n1\n1\n1\n0\n0\n0\n\n\nNov-13\n0\n0\n0\n0\n1\n1\n0\n\n\nDec-13\n0\n0\n-1\n-1\n-1\n-1\n0\n\n\n\nFinally, the long term corrections are applied on each year of the validity period of the holiday.\n\nNew Year: Correction on the contrasts: +1, to be applied to January of 2012 and 2013.\nShrove Tuesday: It may fall either in February or in March. It will fall in March if Easter is on or after 17 April. Taking into account the theoretical distribution of Easter, it gives: prob(March) = +0.22147, prob(February) = +0.77853. The correction of the contrasts will be +1.55707 for Tuesday in February 2012 and +0.77853 for the other contrast variables. The correction of the contrasts will be +0.44293 for Tuesday in March 2012, +0.22147 for the other contrast variables.\nFreedom Day: Correction on the contrasts: +1, to be applied to April of 2012 and 2013.\n\nThe modifications due to the corrections described above are presented in table below.\nTrading day variables corrected for the long term effects\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth\nMon\nTue\nWed\nThu\nFri\nSat\nLength\n\n\n\n\nJan-12\n1\n1\n0\n0\n0\n0\n0\n\n\nFeb-12\n-0.22115\n-0.44229\n0.778853\n-0.22115\n-0.22115\n-0.22115\n0.75\n\n\nMar-12\n0.221147\n0.442293\n0.221147\n1.221147\n1.221147\n1.221147\n0\n\n\nApr-12\n0\n-1\n-2\n-1\n-1\n-1\n0\n\n\nMay-12\n0\n1\n1\n1\n0\n0\n0\n\n\nJun-12\n0\n0\n0\n0\n1\n1\n0\n\n\nJul-12\n0\n0\n-1\n-1\n-1\n-1\n0\n\n\nAug-12\n0\n0\n1\n1\n1\n0\n0\n\n\nSep-12\n-1\n-1\n-1\n-1\n-1\n0\n0\n\n\nOct-12\n1\n1\n1\n0\n0\n0\n0\n\n\nNov-12\n0\n0\n0\n1\n1\n0\n0\n\n\nDec-12\n0\n-1\n-1\n-1\n-1\n0\n0\n\n\nJan-13\n0\n0\n1\n1\n0\n0\n0\n\n\nFeb-13\n0\n0\n0\n0\n0\n0\n-0.25\n\n\nMar-13\n-1\n-1\n-1\n-1\n0\n0\n0\n\n\nApr-13\n1\n1\n0\n-1\n0\n0\n0\n\n\nMay-13\n0\n0\n1\n1\n1\n0\n0\n\n\nJun-13\n-1\n-1\n-1\n-1\n-1\n0\n0\n\n\nJul-13\n1\n1\n1\n0\n0\n0\n0\n\n\nAug-13\n0\n0\n0\n1\n1\n1\n0\n\n\nSep-13\n0\n-1\n-1\n-1\n-1\n-1\n0\n\n\nOct-13\n0\n1\n1\n1\n0\n0\n0\n\n\nNov-13\n0\n0\n0\n0\n1\n1\n0\n\n\nDec-13\n0\n0\n-1\n-1\n-1\n-1\n0\n\n\n\n\n\nMean and seasonal effects of calendar variables\nThe calendar effects produced by the regression variables that fulfil the definition presented above include a mean effect (i.e. an effect that is independent of the period) and a seasonal effect (i.e. an effect that is dependent of the period and on average it is equal to 0). Such an outcome is inappropriate, as in the usual decomposition of a series the mean effect should be allocated to the trend component and the fixed seasonal effect should be affected to the corresponding component. Therefore, the actual calendar effect should only contain effects that don’t belong to the other components.\nIn the context of JDemetra+ the mean effect and the seasonal effect are long term theoretical effects rather than the effects computed on the time span of the considered series (which should be continuously revised).\nThe mean effect of a calendar variable is the average number of days in its group. Taking into account that one year has on average 365.25 days, the monthly mean effects for a working days are, as shown in the table below, 21.7411 for week days and 8.696 for weekends.\nMonthly mean effects for the Working day variable\n\n\n\nGroups of Working day effect\nMean effect\n\n\n\n\nWeek days\n365.25/12*5/7 = 21.7411\n\n\nWeekends\n365.25/12*2/7 = 8.696\n\n\nTotal\n365.25/12 = 30.4375\n\n\n\nThe number of days by period is highly seasonal, as apart from February, the length of each month is the same every year. For this reason, any set of calendar variables will contain, at least in some variables, a significant seasonal effect, which is defined as the average number of days by period (Januaries..., first quarters...) outside the mean effect. Removing that fixed seasonal effects consists of removing for each period the long term average of days that belong to it. The calculation of a seasonal effect for the working days classification is presented in the table below.\nThe mean effect and the seasonal effect for the calendar periods\n\n\n\n\n\n\n\n\n\n\nPeriod\nAverage number of days\nAverage number of week days\nMean effect\nSeasonal effect\n\n\n\n\nJanuary\n31\n31*5/7=22.1429\n21.7411\n0.4018\n\n\nFebruary\n28.25\n28.25*5/7=20.1786\n21.7411\n-1.5625\n\n\nMarch\n31\n31*5/7=22.1429\n21.7411\n0.4018\n\n\nApril\n30\n30*5/7=21.4286\n21.7411\n-0.3125\n\n\nMay\n31\n31*5/7=22.1429\n21.7411\n0.4018\n\n\nJune\n30\n30*5/7=21.4286\n21.7411\n-0.3125\n\n\nJuly\n31\n31*5/7=22.1429\n21.7411\n0.4018\n\n\nAugust\n31\n31*5/7=22.1429\n21.7411\n0.4018\n\n\nSeptember\n30\n30*5/7=21.4286\n21.7411\n-0.3125\n\n\nOctober\n31\n31*5/7=22.1429\n21.7411\n0.4018\n\n\nNovember\n30\n30*5/7=21.4286\n21.7411\n-0.3125\n\n\nDecember\n31\n31*5/7=22.1429\n21.7411\n0.4018\n\n\nTotal\n365.25\n260.8929\n260.8929\n0\n\n\n\nFor a given time span, the actual calendar effect for week days can be easily calculated as the difference between the number of week days in a specific period and the sum of the mean effect and the seasonal effect assigned to this period, as it is shown in the table below for the period 01.2013 – 06.2013.\nThe calendar effect for the period 01.2013 - 06.2013\n\n\n\n\n\n\n\n\n\n\nTime period (t)\nWeek days\nMean effect\nSeasonal effect\nCalendar effect\n\n\n\n\nJan-2013\n23\n21.7411\n0.4018\n0.8571\n\n\nFeb-2013\n20\n21.7411\n-1.5625\n-0.1786\n\n\nMar-2013\n21\n21.7411\n0.4018\n-1.1429\n\n\nApr-2013\n22\n21.7411\n-0.3125\n0.5714\n\n\nMay-2013\n23\n21.7411\n0.4018\n0.8571\n\n\nJun-2013\n20\n21.7411\n-0.3125\n-1.4286\n\n\nJul-2013\n23\n21.7411\n0.4018\n0.8571\n\n\n\nThe distinction between the mean effect and the seasonal effect is usually unnecessary. Those effects can be considered together (simply called mean effects) and be computed by removing from each calendar variable its average number of days by period. These global means effect are considered in the next section.\n\n\nImpact of the mean effects on the decomposition\nWhen the ARIMA model contains a seasonal difference – something that should always happen with calendar variables – the mean effects contained in the calendar variables are automatically eliminated, so that they don’t modify the estimation. The model is indeed estimated on the series/regression variables after differencing. However, they lead to a different linearised series (\\(y_{\\text{lin}})\\). The impact of other corrections (mean and/or fixed seasonal) on the decomposition is presented in the next paragraph. Such corrections could be obtained, for instance, by applying other solutions for the long term corrections or by computing them on the time span of the series.\nNow the model with “correct” calendar effects (denoted as \\(C\\)), i.e. effects without mean and fixed seasonal effects, can be considered. To simplify the problem, the model has no other regression effects.\nFor such a model the following relations hold:\n\\[y_{\\text{lin}} = \\ y - C\\]\n\\[T = \\ F_{T}\\left( y_{\\text{lin}} \\right)\\]\n\\[S = \\ F_{S}\\left( y_{\\text{lin}} \\right) + C\\]\n\\[I = \\ F_{I}\\left( y_{\\text{lin}} \\right)\\]\nwhere:\nT - the trend;\nS - the seasonal component;\nI - the irregular component;\n\\(F_{X}\\) - the linear filter for the component X.\nConsider next other calendar effects (\\(\\widetilde{C}\\)) that contain some mean (\\(\\text{cm}\\), integrated to the final trend) and fixed seasonal effects (\\(\\text{cs}\\), integrated to the final seasonal). The modified equations are now:\n\\[\\widetilde{C} = C + cm + cs\\]\n\\[{\\widetilde{y}}_{\\text{lin}} = \\ y - \\widetilde{C} = \\ y_{\\text{lin}} - cm - cs\\]\n\\[\\widetilde{T} = \\ F_{T}\\left( {\\widetilde{y}}_{\\text{lin}} \\right) + cm\\]\n\\[\\widetilde{S} = \\ F_{S}\\left( {\\widetilde{y}}_{\\text{lin}} \\right) + C + cs\\]\n\\[\\widetilde{I} = \\ F_{I}\\left( {\\widetilde{y}}_{\\text{lin}} \\right)\\]\nTaking into account that \\(F_{X}\\) is a linear transformation and that1\n\\[F_{T}\\left( \\text{cm} \\right) = cm\\]\n\\[F_{T}\\left( \\text{cs} \\right) = 0\\]\n\\[F_{S}\\left( \\text{cm} \\right) = 0\\ \\]\n\\[F_{S}\\left( \\text{cs} \\right) = cs\\]\n\\[F_{I}\\left( \\text{cm} \\right) = 0\\]\n\\[F_{I}\\left( \\text{cs} \\right) = 0\\]\nThe following relationships hold:\n\\[\\widetilde{T} = \\ F_{T}\\left( {\\widetilde{y}}_{\\text{lin}} \\right) + cm = F_{T}\\left( y_{\\text{lin}} \\right) - cm + cm = T\\]\n\\[\\widetilde{S} = \\ F_{S}\\left( {\\widetilde{y}}_{\\text{lin}} \\right) + C + cs = F_{S}\\left( y_{\\text{lin}} \\right) - cs + C + cs = S\\]\n\\[\\widetilde{I} = \\ I\\]\nIf we don’t take into account the effects and apply the same approach as in the “correct” calendar effects, we will get:\n\\[\\breve{T} = \\ F_{T}\\left( {\\widetilde{y}}_{\\text{lin}} \\right) = T - cm\\]\n\\[\\breve{S} = \\ F_{S}\\left( {\\widetilde{y}}_{\\text{lin}} \\right) + \\widetilde{C} = S + cm\\]\n\\[\\breve{I} = \\ F_{I}\\left( {\\widetilde{y}}_{\\text{lin}} \\right) = I\\]\nThe trend, seasonal and seasonally adjusted series will only differ by a (usually small) constant.\nIn summary, the decomposition does not depend on the mean and fixed seasonal effects used for the calendar effects, provided that those effects are integrated in the corresponding final components. If these corrections are not taken into account, the main series of the decomposition will only differ by a constant.\n\n\nLinear transformations of the calendar variables\nAs far as the RegARIMA and the TRAMO models are considered, any non-degenerated linear transformation of the calendar variables can be used. It will produce the same results (likelihood, residuals, parameters, joint effect of the calendar variables, joint F-test on the coefficients of the calendar variables…). The linearised series that will be further decomposed is invariant to any linear transformation of the calendar variables.\nHowever, it should be mentioned that choices of calendar corrections based on the tests on the individual t statistics are dependent on the transformation, which is rather arbitrary. This is the case in old versions of TRAMO-SEATS. That is why the joint F-test (as in the version of TRAMO-SEATS implemented in TSW+) should be preferred.\nAn example of a linear transformation is the calculation of the contrast variables. In the case of the usual trading day variables, they are defined by the following transformation: the 6 contrast variables (\\(\\text{No.}\\left( \\text{Mondays} \\right) - No.\\left( \\text{Sundays} \\right),\\ldots No.\\left( \\text{Saturdays} \\right) - No.(Sundays)\\)) used with the length of period.\n\\[\\begin{bmatrix}                 \n  1 & 0 & 0 & 0 & 0 & 0 & - 1 \\\\    \n  0 & 1 & 0 & 0 & 0 & 0 & - 1 \\\\    \n  0 & 0 & 1 & 0 & 0 & 0 & - 1 \\\\    \n  0 & 0 & 0 & 1 & 0 & 0 & - 1 \\\\    \n  0 & 0 & 0 & 0 & 1 & 0 & - 1 \\\\    \n  0 & 0 & 0 & 0 & 0 & 1 & - 1 \\\\    \n  1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\      \n  \\end{bmatrix}\\begin{bmatrix}      \n  \\text{Mon} \\\\                     \n  \\text{Tue} \\\\                     \n  \\text{Wed} \\\\                     \n  \\text{Thu} \\\\                     \n  \\text{Fri} \\\\                     \n  \\text{Sat} \\\\                     \n  \\text{Sun} \\\\                     \n  \\end{bmatrix} = \\begin{bmatrix}   \n  Mon - Sun \\\\                      \n  Tue - Sun \\\\                      \n  Wed - Sun \\\\                      \n  Thu - Sun \\\\                      \n  Fri - Sun \\\\                      \n  Sat - Sun \\\\                      \n  \\text{Length of period} \\\\      \n  \\end{bmatrix}\\]\nFor the usual working day variables, two variables are used: one contrast variable and the length of period\n\\[\\begin{bmatrix}                  \n  1 & - \\frac{5}{2} \\\\              \n  1 & 1 \\\\                          \n  \\end{bmatrix}\\begin{bmatrix}      \n  \\text{Week} \\\\                    \n  \\text{Weekend} \\\\                 \n  \\end{bmatrix} = \\begin{bmatrix}   \n  \\text{Contrast week} \\\\          \n  \\text{Length of period} \\\\      \n  \\end{bmatrix}\\]\nThe \\(\\text{Length of period}\\) variable is defined as a deviation from the length of the month (in days) and the average month length, which is equal to \\(30.4375.\\) Instead, the leap-year variable can be used here (see Regression sections in RegARIMA or Tramo)2.\nSuch transformations have several advantages. They suppress from the contrast variables the mean and the seasonal effects, which are concentrated in the last variable. So, they lead to fewer correlated variables, which are more appropriate to be included in the regression model. The sum of the effects of each day of the week estimated with the trading (working) day contrast variables cancel out.\n\n\nHandling of specific holidays\ncheck vs GUI (v3) and rjd3\nThree types of holidays are implemented in JDemetra+:\n\nFixed days, corresponding to the fixed dates in the year (e.g. New Year, Christmas).\nEaster related days, corresponding to the days that are defined in relation to Easter (e.g. Easter +/- n days; example: Ascension, Pentecost).\nFixed week days, corresponding to the fixed days in a given week of a given month (e.g. Labor Day celebrated in the USA on the first Monday of September).\n\nFrom a conceptual point of view, specific holidays are handled in exactly the same way as the other days. It should be decided, however, to which group of days they belong. Usually they are handled as Sundays. This convention is also used in JDemetra+. Therefore, except if the holiday falls on a Sunday, the appearance of a holiday leads to correction in two groups, i.e. in the group that contains the weekday, in which holiday falls, and the group that contains the Sundays.\nCountry specific holidays have an impact on the mean and the seasonal effects of calendar effects. Therefore, the appropriate corrections to the number of particular days (which are usually the basis for the definition of other calendar variables) should be applied, following the kind of holidays. These corrections are applied to the period(s) that may contain the holiday. The long term corrections in JDemetra+ don’t take into account the fact that some moving holidays could fall on the same day (for instance the May Day and the Ascension). However, those events are exceptional, and their impact on the final result is usually not significant.\n\nFixed day\nThe probability that the holiday falls on a given day of the week is 1/7. Therefore, the probability to have 1 day more that is treated like Sunday is 6/7. The effect on the means for the period that contains the fixed day is presented in the table below (the correction on the calendar effect has the opposite sign).\nThe effect of the fixed holiday on the period, in which it occurred\n\n\n\nSundays\nOthers days\nContrast variables\n\n\n\n\n+ 6/7\n- 1/7\n1/7 - (+ 6/7)= -1\n\n\n\n\n\nEaster related days\nEaster related days always fall the same week day (denoted as Y in the table below: The effects of the Easter Sunday on the seasonal means). However, they can fall during different periods (months or quarters). Suppose that, taking into account the distribution of the dates for Easter and the fact that this holiday falls in one of two periods, the probability that Easter falls during the period \\(m\\) is \\(p\\), which implies that the probability that it falls in the period \\(m + 1\\) is \\(1 - p\\). The effects of Easter on the seasonal means are presented in the table below.\nThe effects of the Easter Sunday on the seasonal means\n|Period | Sundays Days X Others days Contrast Y Other contrasts |————| ————- ———— —————– ——————- ——————— |m |+ p - p 0 - 2p - p |m+1 | + (1-p) - (1-p) 0 - 2\\(\\times\\)(1-p) - (1-p)\nThe distribution of the dates for Easter may be approximated in different ways. One of the solutions consists of using some well-known algorithms for computing Easter on a very long period. JDemetra+ provides the Meeus/Jones/Butcher’s and the Ron Mallen’s algorithms (they are identical till year 4100, but they slightly differ after that date). Another approach consists in deriving a raw theoretical distribution based on the definition of Easter. It is the solution used for Easter related days. It is shortly explained below.\nThe date of Easter in the given year is the first Sunday after the full moon (the Paschal Full Moon) following the northern hemisphere’s vernal equinox. The definition is influenced by the Christian tradition, according to which the equinox is reckoned to be on 21 March3 and the full moon is not necessarily the astronomically correct date. However, when the full moon falls on Sunday, then Easter is delayed by one week. With this definition, the date of Easter Sunday varies between 22 March and 25 April. Taking into account that an average lunar month is \\(29.530595\\) days the approximated distribution of Easter can be derived. These calculations do not take into account the actual ecclesiastical moon calendar.\nFor example, the probability that Easter Sunday falls on 25 March is 0.004838 and results from the facts that the probability that 25 March falls on a Sunday is \\(1/7\\) and the probability that the full moon is on 21 March, 22 March, 23 March or 24 March is \\(5/29.53059\\). The probability that Easter falls on 24 April is 0.01708 and results from the fact that the probability that 24 April is Sunday is \\(1/7\\) and takes into account that 18 April is the last acceptable date for the full moon. Therefore the probability that the full moon is on 16 April or 17 April is \\(1/29.53059\\) and the probability that the full moon is on 18 April is \\(1.53059/29.53059\\).\nThe approximated distribution of Easter dates\n\n\n\nDay\nProbability\n\n\n\n\n22 March\n1/7 * 1/29.53059\n\n\n23 March\n1/7 * 2/29.53059\n\n\n24 March\n1/7 * 3/29.53059\n\n\n25 March\n1/7 * 4/29.53059\n\n\n26 March\n1/7 * 5/29.53059\n\n\n27 March\n1/7 * 6/29.53059\n\n\n28 March\n1/29.53059\n\n\n29 March\n1/29.53059\n\n\n…\n…\n\n\n18 April\n1/29.53059\n\n\n19 April\n1/7 * (6 + 1.53059)/29.53059\n\n\n20 April\n1/7 * (5 + 1.53059)/29.53059\n\n\n21 April\n1/7 * (4 + 1.53059)/29.53059\n\n\n22 April\n1/7 * (3 + 1.53059)/29.53059\n\n\n23 April\n1/7 * (2 + 1.53059)/29.53059\n\n\n24 April\n1/7 * (1 + 1.53059)/29.53059\n\n\n25 April\n1/7 * 1.53059/29.53059\n\n\n\n\n\nFixed week days\nFixed week days always fall on the same week day (denoted as Y in the table below) and in the same period. Their effect on the seasonal means is presented in the table below.\nThe effect of the fixed week holiday on the period, in which it occurred\n\n\n\nSundays\nDay Y\nOthers days\n\n\n\n\n+ 1\n- 1\n0\n\n\n\nThe impact of fixed week days on the regression variables is zero because the effect itself is compensated by the correction for the mean effect.\n\n\n\nHolidays with a validity period\nWhen a holiday is valid only for a given time span, JDemetra+ applies the long term mean corrections only on the corresponding period. However, those corrections are computed in the same way as in the general case.\nIt is important to note that using or not using mean corrections will impact in the estimation of the RegARIMA and TRAMO models. Indeed, the mean corrections do not disappear after differencing. The differences between the SA series computed with or without mean corrections will no longer be constant.\n\n\nDifferent Kinds of calendars\nsee link with GUI\nThis scenario presents how to define different kinds of calendars. These calendars can be applied to the specifications that take into account country-specific holidays and can be used for detecting and estimating the calendar effects.\nThe calendar effects are those parts of the movements in the time series that are caused by different number of weekdays in calendar months (or quarters). They arise as the number of occurrences of each day of the week in a month (or a quarter) differs from year to year. These differences cause regular effects in some series. In particular, such variation is caused by a leap year effect because of an extra day inserted into February every four years. As with seasonal effects, it is desirable to estimate and remove calendar effects from the time series.\nThe calendar effects can be divided into a mean effect, a seasonal part and a structural part. The mean effect is independent from the period and therefore should be allocated to the trend-cycle. The seasonal part arises from the properties of the calendar that recur each year. For one thing, the number of working days of months with 31 calendar days is on average larger than that of months with 30 calendar days. This effect is part of the seasonal pattern captured by the seasonal component (with the exception of leap year effects). The structural part of the calendar effect remains to be determined by the calendar adjustment. For example, the number of working days of the same month in different years varies from year to year.\nBoth X-12-ARIMA/X-13ARIMA-SEATS and TRAMO/SEATS estimate calendar effects by adding some regressors to the equation estimated in the pre-processing part (RegARIMA or TRAMO, respectively). Regressors mentioned above are generated from the default calendar or the user defined calendar.\nThe calendars of JDemetra+ simply correspond to the usual trading days contrast variables based on the Gregorian calendar, modified to take into account some specific holidays. Those holidays are handled as “Sundays” and the variables are properly adjusted to take into account the long term mean effects.\n\n\nTests for residual trading days\nWe consider below tests on the seasonally adjusted series (\\(sa_t\\)) or on the irregular component (\\(irr_t\\)). When the reasoning applies on both components, we will use \\(y_t\\). The functions \\(stdev\\) stands for “standard deviation” and \\(rms\\) for “root mean squares”\nThe tests are computed on the log-transformed components in the case of multiplicative decomposition.\nTD are the usual contrasts of trading days, 6 variables (no specific calendar).\n\nNon significant irregular\nWhen \\(irr_t\\) is not significant, we don’t compute the test on it, to avoid irrelevant results. We consider that \\(irr_t\\) is significant if \\(stdev( irr_t)&gt;0.01\\) (multiplicative case) or if \\(stdev(irr_t)/rms(sa_t) &gt;0.01\\) (additive case).\n\n\nF test\nThe test is the usual joint F-test on the TD coefficients, computed on the following models:\n\nAutoregressive model (AR modelling option)\nWe compute by OLS:\n\\[y_t=\\mu + \\alpha y_{t-1} + \\beta TD_t + \\epsilon_t \\]\n\n\nDifference model\nWe compute by OLS:\n\\[\\Delta y_t - \\overline{\\Delta y_t}=\\beta TD_t + \\epsilon_t \\]\nSo, the latter model is a restriction of the first one (\\(\\alpha =1, \\mu =μ=\\overline{\\Delta y_t}\\))\nThe tests are the usual joint F-tests on \\(\\beta \\quad (H_0:\\beta=0)\\).\nBy default, we compute the tests on the 8 last years of the components, so that they might highlight moving calendar effects.\nRemark:\nIn Tramo, a similar test is computed on the residuals of the Arima model. More exactly, the F-test is computed on \\(e_t=\\beta TD_t + \\epsilon_t\\), where \\(e_t\\) are the one-step-ahead forecast errors."
  },
  {
    "objectID": "A-calendar-correction.html#regressors-for-calendar-correction",
    "href": "A-calendar-correction.html#regressors-for-calendar-correction",
    "title": "Calendar and user-defined corrections",
    "section": "Regressors for calendar correction",
    "text": "Regressors for calendar correction\nunlike seasonality, calendar effects are corrected via regressors here we’ll see how to build them\nit always start with building a calendar (or using a default one) which will allow to take holidays into account, this is described here\nthen regrssors will be bulit from calendars + info on distinguishing several types of days (more or less), mondays…\nseveral cases, as regressors have the same data granularity as the input series\n\ndaily series : dummies for holidays, type of day in p=7\nmonthly and quaterly series : regressors = aggregated indicators holidays are grouped with one day, and more or less groups\n\nthe goal is at the end to have regressors can be - built in\n\nexternal, completely user defined\n\nonce the calendar is defined the corresponding regressors can be generated and used in gui in R\n\nCustomizing calendars\nThere are three ways to build customized calendars taking into account national holidays\n- In the Graphical User Interface \nThe resulting calendar will allow to generate customized regressors which can then be added while running a seasonal adjustment processing The customized calendar can be directly linked to the calendar correction option in GUI while running a seasonal adjustment processing (see SA chapter, link).\n- In R \nvia GUI (link) or in R (link).\n- Directly writing xml files \n\nPre-Defined Holidays\nA Special days list is pre-defined for most commonly occurring holidays.\n{: .table .table-style}\n  | **Holiday**    |    **Definition**| \n  ----------------- ----------------------------------------------------------------------------------------------------------------------------| \n |  New Year       |   Fixed holiday, falls on January, 1.| \n | Ash Wednesday   |   Moving holiday, occurring 46 days before Easter.| \n | Easter          |   Moving holiday, varies between March, 22 and April, 25.| \n |  Maundy Thursday|   Moving holiday, falls on the Thursday before Easter.| \n |  Good Friday    |   Moving holiday, falls on the Friday before Easter.| \n |  Easter Monday  |   Moving holiday, falls on the day after Easter.| \n |  Ascension Day  |   Moving holiday, celebrated on Thursday, 40 days after Easter.| \n |  Pentecost      |   Moving holiday, celebrated 50 days after Easter Sunday.| \n |  Whit Monday    |   Moving holiday, falling on the day after Pentecost.| \n |  May Day        |   Fixed holiday, falls on May, 1.| \n |  Assumption     |   Fixed holiday, falls on August, 15.| \n |  Halloween      |   Fixed holiday, falls on October, 31.| \n |  All Saints Day |   Fixed holiday, falls on November, 1.| \n |  Thanksgiving   |   Moving holiday, celebrated on the second Monday of October (Canada) or on the fourth Thursday of November (United States).| \n | Christmas Day   |   Fixed holiday, falls on December, 25.| \n\n\nIn GUI\n\nDefault Calendar\nIn the graphical user interface, calendars in are stored in the Workspace window in the Utilities section. In the default calendar, country-specific national holidays are not taken into account, it reflects only the usual composition of the weeks in the calendar periods.\n![Text](All_images/UG_CAL_image1.jpg)\n\n**The *Calendars* section in the *Workspace* window**\nTo view the details of the default calendar\n- double click on it\n\n![Text](All_images/UG_CAL_image2.jpg)\n\n**The default view of the default calendar**\n\n\nSet Properties\nIn the Properties panel the user can set:\n\nFrequency (monthly, quarterly..)\nTrading days or working days regressors\n\nTrading days: 6 contrast variables (\\(number\\ of\\ Mondays - number\\ of\\ Sundays\\),…) and one regressor for the leap year effect.\nWorking Days: 1 contrast variable (\\(number\\ of\\ working days (monday to friday) - number\\ of\\ Saturdays and Sundays\\),…) and one regressor for the leap year effect.\n\n\n\nText\n\n\nModification of the initial settings for the Default calendar\n\n\nSpectrum visualization\nThe top-right panel displays the spectrum for the given calendar variable. By default, the first variable from the table is shown.\n\nTo change it, click on the calendar variable header.\n\nCalendar variables shouldn’t have a peak neither at a zero frequency (trend) nor the seasonal frequencies.\n #### Modify an existing Calendar\n\nclick the option Edit from the context menu\nthe list of holidays defined for this calendar is displayed\n\n\n\n\nText\n\n\nEdit a calendar window\n\nTo add a holiday unfold the + menu\nTo remove a holiday click on it and choose the - button \n\nRemoving a holiday from the calendar\n\n\nCreating a new calendar\nAn appropriate calendar, containing the required national holidays, needs to be created to adjust a series for country-specific calendar effects.\n\nright click on the Calendar item from the Workspace window and choose Add\n\n\n\n\nText\n\n\nThree options are available:\n\nNational calendars: allows to include country-specific holidays\nComposite calendars : creates calendar as a weighted sum of several national calendars\nChained calendars : allows to chain two national calendars before and after a break\n\n\n\nNational Calendar\nTo define a national calendar: right click on Calendar item in the Utility panel of the workspace window\n\n\n\nText\n\n\n\nTo add a holiday unfold the + menu\nTo remove a holiday from the list click on it and choose the - button.\n\n\n\n\nText\n\n\nFour options are available here:\n- **Fixed** : holiday occurring at the same date\n\n- **Easter Related**: holiday that depends on Easter Sunday date\n\n- **Fixed Week**: fixed holiday that always falls in a specific week of a given month\n\n- **Special Day**:  choose a holiday from a list of pre-defined holidays (link to table)\n\n\n\nText\n\n\n\nto use Julian Easter\n\n\n\n\nText\n\n\n**The \\*Julian Easter\\* option**\nTo add a holiday from this list to the national calendar, choose the Special day item from the Special days list.\n Adding a pre-defined holiday to the calendar\nBy default, when the Special Days option is selected, JDemetra+ always adds Christmas to the list of selected holidays. The user can change this initial choice by specifying the settings in the panel on the right and clicking OK. The settings that can be changed include:\n\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned.\nDay event: a list of pre-defined holidays (link to table)\nOffset: allows to set a holiday as related to a pre-specified holiday by specifying the distance in days (e.g Easter Sunday). Default offset is 1. It can be positive or negative. Positive offset: defines a holiday following the pre-specified holiday. Negative offset: defines a holiday preceding the selected pre-specified.\n Choosing a pre-defined holiday from the list\nTo define a fixed holiday not included in the list of pre-defined holidays:\n\nchoose Fixed from the Special days list: by default January, 1 is displayed. Specify the settings:\n\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned.\nDay: day of month when the fixed holiday is celebrated.\nMonth: month, in which the fixed holiday is celebrated.\n\n\n\n\nText\n\n\nOptions for a fixed holiday\n\nAdd Corpus Christi: example of an Easter related holiday not included in the special day list(link to table). It is is a moving holiday celebrated 60 days after Easter\n\nchoose the Easter related item from the Special days list.\n\n By default Easter + 1 is displayed. Setting can be changed :\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned.\nOffset: To define Corpus Christi enter 60, as it is celebrated 60 days after Easter Sunday.\n\n\n\n\nText\n\n\n\nFixed week option: when dealing with holidays occurring on the same week of a given month. Example: Labour Day in the USA and Canada, celebrated on the first Monday of September in Canada\n\nchoose Fixed Week from the Special days list.\n\n\n\n\nText\n\n\n\nAvailable settings are:\n\nStart: starting date for the holiday (expecting yyyy-mm-dd) Default is the starting date of the calendar (empty cell).\nEnd: same as start\nWeight : specifies the impact of the holiday on the series. The default weight is 1 (full weight) assuming that the influence of the holiday is the same as a regular Sunday. If less the a value between 0 and 1 can be assigned\nDay of Week: day of week when the holiday is celebrated each year\nMonth: month, in which the holiday is celebrated each year\nWeek: number denoting the place of the week in the month: between 1 and 5\n\n\n\n\nText\n\n\nThe list of the holidays should contain only unique entries. Otherwise, a warning, as shown in the picture below, will be displayed.\n\n\n\nText\n\n\nA calendar without a name cannot be saved. Fill the Name box before saving the calendar.\n\n\n\nText\n\n\nExample : final view of a properly defined calendar for Poland\n\n\n\nText\n\n\nThe calendar is visible in the Workspace window\n\nTo display the available options right-click on it\n\nA national calendar can be edited, duplicated (to create another calendar) and/or analysed (double click to display it in the panel on the right) or deleted.\n\n\nChained Calendar\nCreating a chained calendar is relevant when a major break occurs in the definition of the country-specific holidays.\nFirst define the 2 (or \\(N\\)) national calendars corresponding to each regime as explained in the section above.\nTo define a chained calendar: right click on Calendar item in the Utility panel of the workspace window\n\n\n\nText\n\n\nIn the Properties panel specify:\n\nfirst and the second calendar\nbreak date\n\n\n\n\nText\n\n\n\n\nComposite Calendar\nCreating a chained calendar is relevant when correcting series which include data from more than one country/region. This option can be used, for example, to create the calendar for the European Union or to create the national calendar for a country, in which regional holidays are celebrated.\nFirst define the relevant national calendars corresponding to each member state/region as explained above.\nTo define a chained calendar: right click on Calendar item in the Utility panel of the workspace window\n\n\n\nText\n\n\n\nFill the name box\nMark the regional calendars to be used\nAssign a weight to each calendar.\n\n\n\n\nText\n\n\n\n\nImporting an existing calendar from a file\nRight click on the Calendar item from the Workspace window and choose the Import item from the menu.\n\n\n\nText\n\n\nImporting a calendar to JDemetra+\n\nchoose the appropriate file and open it\n\n\n\n\nText\n\n\nChoosing the file\nJDemetra+ adds it to the calendars list\n\n\n\nText\n\n\nA list of calendars with a newly imported calendar\n\n\nExample of a calendar file\nexample of a html file containing a calendar\n #### In R\nIn version 2 (RJDemetra), not possible to build calendars and generate regressors with jd+. Two approaches\n\nuse built in regressors (wd or td) not taking into account national holidays\nimport externally generated user defined calendar\n\n(link to how to plug this in into a spec)\nin version 3 new functionalities\n\n\nBuilding calendar\n(time series, data frequency will be taken into account later…) give an overview of the process beforehand\nstep 1: defining a calendar\n\ndefinition of days 3 functions ‘fixed_day’ and ‘fixed_week_day’ and ‘easter add a ’single_day’ also pre-defined special day ‘special_day’, eleven pre-.. events\na list of day constitutes a calendar\n\nhere above: national calendar equivalent of\n\n\ngenerating regressors\n\nnormal\n\n\neaster effect"
  },
  {
    "objectID": "A-calendar-correction.html#footnotes",
    "href": "A-calendar-correction.html#footnotes",
    "title": "Calendar and user-defined corrections",
    "section": "",
    "text": "In case of SEATS the properties can be trivially derived from the matrix formulation of signal extraction. They are also valid for X-11 (additive).↩︎\nGÓMEZ, V., and MARAVALL, A (2001b).↩︎\nIn fact, astronomical observations show that the equinox occurs on 20 March in most years.↩︎"
  },
  {
    "objectID": "A-benchmarking.html#benchmarking-overview",
    "href": "A-benchmarking.html#benchmarking-overview",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Benchmarking overview",
    "text": "Benchmarking overview\nOften one has two (or multiple) datasets of different frequency for the same target variable. Sometimes, however, these data sets are not coherent in the sense that they don’t match up. Benchmarking[^1] is a method to deal with this situation. An aggregate of a higher-frequency measurement variables is not necessarily equal to the corresponding lower-frequency less-aggregated measurement. Moreover, the sources of data may have different reliability levels. Usually, less frequent data are considered more trustworthy as they are based on larger samples and compiled more precisely. The more reliable measurements, hence often the less frequent, will serve as benchmark.\nIn seasonal adjustment methods benchmarking is the procedure that ensures the consistency over the year between adjusted and non-seasonally adjusted data. It should be noted that the [ESS Guidelines on Seasonal Adjustment (2015)] (https://ec.europa.eu/eurostat/documents/3859598/6830795/KS-GQ-15-001-EN-N.pdf/d8f1e5f5-251b-4a69-93e3-079031b74bd3), do not recommend benchmarking as it introduces a bias in the seasonally adjusted data. The U.S. Census Bureau also points out that “forcing the seasonal adjustment totals to be the same as the original series annual totals can degrade the quality of the seasonal adjustment, especially when the seasonal pattern is undergoing change. It is not natural if trading day adjustment is performed because the aggregate trading day effect over a year is variable and moderately different from zero”[^2]. Nevertheless, some users may need that the annual totals of the seasonally adjusted series match the annual totals of the original, non-seasonally adjusted series[^3].\nAccording to the [ESS Guidelines on Seasonal Adjustment (2015)] (https://ec.europa.eu/eurostat/documents/3859598/6830795/KS-GQ-15-001-EN-N.pdf/d8f1e5f5-251b-4a69-93e3-079031b74bd3), the only benefit of this approach is that there is consistency over the year between adjusted and the non-seasonally adjusted data; this can be of particular interest when low-frequency (e.g. annual) benchmarking figures officially exist (e.g. National Accounts, Balance of Payments, External Trade, etc.) and where users’ needs for time consistency are stronger."
  },
  {
    "objectID": "A-benchmarking.html#tools",
    "href": "A-benchmarking.html#tools",
    "title": "Benchmarking and temporal disagreggation",
    "section": "Tools",
    "text": "Tools\n\nBenchmarking with GUI\n\nWith the pre-defined specifcations the benchmarking functionality is not applied by default following the ESS Guidelines on Seasonal Adjustment (2015) recommendations. It means that once the user has seasonally adjustd the series with a pre-defined specifcation the Benchmarking node is empty. To execute benchmarking click on the Specifications button and activate the checkbox in the Benchmarking section.\n\nBenchmarking option – a default view\nThree parameters can be set here. Target specifies the target variable for the benchmarking procedure. It can be either the Original (the raw time series) or the Calendar Adjusted (the time series adjusted for calendar effects). Rho is a value of the AR(1) parameter (set between 0 and 1). By default it is set to 1. Finally, Lambda is a parameter that relates to the weights in the regression equation. It is typically equal to 0 (for an additive decomposition), 0.5 (for a proportional decomposition) or 1 (for a multiplicative decomposition). The default value is 1.\nTo launch the benchmarking procedure click on the Apply button. The results are displayed in four panels. The top-left one compares the original output from the seasonal adjustment procedure with the result from applying a benchmarking to the seasonal adjustment. The bottom-left panel highlights the differences between these two results. The outcomes are also presented in a table in the top-right panel. The relevant statistics concerning relative differences are presented in the bottom-right panel.\n\nThe results of the benchmarking procedure\nBoth pictures and the table can be copied the usual way (see the Simple seasonal adjustment of a single time series scenario).\n\nOptions for benchmarking results\nTo export the result of the benchmarking procedure (benchmarking.result) and the target data (benchmarking.target) one needs to once execute the seasonal adjustment with benchmarking using the muli-processing option (see the Simple seasonal adjustment of multiple time series scenario. Once the muli-processing is executed, select the Output item from the SAProcessing menu.\n\nThe SAProcessing menu\nExpand the \"+\" menu and choose an appropriate data format (here Excel has been chosen). It is possible to save the results in TXT, XLS, CSV, and CSV matrix formats. Note that the available content of the output depends on the output type.\n\nExporting data to an Excel file\nChose the output items that refer to the results from the benchmarking procedure, move them to the window on the right and click OK.\n\nExporting the results of the benchmarking procedure\n\n\n\nBenchmarking in R\nSee package rjd3bench and its documentation pages in R."
  },
  {
    "objectID": "A-trend-cycle-estimation.html#overview",
    "href": "A-trend-cycle-estimation.html#overview",
    "title": "Trend-cycle estimation",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "A-trend-cycle-estimation.html#estimation-methods",
    "href": "A-trend-cycle-estimation.html#estimation-methods",
    "title": "Trend-cycle estimation",
    "section": "Estimation Methods",
    "text": "Estimation Methods"
  },
  {
    "objectID": "A-trend-cycle-estimation.html#tools",
    "href": "A-trend-cycle-estimation.html#tools",
    "title": "Trend-cycle estimation",
    "section": "Tools",
    "text": "Tools\n\nrjd3highfeq package\n\n\nrjdfilters package"
  },
  {
    "objectID": "A-nowcasting.html",
    "href": "A-nowcasting.html",
    "title": "Nowcasting",
    "section": "",
    "text": "Under construction."
  },
  {
    "objectID": "P_Tools.html",
    "href": "P_Tools.html",
    "title": "Tools",
    "section": "",
    "text": "The different tools described in this part:\n\nGraphical User Interface GUI\n…enhanced with additional plug-ins\n..and a Cruncher for mass production\nR packages"
  },
  {
    "objectID": "T-graphical-user-interface.html#overview",
    "href": "T-graphical-user-interface.html#overview",
    "title": "Graphical User Interface",
    "section": "Overview",
    "text": "Overview\nThis chapter provides general information about using the graphical interface (GUI). Specific indications related to a given algorithm (X13-Arima, Tramo-seats, Benchmarking…) are displayed in the relevant chapters."
  },
  {
    "objectID": "T-graphical-user-interface.html#available-algorithms",
    "href": "T-graphical-user-interface.html#available-algorithms",
    "title": "Graphical User Interface",
    "section": "Available algorithms",
    "text": "Available algorithms\nThe graphical user interface in the 2.x family gives access to:\n\nSeasonal adjustment (SA) algorithms\n\nX13-Arima\nTramo-Seats\nDirect-indirect SA comparisons\n\nOutlier detection (TERROR)\nBenchmarking\n\nThe graphical user interface in the 3.x family gives access in addition to extended SA algorithms for high-frequency data (HF) high-frequency data (HF)."
  },
  {
    "objectID": "T-graphical-user-interface.html#available-time-series-tools",
    "href": "T-graphical-user-interface.html#available-time-series-tools",
    "title": "Graphical User Interface",
    "section": "Available Time Series tools",
    "text": "Available Time Series tools\nThe graphical user interface in the 2.x and 3.x family give access to generic time series tools:\n\nGraphics\n\ntime domain\nspectral analysis\n\nTests\n\nseasonality tests\nautocorrelation, normality, randomness tests"
  },
  {
    "objectID": "T-graphical-user-interface.html#installation-procedure",
    "href": "T-graphical-user-interface.html#installation-procedure",
    "title": "Graphical User Interface",
    "section": "Installation Procedure",
    "text": "Installation Procedure\nJDemetra+ is a stand-alone application packed in a zip package. To run JDemetra+ the Java RE 8 or higher is needed. Java RE can be downloaded from Oracle website.\nThe official release of JDemetra+ is accessible at a dedicated Github page. The site presents all available releases - both official releases (labelled in green as latest releases) and pre-releases (labelled in red) - packed in zip packages. From the Latest release section either choose the installer appropriate for your operating system (Windows, Linux, Mac OS, Solaris) or take the portable zip-file. The installation process is straightforward and intuitive. For example, when the zip-file is chosen and downloaded, then under Windows OS the application can be found in the “bin”-folder of the installation/unpacked zip. To open an application, double click on nbdemetra.exe or nbdemetra64.exe depending on the system version (nbdemetra.exe for the 32-bit system version and nbdemetra64.exe for the 64-bit system version).\n\n\n\nLaunching JDemetra+\n\n\nIf the launching of JDemetra+ fails, you can try the following operations:\n\nCheck if Java SE Runtime Environment (JRE) is properly installed by typing in the following command in a terminal: java –version\nCheck the logs in your home directory:\n\n%appdata%/.nbdemetra/dev/var/log/ for Windows;\n~/.nbdemetra/dev/var/log/ for Linux and Solaris;\n~/Library/Application Support/.nbdemetra/dev/var/log/ for Mac OS X.\n\n\nIn order to remove a previously installed JDemetra+ version, the user should delete an appropriate JDemetra+ folder."
  },
  {
    "objectID": "T-graphical-user-interface.html#running-jdemetra",
    "href": "T-graphical-user-interface.html#running-jdemetra",
    "title": "Graphical User Interface",
    "section": "Running JDemetra+",
    "text": "Running JDemetra+\nTo open an application, navigate to the destination folder and double click on nbdemetra.exe or nbdemetra64.exe depending on the system version (nbdemetra.exe for the 32-bit system version and nbdemetra64.exe for the 64-bit system version).\n\n\n\nRunning JDemetra+"
  },
  {
    "objectID": "T-graphical-user-interface.html#closing-jdemetra",
    "href": "T-graphical-user-interface.html#closing-jdemetra",
    "title": "Graphical User Interface",
    "section": "Closing JDemetra+",
    "text": "Closing JDemetra+\nTo close the application, select File → Exit from the File menu.\n\n\n\nClosing JDemetra+\n\n\nThe other way is to click on the close box in the upper right-hand corner of the JDemetra+ window. If there is any unsaved work, JDemetra+ will display a warning and provide the user with the opportunity to save it. The message box is shown below.\n\n\n\nThe warning from leaving JDemetra+ without saving the workspace\n\n\nBELOW: menus and functions common to all the algos"
  },
  {
    "objectID": "T-graphical-user-interface.html#interface-starting-winwow",
    "href": "T-graphical-user-interface.html#interface-starting-winwow",
    "title": "Graphical User Interface",
    "section": "Interface Starting Winwow",
    "text": "Interface Starting Winwow\nThe default view of the JDemetra+ window, which is displayed after launching the program, is shown below.\n\n\n\nJDemetra+ default window\n\n\nBy default, on the left hand side of the window two panels are visible: the Workspace panel and the Providers panel. The Workspace panel stores the work performed by the user in a coherent and structured way. The Providers panel presents the list of the data sources and organizes the imported series within each data provider. By default, JDemetra+ supports the following data sources:\n\nJDBC;\nODBC;\nSDMX;\nExcel spreadsheets;\nTSW (input files for the Tramo-Seats-Windows application by the Bank of Spain);\nTXT;\nUSCB (input files for the X-13-ARIMA-SEATS application by the U.S. Census Bureau);\nXML.\n\nAll standard databases (Oracle, SQLServer, DB2, MySQL) are supported by JDemetra+ via JDBC, which is a generic interface to many relational databases. Other providers can be added by users by creating plugins. We will now focus on the Spreadsheets data source, which corresponds to the series prepared in an Excel file. The file should have dates in Excel date format. Dates should be placed in the first column (or in the first row) and titles of the series in the corresponding cell of the first row (or in the first column). The top-left cell \\(A1\\) can include text or it can be left empty. The empty cells are interpreted by JDemetra+ as missing values and they can appear at the beginning, in the middle and at the end of the time series. The example is shown below.\n\n\n\nExample of an Excel spreadsheet that can be imported to JDemetra+\n\n\nOnce the spreadsheet is prepared and saved, it can be imported to JDemetra+ as it is shown by the tutorial below.\n\nAn example of importing process for the Excel file\nThe default JDemetra+ window, which is displayed after launching the program, is clearly divided into several panels.\n\n\n\nJDemetra+ default view\n\n\nThe key parts of the user interface are:\n\nThe application menu.\nThe Providers window, which organises time series;\nThe Workspace window, which stores results generated by the software as well as settings used to create them;\nA central empty zone for presenting the actual analyses further called the Results panel."
  },
  {
    "objectID": "T-graphical-user-interface.html#widgets",
    "href": "T-graphical-user-interface.html#widgets",
    "title": "Graphical User Interface",
    "section": "Widgets",
    "text": "Widgets\n\nAll TS&view\n\n\nSearch option"
  },
  {
    "objectID": "T-graphical-user-interface.html#application-menus",
    "href": "T-graphical-user-interface.html#application-menus",
    "title": "Graphical User Interface",
    "section": "Top bar menus",
    "text": "Top bar menus\n(Application menu: all that is available from the top bar)\nThe majority of functionalities are available from the main application menu, which is situated at the very top of the main window. If the user moves the cursor to an entry in the main menu and clicks on the left mouse button, a drop-down menu will appear. Clicking on an entry in the drop-down menu selects the highlighted item.\n\n\n\nThe main menu with selected drop-down menu\n\n\nThe functions available in the main application menu are:\n\nFile\nStatistical methods\nX-13Doc\nRegArimaDoc\nTramoDoc\nTramoSeatsDoc\nView\nTools\nWindow\nHelp\n\n\nFile\nThe File menu is intended for working with workspaces and data sources. It offers the following functions:\n\nNew Workspace – creates a new workspace and displays it in the Workspace window with a default name (Workspace_#number);\nOpen Workspace – opens a dialog window, which enables the user to select and open an existing workspace;\nOpen Recent Workspace – presents a list of workspaces recently created by the user and enables the user to open one of them;\nSave Workspace – saves the project file named by the system under the default name (Workspace_#number) and in a default location. The workspace can be re-opened at a later time;\nSave Workspace As… – saves the current workspace under the name chosen by the user in the chosen location. The workspace can be re-opened at a later time;\nOpen Recent – presents a list of datasets recently used and enables the user to open one of them;\nExit – closes an application.\n\n\n\n\nThe content of the File menu\n\n\n\n\nStatistical Methods\nThe Statistical methods menu includes functionalities for modelling, analysis and the seasonal adjustment of a time series. They are divided into three groups:\n\nAnomaly Detection – allows for a purely automatic identification of regression effects;\nModelling – enables time series modelling using the TRAMO and RegARIMA models;\nSeasonal adjustment – intended for the seasonal adjustment of a time series with the TRAMO-SEATS and X-13ARIMA-SEATS methods.\n\n\n\n\nThe Statistical methods menu.\n\n\n\n\nView\nThe View menu contains functionalities that enable the user to modify how JDemetra+ is viewed. It offers the following items:\n\nSplit – the function is not operational in the current version of the software.\nToolbars – displays selected toolbars under the main menu. The File toolbar contains the Save all icon. The Performance toolbar includes two icons: one to show the performance of the application, the other to stop the application profiling and taking a snapshot. The Other toolbar determines the default behaviour of the program when the user double clicks on the data. It may be useful to plot the data, visualise it on a grid, or to perform any pre-specified action, e.g. execute a seasonal adjustment procedure.\nShow Only Editor – displays only the Results panel and hides other windows (e.g. Workspace and Providers).\nFull Screen – displays the current JDemetra+ view in full screen.\n\n\n\n\nThe View menu\n\n\n\n\nTools menu\nThe following functionalities are available from the Tools menu:\n\nContainer – includes several tools for displaying data in a time domain;\nSpectral analysis – contains tools for the analysis of a time series in a frequency domain;\nAggregation – enables the user to investigate a graph of the sum of multiple time series;\nDifferencing – allows for the inspection of the first regular differences of the time series;\nSpreadsheet profiler – offers an Excel-type view of the XLS file imported to JDemetra+.\nPlugins – allows for the installation and activation of plugins, which extend JDemetra+ functionalities.\nOptions – presents the default interface settings and allows for their modification.\n\n\n\n\nThe Tools menu\n\n\n\nContainer\nContainer includes basic tools to display the data. The following items are available: Chart, Grid, Growth Chart and List.\n\n\n\nThe Container menu\n\n\nSeveral containers can be opened at the same time. Each of them may include multiple time series.\nChart plots the time series as a graph. This function opens an empty window. To display a given series drag and drop the series from the Providers window into the empty window. More than one series can be displayed on one graph. The chart is automatically rescaled after adding a new series.\n\n\n\nLaunching the Chart functionality\n\n\nThe series to be viewed can be also dragged from the other windows (e.g. from the Variables window) or directly from the windows that display the results of the estimation procedure.\n\n\n\nDisplaying the seasonally adjusted series on a separate chart\n\n\nTo adjust the view of the chart and save it to a given location use the local menu, which is displayed after right-clicking on the chart. The explanation of the functions available for the local menu is given below.\n\n\n\nLocal menu basic options for the time series graph\n\n\nTo display the time series value at a given date, hover over it with the cursor. Once the time series is selected by clicking on it with the right mouse button, the options dedicated to this series are available.\n\n\n\nLocal menu options for chart\n\n\nA list of possible actions includes:\n\nOpen – opens selected time series in a new window that contains Chart and Grid panels.\nOpen with – opens the time series in a separate window according to the user choice (Chart & grid or Simple chart). The All ts views option is not currently available.\nSave – saves the marked series in a spreadsheet file or in a text file.\nRename – enables the user to change the time series name.\nFreeze – disables modifications of the chart.\nCopy – copies the series and allows it to be pasted to another application e.g. into Excel.\nPaste – pastes the time series previously marked.\nSplit into yearly components – opens a window that presents the analysed series data split by year. This chart is useful to investigate the differences in time series values caused by the seasonal factors as it gives some information on the existence and size of the deterministic and stochastic seasonality in data.\nRemove – removes a time series from the chart.\nSelect all – selects all the time series presented in the graph.\nShow title – option is not currently available.\nShow legend – displays the names of all the time series presented on the graph.\nEdit format – enables the user to change the data format.\nColor scheme – allows the colour scheme used in the graph to be changed.\nLines thickness – allows the user to choose between thin and thick lines to be used for a graph.\nClear – removes all the time series from the chart.\nShow all – this option is not currently available.\nExport image to – allows the graph to be sent to the printer and saved in the clipboard or as a file in a jpg format.\nConfigure – enables the user to customize the chart and series display.\n\nGrid enables the user to display the selected time series as a table. This function opens an empty window. To display a given series drag and drop the series from the Providers window into the empty window. More than one series can be displayed in one table.\n\n\n\nLaunching the Grid functionality\n\n\nTo display options available for a given time series, left click on any time series’ observation.\n\n\n\nLocal menu options for the Grid view\n\n\nThe options available in Grid are:\n\nTranspose – changes the orientation of the table from horizontal to vertical.\nReverse chronology – displays the series from the last to the first observation.\nSingle time series – removes from the table all time series apart from the selected one.\nUse color scheme – allows the series to be displayed in colour.\nShow bars – presents values in a table as horizontal bars.\nShow crosshair – highlights an active cell.\nZoom – option for modifying the chart size.\n\nWhen none of the series is selected, the local menu offers a reduced list of options. The explanation of the other options can be found below in the ‘Local menu options for chart’ figure in the Container section.\n\n\n\nA reduced list of options for Grid \n\n\nThe Growth chart tab opens an empty window. Once a given series is dropped into it, Growth chart presents the year-over-year or period-over-period growth rates for the selected time series. More than one series can be displayed in a table. The growth chart is automatically rescaled after adding a new series.\n\n\n\nThe Growth chart view with a local menu\n\n\nA left click displays a local menu with the available options. Those that are characteristic for the Growth chart are:\n\nKind – displays m/m (or q/q) and y/y growth rates for all time series in the chart (previous period and previous year options respectively). By default, the period-over-period growth rates are shown.\nEdit last year – for clarity and readability purposes, only five of the last years of observations are shown by default. This setting can be adjusted in the Options section, if required.\n\nThe explanation of other options can be found below in the ‘Local menu options for chart’ figure in the Container section.\nThe List tab provides basic information about the chosen time series, such as; the start and end date, the number of observations and a sketch of the data graph. This function opens an empty window. To display information, drag and drop the series from the Providers window into the List window. A right click displays the local menu with all available options. Apart from the standard options, the local menu for List enables marking the series that match the selected frequency (yearly, half-yearly, quarterly, monthly) by using the Select by frequency option. An explanation of other options can be found below in the ‘Local menu options for chart’ figure in the Container section.\n\n\n\nA view of a list of series\n\n\nFor a selected series a local menu offers an extended list of options. The explanation of the functions available for the local menu is given below in the ‘Local menu options for chart’ figure in the Container section.\n\n\n\nOptions available for a selected series from the list\n\n\n\n\nSpectral analysis\nThe Spectral analysis section provides three spectral graphs that allows an in-depth analysis of a time series in the frequency domain. These graphs are the Auto-regressive Spectrum, the Periodogram and the Tukey Spectrum. For more information the user may study a basic desription of spectral analysis and a detailed presentation of the abovementioned tools.\n\n\n\nTools for spectral analysis\n\n\n\n\nAggregation\nAggregation calculates the sum of the selected series and provides basic information about the selected time series, including the start and end date, the number of observations and a sketch of the data graph, in the same way as in the List functionality. Aggregation opens an empty window. To sum the selected series, drag and drop them from the Providers window into the Aggregation window. Right click displays the local menu with the available options. The content of the local menu depends on the panel chosen (the panel on the left that contains the list of the series and the panel on the right that presents the graph of an aggregate). The local menu for the list of series offers the option Select by frequency, which marks all the series on the list that are yearly, half-yearly, quarterly or monthly (depending on the user’s choice). The explanation of the other options can be found below in the ‘Local menu options for chart’ figure in the Container section. The local menu for the panel on the left offers functionalities that are analogous to the ones that are available for the List functionalities, while the options available for the local menu in the panel on the left are the same as the ones available in Chart (see Container).\n\n\n\nThe Aggregation tool\n\n\n\n\nDifferencing\nThe Differencing window displays the first regular differences for the selected time series together with the corresponding periodogram and the PACF function. By default, the window presents the results for non-seasonally and seasonally differenced series (( \\(d = 1,D = 1\\))). These settings can be changed through the Properties window (Tools → Properties). A description of a periodogram and the PACF function can be found here.\n\n\n\nThe properties of the Differencing tool\n\n\nThe typical results are shown below. The bottom left graph presents the partial autocorrelation coefficients (vertical bars) and the confidence intervals. The right-click local menu offers several functionalities for a differenced series. An explanation of the available options can be found below in the “Local menu options for chart” figure in the Container section.\n\n\n\nThe Differencing tool\n\n\nFor the Partial autocorrelation and the Periodogram panels the right-button menu offers “a copy series” option that allows data to be exported to another application and a graph to be printed and saved to a clipboard or as a jpg file. Information about the partial autocorrelation function is given here. The description of a periodogram is presented in the Spectral graphs scenario.\n\n\nSpreadsheet profiler\nThe Spreadsheet profiler offers an Excel-type view of the XLS file imported to JDemetra+. To use this functionality drag the file name from the Providers window and drop it to the empty Spreadsheet profiler window.\n\n\n\nThe Spreadsheet Profiler window\n\n\n\n\nPlugins\nInstallation an functionalities of plugins are described in the related chapter\n\n\nOptions\nThe Options window includes five main panels: Demetra, General, Keymap, Appearance and Miscellaneous. They are visible in the very top of the Options window.\n\n\n\nThe main sections of the Options window\n\n\nBy default, the Demetra tab is shown. It is divided into seven panels: Behaviour, Demetra UI, Statistics, Data transfer, Demetra Paths, ProcDocumentItems, and Interchange.\nBehaviour defines the default reaction of JDemetra+ to some of the actions performed by the user.\n\nProviders – an option to show only the data providers that are currently available.\nPersistence – an option to restore the data sources after re-starting the application so that there is no need to fetch them again (Persist opened DataSources) and an option to restore all the content of the chart and grid tools (Persist tools content).\nThreading – defines how resources are allocated to the computation (Batch Pool Size controls the number of cores used in parallel computation and Batch Priority defines the priority of computation over other processes). Changing these values might improve computation speed but also reduce user interface responsiveness.\nTime Series – determines the default behaviour of the program when the user double clicks on the data. It may be useful to plot the data, visualise it on a grid, or to perform any pre-specified action, e.g. execute a seasonal adjustment procedure.\n\n\n\n\nThe content of the Behavior tab\n\n\nThe Demetra UI tab enables the setting of:\n\nA default colour scheme for the graphs (Color scheme).\nThe data format (uses MS Excel conventions). For example, ###,###.#### implies the numbers in the tables and the y-axis of the graphs will be rounded up to four decimals after the decimal point (Data format).\nThe default number of last years of the time series displayed in charts representing growth rates (Growth rates).\nThe control of the view of the window for adding pre-specified outliers. (Pre-specified Outliers).\nThe visibility of the icons in the context menus (Context Menus).\n\n\n\n\nThe content of the Demetra UI tab\n\n\nThe Statistics tab includes options to control:\n\nThe number of years used for spectral analysis and for model stability (Default Number of Last Years);\nThe default pre-defined specification for seasonal adjustment (Seasonal Adjustment);\nThe type of the analysis of revision history (Revision History):\n\nFreeParameters – the RegARIMA model parameters and regression coefficients of the RegARIMA model will be re-estimated each time the end point of the data is changed. This argument is ignored if no RegARIMA model is fit to the series.\nComplete – the whole RegARIMA model together with regressors will be re-identified and re-estimated each time the end point of the data is changed. This argument is ignored if no RegARIMA model is fitted to the series.\nNone – the ARIMA parameters and regression coefficients of the RegARIMA model will be fixed throughout the analysis at the values estimated from the entire series (or model span).\n\nThe settings for the quality measures and tests used in a diagnostic procedure:\n\nDefault components – a list of series and diagnostics that are displayed in the SAProcessing \\(\\) Output window. The list of default items can be modified with the respective Select button (see figure below)\nDiagnostics – a list of diagnostics tests, where the user can modify the default settings (see figure “The panel for modification of the settings for the tests in the Basic checks section” below).\n\n\n\n\n\nThe Default components section on the Statistics tab\n\n\nAn explanation of the list of the series and diagnostics components that are displayed in the Default components section can be found here.\nTo modify the settings for a particular measure, double click on a selected row (select the test’s name from the list and click on the working tools button), introduce changes in the pop-up window and click the OK button.\nTo reset the default settings for a given test, select this test from the list and click on the backspace button situated below the working tools button. The description of the parameters for each quality measure and test used in a diagnostic procedure can be found in the output from modelling and the output from seasonal adjustement nodes.\n\n\n\nThe panel for modification of the settings for the tests in the Basic checks section\n\n\nThe users can customize the diagnostics and they can specify the default settings for different outputs. Their preferences are saved between different sessions of JDemetra+. This new feature is accessible in the Statistics tab of the Options panel.\n\n\n\nThe settings of the output files\n\n\nThe Data Transfer tab contains multiple options that define the behaviour of the drag and drop and copy-paste actions. To change the default settings, double click on the selected item. Once the modifications are introduced, confirm them with the OK button.\n\n\n\nThe content of the Data Transfer tab\n\n\nDemetra Paths allows the user to specify the relative location of the folders where the data can be found. In this way, the application can access data from different computers. Otherwise, the user would need to have access to the exact path where the data is located. To add a location, select the data provider, click the “+” button and specify the location.\n\n\n\nThe content of the Demetra Paths tab\n\n\nProcDocumentItems includes a list of all reports available for processed documents like seasonal adjustment. The Interchange tab lists the protocols that can be used to export/import information like calendars, specifications, etc. For the time being, the user cannot customize the way the standard exchanges are done. However, such features could be implemented in plug-ins.\nThe next section, General, allows for the customisation of the proxy settings. A proxy is an intermediate server that allows an application to access the Internet. It is typically used inside a corporate network where Internet access is restricted. In JDemetra+, the proxy is used to get time series from remote servers like .Stat.\n\n\n\nThe General tab\n\n\nKeymap provides a list of default key shortcuts to access some of the functionalities and it allows the user to edit them and to define additional shortcuts.\n\n\n\nThe Keymap tab\n\n\nThe Appearance and Miscellaneous tabs are tabs automatically provided by the Netbeans platform. They are not used by JDemetra+.\n\n\n\nWindow menu\nThe Window menu offers several functions that facilitate the analysis of data and enables the user to adjust the interface view to the user’s needs.\n\n\n\nThe Window menu\n\n\n\nPreview Time Series – opens a window that plots any of the series the user selects from Providers.\nDebug – opens a Preview Time Series window that enables a fast display of the graphs for time series from a large dataset. To display the graph click on the series in the Providers window.\nProviders – opens (if closed) and activates the Providers window.\nVariables – opens (if closed) and activates the Variable window.\nWorkspace – opens (if closed) and activates the Workspace window.\nOutput – a generic window to display outputs in the form of text; useful with certain plug-ins (e.g. tutorial descriptive statistics).\nEditor – activates the editor panel (and update the main menu consequently).\nConfigure Window – enables the user to change the way that the window is displayed (maximise, float, float group, minimise, minimise group). This option is active when some window is displayed in the JD+ interface.\nProperties – opens the Properties window and displays the properties of the marked item (e.g. time series, data source).\nReset Windows – restores the default JDemetra+ view.\nClose Window – closes all windows that are open.\nClose All Documents – closes all documents that are open.\nClose Other Documents – closes all documents that are open except for the one that is active (which is the last activated one).\nDocument Groups – enables the user to create and manage the document groups.\nDocuments – lists all documents that are active.\n\n\n\nHelp menu"
  },
  {
    "objectID": "T-graphical-user-interface.html#providers-window",
    "href": "T-graphical-user-interface.html#providers-window",
    "title": "Graphical User Interface",
    "section": "Providers window",
    "text": "Providers window\nThe Providers window presents the list of the data sources and organises the imported series within each data provider.\n\n\n\nThe Providers window\n\n\nThe allowed data sources include:\n\nJDBC;\nODBC;\nSDMX;\nSpreadsheets;\nTSW;\nTXT;\nUSCB;\nXML.\n\nAll standard databases (Oracle, SQLServer, DB2, MySQL) are supported by JDemetra+ via JDBC, which is a generic interface to many relational databases. Other providers can be added by users by creating plugins (see Plugins section in the Tools menu). To import data, right-click on the appropriate provider from the Providers panel and specify the required parameters. For all providers the procedure follows the same logic. An example is provided here.\nThe Providers window organises data in a tree structure reflecting the manner in which data are presented in the original source. The picture below presents how JDemetra+ visualises the imported spreadsheet file. If the user expands all the pluses under the spreadsheet all the series within each sheet that has been loaded are visible. Here two time series are visible: Japan (under the Asia branch) and United States (under the North America branch) while the Europe branch is still folded. The names of the time series have been taken from the column headings of the spreadsheet while the names of the branches come from sheets’ names.\n\n\n\nA structure of a dataset\n\n\nSeries uploaded to the Providers window can be displayed, modified and tested for seasonality and used in estimation routines (see Modelling and Seasonal adjustment). The data sources can be restored after re-starting the application so that there is no need to get them again. This functionality can be set in the Behaviour tab available at the Option item from the Tools menu.\n\nSpreadsheets\nThe Spreadsheets data source corresponds to the series prepared in the Excel file. The file should have true dates in the first column (or in the first row) and titles of the series in the corresponding cell of the first row (or in the first column). The top-left cell \\(A1\\) can include a text or it can be left empty. The empty cells are interpreted by JDemetra+ as missing values and they can appear in the beginning, in the middle and in the end of time series.\nAn example is presented below:\n\n\n\nExample of an Excel spreadsheet that can be imported to JDemetra+\n\n\nTime series are identified by their names. JDemetra+ derives some information (like data periodicity, starting and ending period) directly from the first column (or from the first row, depending on the chosen data orientation (vertical or horizontal)).\n\n\nImport data\nTo import data from a given data source, click on this data source in the Providers window shown below, choose Open option and specify the import details, such as a path to a data file. These details vary according to data providers. The example below show how to import the data from an Excel file.\n\nFrom the Providers window right-click on the Spreadsheets branch and choose Open option.\n\nThe Open data source window contains the following options:\n\nSpreadsheet file – a path to access the Excel file.\nData format – the data format used to read dates and values. It includes three fields: locale (country), date pattern (data format, e.g. yyyy-mm-dd), number pattern (a metaformat of numeric value, e.g. 0.## represents two digit number).\nFrequency – time series frequency. This can be undefined, yearly, half-yearly, four-monthly, quarterly, bi-monthly, or monthly. When the frequency is set to undefined, JDemetra+ determines the time series frequency by analysing the sequence of dates in the file.\nAggregation type – the type of aggregation (over time for each time series in the dataset) for the imported time series. This can be None, Sum, Average, First, Last, Min or Max. The aggregation can be performed only if the frequency parameter is specified. For example, when frequency is set to Quarterly and aggregation type is set to Average, a monthly time series is transformed to quarterly one with values that are equal to the one third of the sum of the monthly values that belong to the corresponding calendar quarter.\nClean missing – erases the missing values of the series.\n\nNext, in the Source section click the grey “….” button (see below) to open the file.\n\nChoose a file and click OK.\n\nThe user may specify Data format, Frequency and Aggregation type, however this step is not compulsory. When these options are specified JDemetra+ is able to convert the time series frequency. Otherwise, the functionality that enables the time series frequency to be converted will not be available.\n\nThe data are organized in a tree structure.\n\nOnce the data has been successfully imported, it is available to the user for various analyses (e.g. visualization, modelling, seasonal adjustment, etc.)\n\nThe data are organized in a tree structure. If you expand all the plus-signs under the spreadsheet you will see all the series within each sheet that has been loaded. Here all time series are visible under the Production in construction branch. The names of time series have been taken from the columns’ headings of the spreadsheet while the names of the branches come from sheets’ names."
  },
  {
    "objectID": "T-graphical-user-interface.html#workspace-window",
    "href": "T-graphical-user-interface.html#workspace-window",
    "title": "Graphical User Interface",
    "section": "Workspace window",
    "text": "Workspace window\nRestructure: present all the nodes\nWorkspace is a JDemetra+ functionality that stores the work performed by the user in a coherent and structured way. By default, each workspace contains the pre-defined modelling and seasonal adjustment specifications and a basic calendar. A specification is a set of modelling and/or seasonal adjustment parameters. Within the workspace the following items can be saved:\n\nUser-defined modelling specifications and seasonal adjustment specifications;\nDocuments that contain results from time series modelling and output from the seasonal adjustment process;\nUser-defined calendars;\nUser-defined regression variables.\n\nTogether with the results from modelling and seasonal adjustment, the original data, paths to the input files and parameters of processes are all saved. These results can then be re-opened, updated, investigated and modified in further JDemetra+ sessions.\nThe workspace saved by JDemetra+ includes:\n\nMain folder containing several folders that correspond to the different types of items created by the user and;\nThe xml file that enables the user to import the workspace to the application and to display its content.\n\nAn example of the workspace is shown in the figure below.\n\n\n\nA workspace saved on PC\n\n\nThe workspace can be shared with other users, which eases the burden of work with defining specifications, modelling and seasonal adjustment processes.\nThe content of the workspace is presented in the Workspace window. It is divided into three sections:\n\nModelling (contains the default and user-defined specifications for modelling; and the output from the modelling process)\nSeasonal adjustment (contains the default and user-defined specifications for seasonal adjustment and the output from the seasonal adjustment process),\nUtilities (calendars and user defined variables).\n\n\n\n\nThe Workspace window"
  },
  {
    "objectID": "T-graphical-user-interface.html#results-panel",
    "href": "T-graphical-user-interface.html#results-panel",
    "title": "Graphical User Interface",
    "section": "Results panel",
    "text": "Results panel\nThe blank zone in the figure above (on the right of the view) is the location where JDemetra+ displays various windows. More than one window can be displayed at the same time. Windows can overlap with each other with the foremost window being the one in focus or active. The active window has a darkened title bar. The windows in the results panel can be arranged in many different ways, depending on the user’s needs. The example below shows one of the possible views of this panel. The results of the user’s analysis are displayed in an accompanying window. The picture below shows two panels – a window containing seasonal adjustment results (upper panel) and another one containing an autoregressive spectrum (lower panel).\n\n\n\nThe Results panel filled with two windows"
  },
  {
    "objectID": "T-graphical-user-interface.html#data-visualisation",
    "href": "T-graphical-user-interface.html#data-visualisation",
    "title": "Graphical User Interface",
    "section": "Data Visualisation",
    "text": "Data Visualisation\neverything is in Tools &gt; container"
  },
  {
    "objectID": "T-graphical-user-interface.html#generating-outpt",
    "href": "T-graphical-user-interface.html#generating-outpt",
    "title": "Graphical User Interface",
    "section": "Generating Outpt",
    "text": "Generating Outpt\nadd : some explanations + link to cruncher (production chapter)\n\nSteps\n\nOnce a seasonal adjustment process for the dataset is performed Go to the TOP menu bar and follow the path: SAProcessing → Output…\nIn the Batch output window the user can specify which output items will be saved and the folder in which JDemetra+ saves the results. It is possible to save the results in the TXT, XLS, CSV, and CSV matrix formats. In the first step the user should choose the output format from the list.\n\nThe user may choose more than one format as the output can be generated in different formats at the same time.\n\nTo display and modify the settings click on the given output format on the list. The available options depend on the output format.\nFor Csv format the following options are available: folder (location of the file), file prefix (name of the file), presentation (controls how the output is divided into separate files) and series (series included in the file). These options are presented in the next points of this case study.\n\nThe user can define the folder in which the selected results and components will be saved (click the folder item and choose the final destination).\n\nWith the option File Prefix the user can modify the default name of the output saved in the CSV file.\n\nLayout controls how the output is divided into separate files. Expand the list to display available options:\n\nHTable – the output series will be presented in the form of horizontal tables (time series in rows).\nVTable – the output series will be presented in the form of vertical tables (time series in columns).\nList – the output series will be presented in the form of vertical tables (time series in rows). Apart from that, for each time series each file contains in separate columns: the data frequency, the first year and of estimation span, the first period (month or quarter) of observation span and the number of observations. The files do not include dates.\n\n\nThe Content section presents a list of series that will be included into a set of output files. To modify the initial settings click on the grey button in the Content section. The CVS-series window presents two panels: the panel on the left includes a list of all valuable output items. The panel on the right presents the selected output items. Mark the series and use the arrows to change the settings. Confirm your choice with the OK button.\n\nOptions available for the XLS format are the same as for the TXT format with an exception of the Layout section. The list of available codes in the Content section is given here.\n\nBySeries – all results for a given time series are placed in one sheet;\nByComponent – results are grouped by components. Each component type is saved in a separate sheet.\nOneSheet – all results are saved in one sheet.\n\n\nIf the user sets the option layout to ByComponent, the output will be generated as follows:\n\nThe option OneSheet will produce the following XLS file:\n\nBy default, the series in the Excel output files are organised vertically. When the user unmarks the check box the horizontal orientation is used.\n\nIn the case of the TXT format the only available options are folder (location of the file) and series (results included in the output file). The list of available codes in the Content section is given here.\n\nThe CSV matrix produces the CSV file containing information about the model and quality diagnostics of the seasonal adjustment. The user may generate the list of default items or create their own quality report. By default, all the available items are included in the output. The list of the items is given here.\n\nOnce the output settings are selected, click the OK button.\n\nFor each output JDemetra+ provides information on the status of the operation. An example is presented below."
  },
  {
    "objectID": "T-r-packages.html#overview",
    "href": "T-r-packages.html#overview",
    "title": "Using JDemetra+ in R",
    "section": "Overview",
    "text": "Overview\nCore JDemetra Java algorithms can be accessed via several tools:\n\nGraphical User Interface GUI\n…enhanced with additional plug-ins\nR packages\n\nThis chapter provides an overview of the packages linked to JDemetra core routines version 2.x and 3.x (under construction). More details on specific functions are available in the relevant chapters in the Algorithms part of this documentation. Help pages relative to each package, and also vignettes provide a detailed description for each available functions: purpose, arguments, output and examples.\nUseful resources are also available in this GitHub repository.\n\nWhat you will find in this chapter\n(force this format even if provisional) What could be useful here ? In which cases look further here ? Links to other chapters Q&A format\n\n\nPackages based on JDemetra+ version 2 algorithms\nPackages corresponding to version 2.x core routines:\n\nRJDemetra on CRAN or https://github.com/jdemetra/rjdemetra\nrjdworkspace on https://github.com/InseeFrLab/rjdworkspace\nJDCruncheR on https://github.com/InseeFr/JDCruncheR\nggdemetra on https://github.com/AQLT/ggdemetra\nrjdqa on https://github.com/AQLT/rjdqa\n\n\n\nPackages based on JDemetra+ version 3 algorithms\nPackages corresponding to version 3.x core routines:\n\nrjd3toolkit at https://github.com/palatej/rjd3toolkit\nrjd3x13 on https://github.com/palatej/rjd3x13\nrjd3tramoseats at https://github.com/palatej/rjd3tramoseats\nrjdemetra3 at https://github.com/palatej/rjdemetra3\nrjd3sts at https://github.com/palatej/rjd3sts\nrjd3stl at https://github.com/palatej/rjd3stl\nrjd3highfreq at https://github.com/palatej/rjd3highfreq\nrjd3bench at https://github.com/palatej/rjd3bench\nrjd3filters at https://github.com/palatej/rjd3filters\nggdemetra3 on https://github.com/AQLT/ggdemetra3"
  },
  {
    "objectID": "T-r-packages.html#algorithms-available-in-r",
    "href": "T-r-packages.html#algorithms-available-in-r",
    "title": "Using JDemetra+ in R",
    "section": "Algorithms available in R",
    "text": "Algorithms available in R\n\nSeasonal adjustment\n\nUsing JDemetra+ version 2.x\n\n\n\n\n\n\n\n\nAlgorithm\nPackage\nComments\n\n\n\n\nX13-Arima\nRJDemetra\nReg-Arima and X-11 decomposition available independently\n\n\nTramo-Seats\nRJDemetra\nTramo available independently\n\n\n\n\n\nUsing JDemetra+ version 3.x\n\n\n\n\n\n\n\n\nAlgorithm\nPackage\nComments\n\n\n\n\nX13-Arima\nrjd3x13\nReg-Arima and X-11 decomposition available independently\n\n\nExtended X-11\nrjd3highfreq\nFor high-frequency (infra-monthly) data\n\n\nTramo-Seats\nrjd3tramoseats\nTramo available independently\n\n\nExtended Tramo\nrjd3highfreq\nFor high-frequency data\n\n\nExtended Seats\nrjd3highfreq\nFor high-frequency data\n\n\nSTL\nrjd3stl\nIncluding high-frequency data\n\n\nBasic Structural Models\nrjd3sts\nState space framework\n\n\n\nVersion 3.x includes [Revision Policies([T-rev-policies-production.qmd) in X-13 and Tramo-Seats.\nMore details on functions parameters and retrieving output in the chapter dedicated to Seasonal Adjustment\n\n\n\nFiltering and Trend estimation\n\n\n\n\n\n\n\n\nAlgorithm\nPackage\nComments\n\n\n\n\nMoving average functions\nrjd3filters\n\n\n\nLocal Polynomial Trend Estimation\nrjd3filters, rjd3highfreq\n\n\n\n\n\n\nBenchmarking and Temporal disaggregation\n\n\n\nAlgorithm\nPackage\nComment\n\n\n\n\nDenton\nrjd3bench\n\n\n\nCholette\nrjd3bench\n\n\n\nCubic splines\nrjd3bench\n\n\n\nTemporal Disaggregation\nrjd3bench"
  },
  {
    "objectID": "T-r-packages.html#utility-functions-available-in-r",
    "href": "T-r-packages.html#utility-functions-available-in-r",
    "title": "Using JDemetra+ in R",
    "section": "Utility functions available in R",
    "text": "Utility functions available in R\nThe packages listed below contain utility functions useful when running a production process with massive datasets.\n\nRunning the cruncher and generating a quality report\nJDemetra+ cruncher is an executable module designed for mass production of seasonally adjusted series .\n\n\n\nPackage\nJD+ version\nComments\n\n\n\n\nrjwsacruncher\n2.x\nestimation update and output\n\n\nJDCruncheR\n2.x\nall the above + Quality Report\n\n\n\n\n\nWrangling JD+ workspaces\nA workspace is a specific JDemetra+ data format (xml files) allowing to use the graphical user interface (GUI) and the cruncher.\n\n\n\n\n\n\n\n\nPackage\nJD+ version\nComments\n\n\n\n\nrjdworkspace\n2.x\nupdate meta data, merge workspaces\n\n\nrjdemetra3\n3.x\nidem but under construction\n\n\n\n\n\nGenerating enhanced output in SA estimation\nThis additional packages produce enhanced plots and diagnostic outputs.\n\n\n\nPackage\nJD+ version\nComments\n\n\n\n\nrjdmarkdown\n2.x\nenhanced print of diagnostics\n\n\nggdemetra\n3.x\nplots based on ggplot\n\n\nggdemetra3\n3.x\nplots based on ggplot\n\n\nrjdqa\n2.x\nvisual dashboard on one series"
  },
  {
    "objectID": "T-r-packages.html#general-structure",
    "href": "T-r-packages.html#general-structure",
    "title": "Using JDemetra+ in R",
    "section": "General structure",
    "text": "General structure\nThe R object resulting from an estimation is a list of lists containing raw data, parameters, output series and diagnostics.\n\nOutput structure for RJDemetra package\nOrganised by domain:\n\n\n\nV2 SA structure\n\n\nTo retrieve any element just navigate this list of lists.\n\n\nOutput structure for rjd3x13 package\nResults and specification are separated first and then organised by domain.\n\nsa_x13_v3 &lt;- RJDemetra::x13(y_raw, spec = \"RSA5\")\nsa_x13_v3$result\nsa_x13_v3$estimation_spec\nsa_x13_v3$result_spec\nsa_x13_v3$user_defined\n\nTo retrieve any element just navigate this list of lists."
  },
  {
    "objectID": "T-r-packages.html#installation-procedure",
    "href": "T-r-packages.html#installation-procedure",
    "title": "Using JDemetra+ in R",
    "section": "Installation procedure",
    "text": "Installation procedure\n\nversion 2\n\ninstall.packages(\"RJDemetra\")\nremotes::install_github(\"InseeFrLab/rjdworkspace\")\nremotes::install_github(\"InseeFr/JDCruncheR\")\n\n\n\nversion 3\n\n#install.packages(\"remotes\")\n#install.packages(\"devtools\")\nremotes::install_github(\"palatej/rjd3toolkit\")\nremotes::install_github(\"palatej/rjd3x13\")\nremotes::install_github(\"palatej/rjd3tramoseats\")\nremotes::install_github(\"palatej/rjdemetra3\")\nremotes::install_github(\"palatej/rjd3filters\")\nremotes::install_github(\"palatej/rjd3sts\")\nremotes::install_github(\"palatej/rjd3highfreq\")\nremotes::install_github(\"palatej/rjd3stl\")\nremotes::install_github(\"palatej/rjd3bench\")\nremotes::install_github(\"AQLT/ggdemetra3\")\ndevtools::install_github(\"palatej/rj3dfilters\")"
  },
  {
    "objectID": "T-r-packages.html#rjd3-suite-of-packages-overview",
    "href": "T-r-packages.html#rjd3-suite-of-packages-overview",
    "title": "Using JDemetra+ in R",
    "section": "rjd3 suite of packages: overview",
    "text": "rjd3 suite of packages: overview\nThe sections below provide an overview of each package based on version 3.x of JDemetra+. For detailed description refer to the package’s own R documentation pages and vignettes.\n\nrjd3toolkit\nContains utility functions used in other rjd3 packages and has to be systematically installed before using any other rjd3 package. From a user point of view, it allows to:\n\ncustomized the pre-adjustment specification in X13-Arima and Tramo-Seats\ngenerate user-defined regressors for calendar correction\ngenerate auxiliary variables (outliers, ramps..)\nrun arima model estimations\nperform tests\naccess general functions such as autocorrelations, distributions…\n\nMore details for each part can be found in `rjd3toolkit``R help pages and related vignettes.\n\n\nrjd3x13\nrjd3x13 gives access to X13-Arima seasonal adjustment algorithm.\n\nSpecification: created with spec_x11_default(), spec_x13_default(), spec_regarima_default() and customized with rjd3toolkit functions + set_x11()\nApply model with x11(), x13(), fast.x13(), regarima(), fast.regarima()\nRefresh policies: regarima.refresh() and x13.refresh()\n\n\n\nrjd3tramoseats\nrjd3tramoseats gives access to TRAMO-SEATS seasonal adjustment algorithm.\n\nSpecification: created with spec_tramoseats_default(), spec_tramo_default() and customized with rjd3toolkit functions + set_seats()\nApply model with tramoseats(), fast.tramoseats(), tramo(), fast.tramo()\nRefresh policies: tramo.refresh() and tramoseats.refresh()\n\n\n\nrjd3highfreq\nSeasonal adjustment of high frequency (infra-monthly) data:\n\nfractional airline based reg-Arima pre-adjustment\nfractional and multi airline decomposition\nExtension of X-11 decomposition with non integer periodicity\n\n\n\nrjd3sts\nGives access to structural time series and state space models, has to be installed to use rjd3highfreq. Handles high-frequency data.\nSeveral examples available here https://github.com/palatej/test_rjd3sts\n\n\nrjd3stl\nrjd3stl contains usual STL functions but is also tailored to handle high-frequency data.\n\n\nggdemetra3\nggdemetra3 uses ggplot2 to add seasonal adjustment statistics to your plot (Like ggdemetra but compatible with version 3.x.). Also compatible with high-frequency methods:\n\nlibrary(\"ggdemetra3\")\n\nspec &lt;- spec_x13_default(\"rsa3\") |&gt; set_tradingdays(option = \"WorkingDays\")\np_ipi_fr &lt;- ggplot(data = ipi_c_eu_df, mapping = aes(x = date, y = FR)) +\n    geom_line() +\n    labs(title = \"SA - IPI-FR\",\n         x = NULL, y = NULL)\np_sa &lt;- p_ipi_fr +\n    geom_sa(component = \"y_f(12)\", linetype = 2,\n            spec = spec) + \n    geom_sa(component = \"sa\", color = \"red\") +\n    geom_sa(component = \"sa_f\", color = \"red\", linetype = 2)\np_sa\np_sa + \n    geom_outlier(geom = \"label_repel\",\n                 coefficients = TRUE,\n                 ylim = c(NA, 65), force = 10,\n                 arrow = arrow(length = unit(0.03, \"npc\"),\n                               type = \"closed\", ends = \"last\"),\n                 digits = 2)\n\n\n\nrjd3filters\nThe rjd3filters package allows to:\n\neasily create/combine/apply moving averages moving_average() (much more general than stats::filter()) and study their properties: plot coefficients (plot_coef()), gain (plot_gain()), phase-shift (plot_phase()) and different statics (diagnostic_matrix())\ntrend-cycle extraction with different methods to treat endpoints:\nlp_filter() local polynomial filters of Proietti and Luati (2008) (including Musgrave): Henderson, Uniform, biweight, Trapezoidal, Triweight, Tricube, “Gaussian”, Triangular, Parabolic (= Epanechnikov)\n\nrkhs_filter() Reproducing Kernel Hilbert Space (RKHS) of Dagum and Bianconcini (2008) with same kernels\n\nfst_filter() FST approach of Grun-Rehomme, Guggemos, and Ladiray (2018)\n\ndfa_filter() derivation of AST approach of Wildi and McElroy (2019)\nchange the filter used in X-11 for TC extraction\n\n\nCreate moving averages\n\nlibrary(\"rjd3filters\")\n\nm1 &lt;- moving_average(rep(1, 3), lags = 1); m1 # Forward MA\nm2 &lt;- moving_average(rep(1, 3), lags = -1); m2 # centred MA\n\nm1 + m2\nm1 - m2\nm1 * m2\n\nCan be used to create all the MA of X-11:\n\ne1 &lt;- moving_average(rep(1, 12), lags = -6)\ne1 &lt;- e1 / sum(e1)\ne2 &lt;- moving_average(rep(1 / 12, 12), lags = -5)\n\n# used to have the 1rst estimate of the trend\ntc_1 &lt;- M2X12 &lt;- (e1 + e2) / 2\ncoef(M2X12) |&gt; round(3)\nsi_1 &lt;- 1 - tc_1\nM3 &lt;- moving_average(rep(1 / 3, 3), lags = -1)\nM3X3 &lt;- M3 * M3\n\n# M3X3 moving average applied to each month\ncoef(M3X3) |&gt; round(3)\nM3X3_seasonal &lt;- to_seasonal(M3X3, 12)\ncoef(M3X3_seasonal) |&gt; round(3)\ns_1 &lt;- M3X3_seasonal * si_1\ns_1_norm &lt;- (1 - M2X12) * s_1\nsa_1 &lt;- 1 - s_1_norm\nhenderson_mm = moving_average(lp_filter(horizon = 6)$filters.coef[, \"q=6\"],\n                              lags = -6)\ntc_2 &lt;- henderson_mm * sa_1\nsi_2 &lt;- 1 - tc_2\nM5 &lt;- moving_average(rep(1 / 5, 5), lags = -2)\nM5X5_seasonal &lt;- to_seasonal(M5 * M5, 12)\ns_2 &lt;- M5X5_seasonal * si_2\ns_2_norm &lt;- (1 - M2X12) * s_2\nsa_2 &lt;- 1 - s_2_norm\ntc_f &lt;- henderson_mm * sa_2\n\n\npar(mai = c(0.3, 0.3, 0.2, 0))\nlayout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE))\n\nplot_coef(tc_f)\nplot_coef(sa_2, col = \"orange\", add = TRUE)\nlegend(\"topleft\", \n       legend = c(\"Final TC filter\", \"Final SA filter\"),\n       col = c(\"black\", \"orange\"), lty = 1)\n\nplot_gain(tc_f)\nplot_gain(sa_2, col = \"orange\", add = TRUE)\n\nplot_phase(tc_f)\nplot_phase(sa_2, col = \"orange\", add = TRUE)\n\n\n\nApply a moving average\n\ny &lt;- retailsa$AllOtherGenMerchandiseStores\ntrend &lt;- y * tc_1\nsa &lt;- y * sa_1\nplot(window(ts.union(y, trend, sa), start = 2000),\n     plot.type = \"single\",\n     col = c(\"black\", \"orange\", \"lightblue\"))\n\n\n\n\nrjd3bench\nTailored for Benchmarking and temporal disaggregation\nSeveral examples here\n\n\nrjdemetra 3\nThis package allows to wrangle JDemetra+ workspaces in R with functions:\n\nload_workspace\nsave_workspace\n\n…\nUnder construction, it Will contain all the functionalities of rjdworkspace (upgraded from version 2).\nMore information here"
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#overview",
    "href": "T-Production-tools-cruncher-QR.html#overview",
    "title": "Production, Cruncher and quality report",
    "section": "Overview",
    "text": "Overview\nIn this chapter you will find how to\n\nautomate the Seasonal adjustment estimation process\nupdate a workspace when new data is available\nexport output (series, diagnostics, parameters)\ngenerate a quality report usable for selective editing (manual fine tuning)"
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#automate-estimation-with-the-cruncher",
    "href": "T-Production-tools-cruncher-QR.html#automate-estimation-with-the-cruncher",
    "title": "Production, Cruncher and quality report",
    "section": "Automate estimation with the cruncher",
    "text": "Automate estimation with the cruncher\nThe cruncher is an additional “executable” module. It can be launched via R or SAS for example.\nObjectives of the cruncher:\n\nupdate a JDemetra+ workspace (with a given revision policy)\nexport the results (series and diagnostics),\n\nwithout having to open the graphical interface and operate manually. Suitable for a production process.\n\nInstallation procedure\n\nDownload the cruncher\n\nAvailable here https://github.com/jdemetra/jwsacruncher/releases\nClick on the zip code line of the latest release\n\nUnzip locally (or on server)\n\n\n\nHelp pages\nDocumentation is available here or click on the wiki icon on the Github page https://github.com/jdemetra/jwsacruncher/wiki\n\n\nRunning the cruncher in R\nTwo R packages are currently available\n\nrjwsacruncher on CRAN: workspace update and output production\nCruncher (https://github.com/InseeFr/JDCruncheR): same functions as rjwsacruncher but adds a quality report\n\n\nInstallation\n\nrjwsacruncher\n\n\ninstall.packages(rjwsacruncher)\n\n\nJDCruncheR package: download the .zip or .tar.gz file from https://github.com/InseeFr/JDCruncheR/releases.\n\nAdditional packages needed\n\ninstall.packages(c(\"XLConnect\", \"XML\"))\n\n\n\nLoading\n\nlibrary(JDCruncheR)\n\nor\n\nlibrary(rjwsacruncher)\n\n\n\nConnecting the cruncher module\nTo connect the cruncher to the R package, the path to the bin directory containing the cruncher.bat file must be specified. This directory is available once the zip file has been unzipped.\n\noptions(cruncher_bin_directory =\n    \"C:/Software/jwsacruncher-2.2.3/jdemetra-cli-2.2.3/bin\")\n\n\nchecking the current value\n\n\ngetOption(\"cruncher_bin_directory\")\n\n\n\n\nUpdating a workspace\nThe functions described in this section are identical for both packages.\n\nRunning estimations\nThe general context: two use cases\n\nRun first estimation of seasonally adjusted series (from raw series and parameters contained in the workspace)\n\n\ncruncher_and_param(workspace = \"D:/my_folder/my_ws.xml\",\n                   rename_multi_documents = FALSE,\n                   policy = \"complete\" #name of the revision policy\n                   log= my_log_file.txt)\n\n\nApply a revision policy to updated raw series\n\nThe function cruncher_and_param() allows to do that\n\ncruncher_and_param(workspace = \"D:/my_folder/my_ws.xml\",\n                   rename_multi_documents = FALSE,\n                   policy = \"lastoutliers\" #name of the revision policy\n                   log= my_log_file.txt)\n\nTo use the documentation, compute help() or ?function:\n\n?cruncher_and_param\nhelp(cruncher_and_param)\n\nBefore running SA estimations, set the export options.\n\n\n\nConfiguring output options\nAfter updating the workspace with the selected revision policies, the cruncher generates output - series (csv files) - diagnostics and parameters (demetra_m.csv file)\nThese files will be created in the workspace’s repository, sub-repository ’Output”\n\npath=\"My_Workspace/Output/SAProcessing\"\n\n\nSelecting time series to export\n\n# returns names of the currently exported series \ngetOption(\"default_tsmatrix_series\")\n# example of setting this option\noptions(default_tsmatrix_series = c(\"sa\", \"sa_f\"))\n# only seasonally adjsuted series (\"sa\") and its forecasts (\"sa_f\") will be exported\n\n\n\nSelecting diagnostics and parameters to exoprt\n\n# returns names of the currently exported diagnostics and parameters\ngetOption(\"default_matrix_item\")\n# example of setting this option\noptions(default_matrix_item = c(\"likelihood.aic\",\n                                \"likelihood.aicc\",\n                                \"likelihood.bic\",\n                                \"likelihood.bicc\"))"
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#quality-report-with-jdcruncher",
    "href": "T-Production-tools-cruncher-QR.html#quality-report-with-jdcruncher",
    "title": "Production, Cruncher and quality report",
    "section": "Quality report with JDCruncheR",
    "text": "Quality report with JDCruncheR\nThe JDCruncheR package also:\n\ncomputes a quality score\ncreates a quality report from the diagnostics produced by JDemetra+\n\n\nMain steps\nThe three main functions of the package are:\n\nextract_QR to extract the quality report from the csv file (demetra_m.csv) that contains all JD+ diagnostics;\ncompute_score to compute a weighted score based on the diagnostics\nexport_xlsx to export the quality report.\n\n\n# choose the demetra_m.csv file generated by the cruncher\nQR &lt;- extract_QR()\nQR\n\n?compute_score # to see how the score is calculated (formula)\nQR &lt;- compute_score(QR,\n                    n_contrib_score = 3)\n\nQR\n\nQR &lt;- sort(QR, decreasing = TRUE, sort_variables = \"score\")\nexport_xlsx(QR,\n            file_name = \"U:/quality_report.xls\")\n\n\n\nPiling up results\nWhen working with several workspaces or Seasonal adjustment processings (SAP) within a given workspace, quality reports can be piled up with the function rbind() or by creating a mQR_matrix object with the function mQR_matrix()\n\nQR1 &lt;- extract_QR()\nQR2 &lt;- extract_QR()\nmQR &lt;- mQR_matrix(QR1, QR2)\nmQR\n# naming each object\nnames(mQR) &lt;- c(\"report_1\", \"report_2\")\n# Equivalent to: \nmQR &lt;- mQR_matrix(report_1 = QR1, report_2 = QR2)\nmQR\n\n# score calculation for all reports\nmQR &lt;- compute_score(mQR,\n                    n_contrib_score = 3)\nexport_xlsx(mQR,\n            export_dir = \"U:/\")\n\n\n\nConditionnal score\nMissing values can be ignored and conditions can be set for indicators:\n\n# oos_mse weight reduced to 1 when the other \n# indicators are \"Bad\" ou \"Severe\"\ncondition1 &lt;- list(indicator = \"oos_mse\",\n                   conditions = c(\"residuals_independency\",\n                                  \"residuals_homoskedasticity\",\n                                  \"residuals_normality\"),\n                   conditions_modalities = c(\"Bad\",\"Severe\"))\nBQ &lt;- compute_score(BQ, n_contrib_score = 5,\n                    conditional_indicator = list(condition1),\n                    na.rm = TRUE)\n\n\n\nCustomize the score computation\nPractical steps if you want to customize the score computation (see package documentation in R)\n\nselect your indicators of interest\nadjust “good”, “bad”…threshold in JD+ GUI if necessary\nby default good=0, uncertain=1, bad or severe=3\nchange this grading system and/or the weights directly in the package functions\nrebuild your package"
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#list-of-exportable-series",
    "href": "T-Production-tools-cruncher-QR.html#list-of-exportable-series",
    "title": "Production, Cruncher and quality report",
    "section": "List of exportable series",
    "text": "List of exportable series\nSome available output series will be different when using X13-Arima or Tramo-Seats."
  },
  {
    "objectID": "T-Production-tools-cruncher-QR.html#list-of-exportable-diagnostics-and-parameters",
    "href": "T-Production-tools-cruncher-QR.html#list-of-exportable-diagnostics-and-parameters",
    "title": "Production, Cruncher and quality report",
    "section": "List of exportable diagnostics and parameters",
    "text": "List of exportable diagnostics and parameters\nSome parameters and available diagnostics will be different when using X13-Arima or Tramo-Seats.\n\noptions(default_matrix_item = \n    c(\"period\", \"span.start\", \"span.end\", \"span.n\", \"span.missing\",\n      \"espan.start\", \"espan.end\", \"espan.n\", \"log\", \"adjust\", \"regression.lp\",\n      \"regression.ntd\", \"regression.nmh\", \"regression.td-derived\",\n      \"regression.td-ftest\", \"regression.easter\", \"regression.nout\",\n      \"regression.noutao\", \"regression.noutls\", \"regression.nouttc\",\n      \"regression.noutso\", \"regression.td(*):4\", \"regression.out(*)\",\n      \"regression.user(*)\", \"likelihood.neffectiveobs\", \"likelihood.np\",\n      \"likelihood.logvalue\", \"likelihood.adjustedlogvalue\", \"likelihood.ssqerr\",\n      \"likelihood.aic\", \"likelihood.aicc\", \"likelihood.bic\", \"likelihood.bicc\",\n      \"residuals.ser\", \"residuals.ser-ml\", \"residuals.mean\", \"residuals.skewness:3\",\n      \"residuals.kurtosis:3\", \"residuals.dh\", \"residuals.lb\", \"residuals.lb2:3\",\n      \"residuals.seaslb\", \"residuals.bp\", \"residuals.bp2\", \"residuals.seasbp\",\n      \"residuals.nudruns\", \"residuals.ludruns\", \"residuals.nruns\",\n      \"residuals.lruns\", \"arima\", \"arima.mean\", \"arima.p\", \"arima.d\",\n      \"arima.q\", \"arima.bp\", \"arima.bd\", \"arima.bq\", \"arima.phi(*)\",\n      \"arima.bphi(*)\", \"arima.th(*)\", \"arima.bth(*)\", \"decomposition.seasonality\",\n      \"decomposition.parameters_cutoff\", \"decomposition.model_changed\",\n      \"decomposition.tvar-estimator\", \"decomposition.tvar-estimate\",\n      \"decomposition.tvar-pvalue\", \"decomposition.savar-estimator\",\n      \"decomposition.savar-estimate\", \"decomposition.savar-pvalue\",\n      \"decomposition.svar-estimator\", \"decomposition.svar-estimate\",\n      \"decomposition.svar-pvalue\", \"decomposition.ivar-estimator\",\n      \"decomposition.ivar-estimate\", \"decomposition.ivar-pvalue\", \"decomposition.tscorr-estimator\",\n      \"decomposition.tscorr-estimate\", \"decomposition.tscorr-pvalue\",\n      \"decomposition.ticorr-estimator\", \"decomposition.ticorr-estimate\",\n      \"decomposition.ticorr-pvalue\", \"decomposition.sicorr-estimator\",\n      \"decomposition.sicorr-estimate\", \"decomposition.sicorr-pvalue\",\n      \"decomposition.ar_root(*)\", \"decomposition.ma_root(*)\", \"method\",\n      \"variancedecomposition.cycle\", \"variancedecomposition.seasonality\",\n      \"variancedecomposition.irregular\", \"variancedecomposition.tdh\",\n      \"variancedecomposition.others\", \"variancedecomposition.total\",\n      \"diagnostics.logstat\", \"diagnostics.levelstat\", \"diagnostics.fcast-insample-mean\",\n      \"diagnostics.fcast-outsample-mean\", \"diagnostics.fcast-outsample-variance\",\n      \"diagnostics.seas-lin-f\", \"diagnostics.seas-lin-qs\", \"diagnostics.seas-lin-kw\",\n      \"diagnostics.seas-lin-friedman\", \"diagnostics.seas-lin-periodogram\",\n      \"diagnostics.seas-lin-spectralpeaks\", \"diagnostics.seas-si-combined\",\n      \"diagnostics.seas-si-evolutive\", \"diagnostics.seas-si-stable\",\n      \"diagnostics.seas-res-f\", \"diagnostics.seas-res-qs\", \"diagnostics.seas-res-kw\",\n      \"diagnostics.seas-res-friedman\", \"diagnostics.seas-res-periodogram\",\n      \"diagnostics.seas-res-spectralpeaks\", \"diagnostics.seas-res-combined\",\n      \"diagnostics.seas-res-combined3\", \"diagnostics.seas-res-evolutive\",\n      \"diagnostics.seas-res-stable\", \"diagnostics.seas-i-f\", \"diagnostics.seas-i-qs\",\n      \"diagnostics.seas-i-kw\", \"diagnostics.seas-i-periodogram\", \"diagnostics.seas-i-spectralpeaks\",\n      \"diagnostics.seas-i-combined\", \"diagnostics.seas-i-combined3\",\n      \"diagnostics.seas-i-evolutive\", \"diagnostics.seas-i-stable\",\n      \"diagnostics.seas-sa-f\", \"diagnostics.seas-sa-qs\", \"diagnostics.seas-sa-kw\",\n      \"diagnostics.seas-sa-friedman\", \"diagnostics.seas-sa-periodogram\",\n      \"diagnostics.seas-sa-spectralpeaks\", \"diagnostics.seas-sa-combined\",\n      \"diagnostics.seas-sa-combined3\", \"diagnostics.seas-sa-evolutive\",\n      \"diagnostics.seas-sa-stable\", \"diagnostics.seas-sa-ac1\", \"diagnostics.td-sa-all\",\n      \"diagnostics.td-sa-last\", \"diagnostics.td-i-all\", \"diagnostics.td-i-last\",\n      \"diagnostics.td-res-all\", \"diagnostics.td-res-last\", \"diagnostics.ic-ratio-henderson\",\n      \"diagnostics.ic-ratio\", \"diagnostics.msr-global\", \"diagnostics.msr(*)\",\n      \"decomposition.trendfilter\", \"decomposition.seasfilter\", \"m-statistics.m1\",\n      \"m-statistics.m2\", \"m-statistics.m3\", \"m-statistics.m4\", \"m-statistics.m5\",\n      \"m-statistics.m6\", \"m-statistics.m7\", \"m-statistics.m8\", \"m-statistics.m9\",\n      \"m-statistics.m10\", \"m-statistics.m11\", \"m-statistics.q\", \"m-statistics.q-m2\",\n      \"diagnostics.basic checks.definition:2\", \"diagnostics.basic checks.annual totals:2\",\n      \"diagnostics.visual spectral analysis.spectral seas peaks\", \"diagnostics.visual spectral analysis.spectral td peaks\",\n      \"diagnostics.regarima residuals.normality:2\", \"diagnostics.regarima residuals.independence:2\",\n      \"diagnostics.regarima residuals.spectral td peaks:2\", \"diagnostics.regarima residuals.spectral seas peaks:2\",\n      \"diagnostics.outliers.number of outliers:2\", \"diagnostics.out-of-sample.mean:2\",\n      \"diagnostics.out-of-sample.mse:2\", \"diagnostics.m-statistics.q:2\",\n      \"diagnostics.m-statistics.q-m2:2\", \"diagnostics.seats.seas variance:2\",\n      \"diagnostics.seats.irregular variance:2\", \"diagnostics.seats.seas/irr cross-correlation:2\",\n      \"diagnostics.residual seasonality tests.qs test on sa:2\", \"diagnostics.residual seasonality tests.qs test on i:2\",\n      \"diagnostics.residual seasonality tests.f-test on sa (seasonal dummies):2\",\n      \"diagnostics.residual seasonality tests.f-test on i (seasonal dummies):2\",\n      \"diagnostics.combined seasonality test.combined seasonality test on sa:2\",\n      \"diagnostics.combined seasonality test.combined seasonality test on sa (last 3 years):2\",\n      \"diagnostics.combined seasonality test.combined seasonality test on irregular:2\",\n      \"diagnostics.residual trading days tests.f-test on sa (td):2\",\n      \"diagnostics.residual trading days tests.f-test on i (td):2\",\n      \"diagnostics.quality\"\n    ))"
  },
  {
    "objectID": "T-rev-policies-production.html#overview",
    "href": "T-rev-policies-production.html#overview",
    "title": "Production and revision policies",
    "section": "Overview",
    "text": "Overview\nIn this chapter you will find out:\n\nhow to update seasonally adjusted series when new data is available\nwhat is a revision policy in a seasonal adjustment context\nthe description of all the revision policies available in JDemetra+\nhow to implement a revision policy using the Graphical User Interface, R or the Cruncher."
  },
  {
    "objectID": "T-rev-policies-production.html#revision-policies",
    "href": "T-rev-policies-production.html#revision-policies",
    "title": "Production and revision policies",
    "section": "Revision Policies",
    "text": "Revision Policies"
  },
  {
    "objectID": "T-rev-policies-production.html#definition-and-context",
    "href": "T-rev-policies-production.html#definition-and-context",
    "title": "Production and revision policies",
    "section": "Definition and context",
    "text": "Definition and context\nWhen raw data has been modified (extended and/or revised), the previous seasonal adjustment estimation needs updating. It can be redone from scratch (complete re-estimation) or update keeping fixed a predefined set of parameters already estimated. Eurostat’s Guidelines on seasonal adjustment (2015) recommend not to perform a complete re-estimation of the parameters on an infra-annual basis. The set of constraints on the parameters is called “revision policy” or “refresh policy”."
  },
  {
    "objectID": "T-rev-policies-production.html#overview-1",
    "href": "T-rev-policies-production.html#overview-1",
    "title": "Production and revision policies",
    "section": "Overview",
    "text": "Overview\nIn X13-Arima and Tramo-Seats revision policies are ways to impose constraints on the pre-adjustment phase, while the decomposition phase (X-11 or Seats) will be entirely re-run. The changes induced by X-11 re-estimation stem only from a revised linerarized series, while in Seats they are also induced by the arima model possible coefficient and/ or order changes.\nThe table below lists the available policies as well as their name for implementation with the graphical user interface (GUI), the cruncher or rjd3x13 ans rjd3tramoseats packages."
  },
  {
    "objectID": "T-rev-policies-production.html#revision-policies-in-gui",
    "href": "T-rev-policies-production.html#revision-policies-in-gui",
    "title": "Production and revision policies",
    "section": "Revision policies in GUI",
    "text": "Revision policies in GUI\n(pb links to GUI)\nThe saved results from a seasonal adjustment processing can be refreshed when new or modified observations are available.\n\nTo refresh the results open a previously saved workspace using the path File → Open Workspace. Choose the multi-document option from the Workspace window and double click on it to display the multi-document menu (SAProcessing).\n\nOpening a multi-document\nSeveral refreshment options are available.\n\nThe Refresh menu\n\n\nConcurrent\nAccording to the ESS Guidelines on Seasonal Adjustment (2015) , concurrent adjustment means that the model, filters, outliers, regression parameters and transformation type are all re-identified and the respective parameters and factors re-estimated every time new observations are available. This option in JDemetra+ means that a completely new model is identified, and the previous results are not taken into account.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Concurrent adjustment option (on the right). The transformation type has changed from none to log. The ARIMA model has been re-identified (it has changed from (0,1,1)(1,1,0) to (1,1,0)(0,1,1)). In contrast to the initial model, in the updated model trading day effects and a leap year effect are no longer included. Also the automatically identified outliers are not the same in both models.\n\nThe Concurrent adjustment revision policy results\n\n\nPartial concurrent adjustment → Fixed model\nThe Partial concurrent adjustment → Fixed model strategy means that the ARIMA model, outliers and other regression parameters are not re-identified and the values of the parameters are fixed. In particular, no new outliers or calendar variables are added to the model as well as no changes neither in the calendar variables nor in the outliers’ types are allowed. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Fixed model option (on the right). The parameters of the ARIMA part are not estimated and their values are the same as before. The trading days and outliers are fixed too and no new regression effects are identified.\n\nA Partial concurrent adjustment → fixed model revision policy results\n\n\nPartial concurrent adjustment → Estimate regression coefficients\nThe Partial current adjustment → Estimate regression coefficients option means that the ARIMA model, outliers and other regression parameters are not re-identified. The coefficients of the ARIMA model are fixed, other coefficients are re-estimated. In particular, no new outliers or calendar variables are added to the model as well as no changes neither in the calendar variables nor in the outliers’ types are allowed. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients option (on the right). The number of estimated parameters is 16 in the initial model and 14 in the revised model (the parameters of the ARIMA model are not estimated.\n\nThe Partial concurrent adjustment→ Estimate regression coefficients revision policy results\n\n\nPartial concurrent adjustment → Estimate regression coefficients + Arima parameters\nThe Partial concurrent adjustment → Estimate regression coefficients + Arima parameters strategy means that the ARIMA model, outliers and other regression parameters are not re-identified. All parameters of the Reg-ARIMA model are re-estimated but the explanatory variables remain the same. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficient + Arima parameters option (on the right). The parameters of the ARIMA part have been re-estimated and their values have been updated. Also regression coefficients have been re-estimated and the number of estimated coefficients in the revised model is the same as in the initial model (i.e. 16 estimated coefficients). The structure of the model remains unchanged while all coefficients have been updated.\n\nThe Partial concurrent adjustment → Estimate regression coefficients + Arima parameters revision policy results\n\n\nPartial concurrent adjustment → Estimate regression coefficients + outliers\nThe Partial concurrent adjustment → Estimate regression coefficients + outliers option means that the ARIMA model and regression parameters, except outliers, are not re-identified. The parameters of these variables, however, are re-estimated. All outliers are re-identified, i.e. the previous outcome of the outlier detection procedure is not taken into account and all outliers are identified and estimated once again. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients + outliers option (on the right). The parameters of the ARIMA part have been re-estimated and their values have been updated. Also regression coefficients for the calendar variables have been re-estimated. In the revised model there is no Prespecified outliers section. Instead, the outliers were re-identified.\n\nThe Partial concurrent adjustment → Estimate regression coefficient + outliers revision policy results\n\n\nThe Partial concurrent adjustment → Estimate regression coefficients + Arima model\nThe Partial concurrent adjustment → Estimate regression coefficients + Arima model option means that the ARIMA model, outliers and regression variables (except the calendar variables) are re-identified. All parameters are re-estimated. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients + Arima model option (on the right). The ARIMA part has been re-identified (a change from (2,1,0)(0,1,1) to (0,1,1)(1,1,1)). Also the regression coefficients for the calendar variables have been re-estimated. In the revised model there is no Prespecified outliers section. Therefore, the outliers were re-identified.\n\nThe Partial concurrent adjustment → Estimate regression coefficient + Arima model revision policy results\n\n\nPartial concurrent adjustment → Estimate regression coefficients + Last outliers\nThe Partial concurrent adjustment → Estimate regression coefficients + Last outliers strategy means that the ARIMA model, outliers (except for the last year of the sample) and other regression parameters are not re-identified. All parameters of the Reg-ARIMA model are re-estimated. The software tests for outliers in the last year of the data span and will include in the model those which are statistically significant. The transformation type remains unchanged.\nThe picture below presents the initial model (on the left) and the results of the refreshment procedure with the Partial concurrent adjustment → Estimate regression coefficients + Last outliers option (on the right). The parameters of the ARIMA part have been re-estimated and their values have been updated. Also the regression coefficients have been re-estimated. The number of estimated coefficients in the revised model is larger than the initial model because an additional outlier has been identified in the last year of the data span.\n\nThe Partial concurrent adjustment → Estimate regression coefficient + Last outliers revision policy results"
  },
  {
    "objectID": "T-plug-ins.html#main-functions",
    "href": "T-plug-ins.html#main-functions",
    "title": "Plug-ins for JDemetra+",
    "section": "Main functions",
    "text": "Main functions\n\nDefault Plugins\n\n\n\n\n\n\n\n\nName\nCategory\nDescription\n\n\n\n\nNbDemetra – Anomaly detection\nSA core algorithms\nIdentification of outliers\n\n\nNbDemetra – Spreadsheet\nIO (Input/output)\nTime series providers for spreadsheet (Excel, OpenOffice)\n\n\nNbDemetra – Common\nIO (Input/output)\nCommon time series providers, like XML and TXT\n\n\nNbDemetra – JDBC\nIO (Input/output)\nTime series provider for the JDBC sources\n\n\nNbDemetra – ODBC\nIO (Input/output)\nTime series provider for the ODBC sources\n\n\nNbDemetra – SDMX\nIO (Input/output)\nTime series provider for SDMX files\n\n\nNbDemetra – Core\nSA core algorithms\nEncapsulation of the core algorithms\n\n\nNbDemetra – UI\nSA core algorithms\nBasic graphical components\n\n\nNbDemetra – Branding\nSA core algorithms\n\n\n\nNbDemetra – SA\nSA core algorithms\nDefault SA framework, including TRAMO-SEATS and X-13ARIMA-SEATS. This implementation can lead to small differences in comparison with the original programs.\n\n\n\nThis list is displayed in the Installed panel. This panel is available from the Plugin functionality and it is activated from the Tools menu (Figure Activation of the Plugin functionality from the Tools menu in Plugins section)."
  },
  {
    "objectID": "T-plug-ins.html#plugins-list",
    "href": "T-plug-ins.html#plugins-list",
    "title": "Plug-ins for JDemetra+",
    "section": "Plugins-list",
    "text": "Plugins-list\n\nBundesbank plug-ins\n\nConCur: The plug-in ConCur supports the controlled current adjustment approach. It supports the storage of the current components and offers graphical tools to compare forecasted and re-estimated figures. Furthermore, a pre-defined summary of the output containing the most important quality measures can be exported to HTML files.\nKIX: The plug-in KIX (German for chain-linked index) has been designed to facilitate the handling of this index type. It offers addition and subtraction of two or more chain-linked time series as well as the computation of contributions of growth.\n\nKIX2.0: KIX 2.0 offers addition and subtraction of two or more chain-linked time series as well as the computation of contributions of growth following the concept of annual overlap. Contributions to growth are calculated with the partial contribution to growth approach.\nKIXE: KIX_E offers addition and subtraction of two or more chain-linked time series as well as the computation of contributions of growth following the concept of one-period overlap. Contributions to growth are calculated with the aid of the Ribe (1999) contribution to growth approach.\nKIX: The program KIX-CC offers for continuously chain-linked indices the aggregation or disaggregation of two or more indices, or the calculation of contributions to growth.\n\nTransReg: The plug-in TransReg allows the user to carry out grouping and centring of user-defined regression variables in JD+.\nXlsx2Ws: The plug-in Xlsx2Ws allows the converting of specific workspace information to a xlsx file and vice versa.\n\n\n\nNational Bank of Belgium plug-ins\n\nAccessThis JDemetra+ extension is a pure java library for reading time series from MS Access databases. It currently supports versions 2000-2016 read/write and 97 read-only.Being a pure Java library, you don’t need MS Access installed in order to read Access files. (edit versions info here)\nSDMX: This plugin provides time series from SDMX to JDemetra+ by querying web services or parsing files.\nSA Advanced: This module provides some experimental seasonal adjustment methods (with RegArima preprocessing), basic structural models, generalized airline models and airline + seasonal noise models (called mixed airline).\n\ngairline: generalized airline model\nmairline: mixed airline model\nmixedfreq: mixed frequencies seasonal adjustment\nsssts: Seasonal specific structural time series\nsts: Structural time series\n\nBenchmarking: This module provides some experimental methods for temporal disaggregation and multi-variate benchmarking:Chow-Lin, Fernandez, Litterman, Cholette, Calendarization.\nNowcasting: Nowcasting is often defined as the prediction of the present, the very near future and the very recent past. The plug-in developed at the National Bank of Belgium helps to operationalize the process of nowcasting. It can be used to specify and estimate dynamic factor models and visualize how the real-time dataflow updates expectations, as for instance in Banbura and Modugno (2010). The software can also be used to perform pseudo out-of-sample forecasting evaluations that consider the calendar of data releases, contributing to the formalization of the nowcasting problem originally proposed by Giannone, et al. (2008) or Evans (2005)."
  },
  {
    "objectID": "T-plug-ins.html#installation-procedure",
    "href": "T-plug-ins.html#installation-procedure",
    "title": "Plug-ins for JDemetra+",
    "section": "Installation procedure",
    "text": "Installation procedure\nInstallation from GUI\nmenu&gt;tools&gt; plug-ins\nThe Plugins window includes five panels: Updates, Available plugins, Downloaded, Installed and Settings, some of them however are not operational in the current version of the software.\n\nThe Updates panel offers the user the option to manually check if some updates of the already installed plugins are available. This functionality, however, is currently not operational for the JDemetra+ plugins.\nThe Available plugins panel allows the downloading of all plugins that are related to JDemetra+. This functionality, however, is currently not operational for the JDemetra+ plugins.\nThe Downloaded panel is designed for the installation of new plugins from a local machine. This process in explained in more detail below.\nThe Settings panel is designated for adding update centres, which are the locations that hold plugins. For each centre the user can specify proxy settings and a time interval to automatically check for any updates. At the moment this functionality is not operational for the JDemetra+ plugins.\n\nInstallation of the new plugins from the local machine can be done from the Plugin functionality activated from the Tools menu.\nInstallation of the new plugins from the local machine can be done from the Plugin functionality activated from the Tools menu.\n\nActivation of the Plugin functionality from the Tools menu\nTo start the process, go to the Downloaded panel and click on the Add Plugins… option. Next the user should select the plugins from the folder in which the plugins have been saved and click the OK button.\n``\n\nThe Downloaded panel – the choice of available plugins\nThe new plugin is now visible in the panel.\n\nA downloaded plugin\nClick on it and choose the Install button.\n\nStarting an installation procedure\nThere is a wizard that allows the user to install the marked plugin(s). In the first step choose Next to continue or Cancel to terminate the process.\n\nInstallation wizard window\nNext, mark the terms of agreements and choose Install.\n\nInitiating installation process\nThen the process is started.\n\nInstallation in progress\nAfter a while JDemetra+ will provide an update in the installation process. Click Finish to close the window.\n\nInstallation completed\nOnce the process is finished, the newly installed plugin is automatically integrated within the software. The picture below compares the view of the Workspace window before (on the left) and after (on the right) the installation of the NbDemetra-ODBC plugin.\n\nThe impact of the plugin on the interface\nThe list of all installed plugins is displayed in the fourth panel. To modify the current settings mark the plugin (by clicking the checkbox in the Select column) and chose an action.\nThe following options are available:\n\nActivate – activates the marked plugin if it is currently inactive. The option is available for inactive plugins (see the picture below);\nDeactivate – deactivates the marked plugin if it is currently active. The option is available for active plugins (see the picture below);\nUninstall – uninstalls the marked plugin.\n\nInactive plugins can be activated or uninstalled.\n\nActive plugins can be deactivated or uninstalled\n\nList of plugins – deactivation\nThere is a wizard that allows the user to activate/deactivate/uninstall the marked plugin(s). The example below illustrates the deactivation process. In the first step the user is expected to confirm or cancel the deactivation.\n\nPlugin’s deactivation process\nIn the second step the user should decide if the software will be restarted immediately after the uninstallation is completed or not.\n\nThe final step of the installation procedure\nIt is possible to delay the restart of the application, although the restart is necessary to complete the process."
  },
  {
    "objectID": "P_Methods.html",
    "href": "P_Methods.html",
    "title": "Methods",
    "section": "",
    "text": "This part describes in greater detail:\n\nReg-Arima modelling\nX-11: moving average based decomposition\nSEATS: Arima model based decomposition\nSTL: Loess based decomposition\nBenchmarking and temporal disaggregation\nSpectral analysis tools\nTrend Estimation\nTests for seasonality and residuals\nStructural time series and state space framework"
  },
  {
    "objectID": "M-spectral-analysis.html#spectral-analysis-concepts",
    "href": "M-spectral-analysis.html#spectral-analysis-concepts",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Spectral analysis concepts",
    "text": "Spectral analysis concepts\nA time series \\(x_{t}\\) with stationary covariance, mean \\(μ\\) and \\(k^{th}\\) autocovariance \\(E(x_{t}-\\mu)(x_{t- k}\\mu))=\\gamma(k)\\) can be described as a weighted sum of periodic trigonometric functions: \\(sin(\\omega t)\\) and \\(cos(\\omega t)\\), where \\(\\omega=\\frac{2*pi}{T}\\) denotes frequency. Spectral analysis investigates this frequency domain representation of \\(x_{t}\\) to determine how important cycles of different frequencies are in accounting for the behaviour of \\(x_{t}\\).\nAssuming that the autocovariances \\(\\gamma(k)\\) are absolutely summable(\\(\\sum_{k =-\\infty}^{\\infty}|\\gamma(k)|&lt;\\infty\\)), the autocovariance generating function, which summarizes these autocovariances through a scalar valued function, is given by equation Equation 1 1.\n\\[\nacgf(z)=\\sum_{k=-\\infty}^{\\infty}{z^{k}\\gamma(k)}\n\\]\nwhere \\(z\\) denotes complex scalar.\nOnce the equation Equation 1 is divided by \\(\\pi\\) and evaluated at some \\(z{= e}^{- i\\omega} = cos\\omega - isin\\omega\\), where \\(i = \\sqrt{- 1}\\) and \\(\\omega\\) is a real scalar, \\(\\  - \\infty &lt; \\ \\omega &lt; \\infty\\), the result of this transformation is called a population spectrum \\(f(\\omega)\\)for \\(\\ x_{t}\\), given in equation Equation 2 2.\n\\[\nf(\\omega) = \\frac{1}{\\pi}\\sum_{k=- \\infty}^{\\infty}{e^{- ik\\omega}\\gamma(k)}\n\\]\nTherefore, the analysis of the population spectrum in the frequency domain is equivalent to the examination of the autocovariance function in the time domain analysis; however it provides an alternative way of inspecting the process. Because \\(f(\\omega)\\text{dω}\\) is interpreted as a contribution to the variance of components with frequencies in the range \\((\\omega,\\ \\omega + d\\omega)\\), a peak in the spectrum indicates an important contribution to the variance at frequencies near the value that corresponds to this peak.\nAs \\(e^{-i\\omega} = cos\\omega - isin\\omega\\), the spectrum can be also expressed as in equation Equation 3.\n\\[\nf(\\omega) = \\frac{1}{\\pi}\\sum_{k = - \\infty}^{\\infty}{(cos\\omega k - isin\\omega k)\\gamma(k)}\n\\]\nSince \\(\\gamma(k) = \\gamma( - k)\\) (i.e. \\(\\gamma(k)\\) is an even function of \\(k\\)) and \\(\\sin{( - x)}\\  = \\operatorname{-sin}x\\), Equation 3  can be presented as equation\n\\[\nf(\\omega) = \\frac{1}{\\pi}\\lbrack \\ \\gamma(0) + 2\\sum_{k = 1}^{\\infty}{\\ \\gamma(k)}cos\\text{ωk} \\rbrack\n\\]\nThis implies that if autocovariances are absolutely summable the population spectrum exists and is a continuous, real-valued function of \\(\\omega\\). Due to the properties of trigonometric functions \\((\\cos( - \\omega k) = \\cos(\\text{ωk})\\) and \\(\\cos(\\omega + 2\\pi j)k = cos(\\omega k))\\) the spectrum is a periodic, even function of \\(\\omega\\), symmetric around \\(\\omega = 0\\). Therefore, the analysis of the spectrum can be reduced to the interval \\(( - \\pi,\\pi)\\). The spectrum is non-negative for all \\(\\omega \\in ( - \\pi,\\pi)\\).\nThe shortest cycle that can be distinguished in a time series lasts two periods. The frequency which corresponds to this cycle is \\(\\omega = \\pi\\) and is called the Nyquist frequency. The frequency of the longest cycles that can be observed in the time series with \\(n\\) observations is \\(\\omega = \\frac{2\\pi}{n}\\) and is called the fundamental (Fourier) frequency.\nNote that if \\(x_{t}\\) is a white noise process with zero mean and variance \\(\\sigma^{2}\\), then for all \\(|k|&gt; 0\\) \\(\\gamma(k)=0\\) and the spectrum of \\(x_{t}\\) is constant (\\(f(\\omega)= \\frac{\\sigma^{2}}{\\pi}\\)) since each frequency in the spectrum contributes equally to the variance of the process3.\nThe aim of spectral analysis is to determine how important cycles of different frequencies are in accounting for the behaviour of a time series4. Since spectral analysis can be used to detect the presence of periodic components, it is a natural diagnostic tool for detecting trading day effects as well as seasonal effects5. Among the tools used for spectral analysis are the autoregressive spectrum and the periodogram.\nThe explanations given in the subsections of this node derive mainly from DE ANTONIO, D., and PALATE, J. (2015) and BROCKWELL, P.J., and DAVIS, R.A. (2006).\n\nTheoretical spectral density of an ARIMA model"
  },
  {
    "objectID": "M-spectral-analysis.html#spectral-density-estimation",
    "href": "M-spectral-analysis.html#spectral-density-estimation",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Spectral density estimation",
    "text": "Spectral density estimation\n\nMethod 1: The periodogram\nFor any given frequency \\(\\omega\\) the sample periodogram is the sample analog of the sample spectrum. In general, the periodogram is used to identify the periodic components of unknown frequency in the time series. X-13ARIMA-SEATS and TRAMO-SEATS use this tool for detecting seasonality in raw time series and seasonally adjusted series. Apart from this it is applied for checking randomness of the residuals from the ARIMA model.\nTo define the periodogram, first consider the vector of complex numbers6:\n\\[\n\\mathbf{x} = \\begin{bmatrix}\n  x_{1} \\\\\n  x_{2} \\\\\n  . \\\\\n  . \\\\\n  . \\\\\n  x_{n} \\\\\n  \\end{bmatrix} \\in \\mathbb{C}^{n}\n\\]\nwhere \\(\\mathbb{C}^{n}\\) is the set of all column vectors with complex-valued components.\nThe Fourier frequencies associated with the sample size \\(n\\) are defined as a set of values \\(ω_{j} = \\frac{2\\pi j}{n}\\), \\(j = - \\lbrack \\frac{n-1}{2}\\rbrack,\\ldots,\\lbrack\\frac{n}{2}\\rbrack\\), \\(-\\pi&lt; \\omega_{j} \\leq \\pi\\), \\(j\\in F_{n}\\), where \\({\\lbrack n\\rbrack}\\) denotes the largest integer less than or equal to \\(n\\). The Fourier frequencies, which are called harmonics, are given by integer multiples of the fundamental frequency \\(\\ \\frac{2\\pi}{n}\\).\nNow the \\(n\\) vectors \\(e_{j} = n^{- \\frac{1}{2}}(e^{-i\\omega_{j}},e^{-i{2\\omega}_{j}},\\ldots,e^{- inω_{j}})^{'}\\) can be defined. Vectors \\(e_{1},\\ldots, e_{n}\\) are orthonormal in the sense that:\n\\[\n{\\mathbf{e}_{j}^{*}\\mathbf{e}}_{k} = n^{- 1}\\sum_{r = 1}^{n}e^{ir(\\omega_{j} - \\omega_{k})} = { \\begin{matrix}\n1,\\ if\\ j = k \\\\\n0,\\ if\\ j \\neq k \\\\\n\\end{matrix}}\n\\]\nwhere \\(\\mathbf{e}_{j}^{*}\\) denotes the row vector, which \\(k^{th}\\) component is the complex conjugate of the \\(k^{th}\\) component of \\(\\mathbf{e}_{j}\\).7 These vectors are a basis of \\(F_{n}\\), so that any \\(\\mathbf{x}\\in\\mathbb{C}^{n}\\) can be expressed as a sum of \\(n\\) components:\n\\[\n\\mathbf{x} = \\sum_{j = - \\lbrack\\frac{n - 1}{2}\\rbrack}^{\\lbrack\\frac{n}{2}\\rbrack}{a_{j}\\mathbf{e}_{j}}\n\\]\nwhere the coefficients \\(a_{j} = \\mathbf{e}_{j}^{*}\\mathbf{x}=n^{-\\frac{1}{2}}\\sum_{t = 1}^{n}x_{t}e^{-it\\omega_{j}}\\) are derived from Equation 3 by multiplying the equation on the left by \\(\\mathbf{e}_{j}^{*}\\) and using Equation 1.\nThe sequence of \\(\\{a_{j},j\\in F_{n}\\}\\) is referred as a discrete Fourier transform of \\(\\mathbf{x}\\mathbb{\\in C}^{n}\\) and the periodogram \\(I(\\omega_{j})\\) of \\(\\mathbf{x}\\) at Fourier frequency \\(\\omega_{j} = \\frac{2\\pi j}{n}\\) is defined as the square of the Fourier transform \\(\\{a_{j}\\}\\) of \\(\\mathbf{x}\\):\n\\[\n{I(\\omega_{j})\\mathbf{=}{| a_{j} |^{2}}_{\\ } = n^{- \\ 1}| \\sum_{t = 1}^{n}x_{t}e^{- it\\omega_{j}} |^{2}}_{\\mathbf{\\ }}\n\\]\nFrom Equation 2 and Equation 3 it can be shown that in fact the periodogram decomposes the total sum of squares \\(\\sum_{t = 1}^{n}| x_{t} |^{2}\\) into a sums of components associated with the Fourier frequencies \\(ω_{j}\\):\n\\[\n\\sum_{t=1}^{n}{|x_{t}|}^{2} = \\sum_{j = - \\lbrack\\frac{n - 1}{2}\\rbrack}^{\\lbrack\\frac{n}{2}\\rbrack}|a_{j}|^{2} = \\sum_{j = - \\lbrack\\frac{n - 1}{2}\\rbrack}^{\\lbrack\\frac{n}{2}\\rbrack}{I(\\omega_{j})}\n\\]\nIf \\(\\ \\mathbf{x\\  \\in}\\ {R}^{n}\\), \\(\\omega_{j}\\) and \\({-\\omega}_{j}\\) are both in \\(\\lbrack- \\pi, -\\pi \\rbrack\\) and \\(a_{j}\\) is presented in its polar form (i.e. \\(a_{j} = r_{j}\\exp( i\\theta_{j})\\)), where \\(r_{j}\\) is the modulus of \\(a_{j}\\), then Equation 3 can be rewritten in the form:\n\\[\n\\mathbf{x} = a_{0}\\mathbf{e}_{0} + \\sum_{j = 1}^{\\lbrack\\frac{n - 1}{2}\\rbrack}{ {2^{1/2}r}_{j}{(\\mathbf{c}}_{j}\\cos\\theta_{j}{- \\mathbf{s}}_{j}\\sin\\theta_{j}) + a_{n/2}\\mathbf{e}_{n/2}}\n\\]\nThe orthonormal basis for \\({R}^{n}\\) is \\(\\{\\mathbf{e}_{0},\\mathbf{c}_{1},\\mathbf{s}_{1},\\ldots,\\mathbf{c}_{\\lbrack\\frac{n - 1}{2}\\rbrack},\\mathbf{s}_{\\lbrack\\frac{n - 1}{2}\\rbrack},\\mathbf{e}_{\\frac{n}{2}(excluded\\ if\\ n\\ is\\ odd)}\\}\\), where:\n\\(\\mathbf{e}_{0}\\) is a vector composed of n elements equal to \\(n^{- 1/2}\\), which implies that \\(\\mathbf{a}_{0}\\mathbf{e}_{0} = {(n^{-1}\\sum_{t = 1}^{n}x_{t},\\ldots,n^{- 1}\\sum_{t=1}^{n}x_{t})}^{'}\\);\n\\[\n\\mathbf{c}_{j}=(\\frac{n}{2})^{- 1/2}{(\\cos\\omega_{j},\\cos{2\\omega}_{j},\\ldots,\\cos{n\\omega_{j}})}^{'}, for 1 \\leq j \\leq \\lbrack \\frac{(n - 1)}{2}\\rbrack\n\\]\n\\[\n\\mathbf{s}_{j} = {(\\frac{n}{2})}^{-1/2}{(\\sin{\\omega_{j}},\\sin{2\\omega_{j}},\\ldots,\\sin{n\\omega_{j}})}^{'},\\ for\\ 1 \\leq j \\leq \\lbrack \\frac{(n - 1)}{2} \\rbrack\n\\]\n\\[\n\\mathbf{e}_{n/2} = {(- (n^{-\\frac{1}{2}}),n^{- \\frac{1}{2}},\\ldots,{-(n)}^{- \\frac{1}{2}}),n^{-\\frac{1}{2}})}^{'}\n\\]\nEquation Equation 5 can be seen as an OLS regression of \\(x_{t}\\) on a constant and the trigonometric terms. As the vector of explanatory variables includes \\(n\\) elements, the number of explanatory variables in Equation 5 is equal to the number of observations. HAMILTON, J.D. (1994) shows that the explanatory variables are linearly independent, which implies that an OLS regression yields a perfect fit (i.e. without an error term). The coefficients have the form of a simple OLS projection of the data on the orthonormal basis:\n\\[\n{\\widehat{a}}_{0}=\\frac{1}{\\sqrt{n}}\\sum_{t=1}^{n}x_{t}\n\\tag{1}\\] \n\\[\n{\\widehat{a}}_{n/2}=\\frac{1}{\\sqrt{n}}\\sum_{t=1}^{n}{(-1)}^{t}x_{t}(   \\text{only when n is even})\n\\tag{2}\\] \n\\[\n{\\widehat{a}}_{0}=\\frac{1}{\\sqrt{n}}\\sum_{t=1}^{n}x_{t}\n\\tag{3}\\] \n\\[\n{\\widehat{\\alpha}}_{j} = 2^{1/2}r_{j}\\cos{\\theta_{j}} = {(\\frac{n}{2})}^{- 1/2}\\sum_{t = 1}^{n}x_{t}\\cos{(t\\frac{2\\pi j}{n})}, j   = 1,\\ldots,\\lbrack\\frac{n - 1}{2}\\rbrack\n\\tag{4}\\] \n\\[\n{\\widehat{\\beta}}_{j} = 2^{1/2}r_{j}\\sin{\\theta_{j}} = {(\\frac{n}{2})}^{-1/2}\\sum_{t = 1}^{n}x_{t}\\sin{(t\\frac{2\\pi j}{n})}, j = 1,\\ldots,\\lbrack\\frac{n - 1}{2}\\rbrack\n\\tag{5}\\] \nWith Equation 5 the total sum of squares \\(\\sum_{t = 1}^{n}| x_{t} |^{2}\\) can be decomposed into \\(2 \\times \\lbrack\\frac{n - 1}{2}\\rbrack\\) components corresponding to \\(\\mathbf{c}_{j}\\) and \\(\\mathbf{s}_{j}\\), which are grouped to produce the “frequency \\(ω_{j}\\)” component for \\(1 \\geq j \\geq \\lbrack\\frac{n - 1}{2}\\rbrack\\). As it is shown in the table below, the value of the periodogram at the frequency \\(\\omega_{j}\\) is the contribution of the \\(j^{\\text{th}}\\) harmonic to the total sum of squares \\(\\sum_{t = 1}^{n}| x_{t} |^{2}\\).\nDecomposition of sum of squares into components corresponding to the harmonics\n\n\n\n\n\n\n\n\n\n\nFrequency\nDegrees of freedom\nSum of squares decomposition\n\n\n\n\n\\(\\omega_{0}\\)(mean)\n1\n\\({a_{0}^{2}}_{\\ }=n^{- 1}(\\sum_{t=1}^{n}x_{t})^{2} = I( 0)\\)\n\n\n\\(\\omega_{1}\\)\n2\n\\({2r_{1}^{2}}_{\\ } = 2{|a_{1}|}^{2} = 2I(\\omega_{1})\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(\\omega_{k}\\)\n2\n\\({2r_{k}^{2}}_{\\ } = 2{|a_{k}|}^{2} = 2I(\\omega_{k})\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(\\omega_{n/2} = \\pi\\) (excluded if \\(n\\) is odd)\n1\n\\(a_{n/2}^{2} = I(\\pi)\\)\n\n\nTotal\n\\(\\mathbf{n}\\)\n\\(\\sum_{\\mathbf{t = 1}}^{\\mathbf{n}}\\mathbf{x}_{\\mathbf{t}}^{\\mathbf{2}}\\)\n\n\n\nSource: DE ANTONIO, D., and PALATE, J. (2015).\nObviously, if series were random then each component \\(I(\\omega_{j})\\) would have the same expectation. On the contrary, when the series contains a systematic sine component having a frequency \\(j\\) and amplitude \\(A\\) then the sum of squares \\(I(\\omega_{j})\\) increases with \\(A\\). In practice, it is unlikely that the frequency \\(j\\) of an unknown systematic sine component would exactly match any of the frequencies, for which periodogram have been calculated. Therefore, the periodogram would show an increase in intensities in the immediate vicinity of \\(j\\).8\nNote that in JDemetra+ the periodogram object corresponds exactly to the contribution to the sum of squares of the standardised data, since the series are divided by their standard deviation for computational reasons.\nUsing the decomposition presented in table above the periodogram can be expressed as:\n\\[\nI(\\omega_{j})\\mathbf{=}\\begin{matrix}r_{j}^{2} = \\frac{1}{2}{(\\alpha}_{j}^{2} + \\beta_{j}^{2}) = \\ {\\frac{1}{n}(\\sum_{t = 1}^{n}{x_{t}\\cos{( {t\\frac{2\\pi j}{n}}_{\\ })\\ }})}^{2} + \\frac{1}{n}(\\sum_{t = 1}^{n}{x_{t}\\sin( t\\frac{2\\pi j}{n})_{\\ }})^{2} \\\\\n\\end{matrix}\n\\tag{6}\\] \nwhere \\(j = 0,\\ldots,\\lbrack \\frac{n}{2} \\rbrack\\).\nSince \\(\\mathbf{x} - \\overline{\\mathbf{x}}\\) are generated by an orthonormal basis, and \\(\\overline{\\mathbf{x}}\\mathbf{=}a_{0}\\mathbf{e}_{0}\\) Equation 5 can be rearranged to show that the sum of squares is equal to the sum of the squared coefficients:\n\\[\n\\mathbf{x} - a_{0}\\mathbf{e}_{0} =\\sum_{j=1}^{\\lbrack(n - 1)/2\\rbrack}(\\alpha_{j}\\mathbf{c}_{j}+\\beta_{j}\\mathbf{s}_{j}) + a_{n/2}\\mathbf{e}_{n/2}\n\\tag{7}\\] \nThus the sample variance of \\(x_{t}\\) can be expressed as:\n\\[\nn^{- 1}\\sum_{t=1}^{n}{(x_{t}-\\overline{x})}^{2}=n^{-1}(\\sum_{k=1}^{\\lbrack(n - 1)/2\\rbrack}2{r_{j}}^{2}\n+{a_{n/2}}^{2})\n\\tag{8}\\] \nwhere \\(a_{n/2}^{2}\\) is excluded if \\(n\\) is odd.\nThe term \\(2{r_{j}}^{2}\\) in Equation 14 is then the contribution of the \\(j^{\\text{th}}\\) harmonic to the variance and Equation 14 shows then how the total variance is partitioned.\nThe periodogram ordinate \\(I(\\omega_{j})\\) and the autocovariance coefficient \\(\\gamma(k)\\) are both quadratic forms of \\(x_{t}\\). It can be shown that the periodogram and autocovarinace function are related and the periodogram can be written in terms of the sample autocovariance function for any non-zero Fourier frequency \\(ω_{j}\\) :9\n\\[\nI(\\omega_{j}) = \\sum_{| k | &lt; n}^{\\ }{\\widehat{\\gamma}( k)}_{\\ }e^{- ik\\omega_{j}} = {\\widehat{\\gamma}( 0)}_{\\ } + 2\\sum_{k = 1}^{n - 1}{\\widehat{\\gamma}( k)\\cos{(k\\omega_{j})}}_{\\ }\n\\]\nand for the zero frequency \\(\\ I( 0) = n| \\overline{x} |^{2}\\).\nOnce comparing Equation 15 with an expression for the spectral density of a stationary process:\n\\[\nf(\\omega_{\\ }) = \\frac{1}{2\\pi}\\sum_{k &lt; - \\infty}^{\\infty}{\\gamma( k)}_{\\ }e^{- ik\\omega_{\\ }} = \\frac{1}{2\\pi}\\lbrack {\\gamma( 0)}_{\\ } + 2(\\sum_{k = 1}^{\\infty}{\\gamma( k)\\cos{(k\\omega_{\\ })}}) \\rbrack\n\\]\nIt can be noticed that the periodogram is a sample analogue of the population spectrum. In fact, it can be shown that the periodogram is asymptotically unbiased but inconsistent estimator of the population spectrum \\(f(\\omega)\\).[^75] Therefore, the periodogram is a wildly fluctuating, with high variance, estimate of the spectrum. However, the consistent estimator can be achieved by applying the different linear smoothing filters to the periodogram, called lag-window estimators. The lag-window estimators implemented in JDemetra+ includes square, Welch, Tukey, Barlett, Hanning and Parzen. They are described in DE ANTONIO, D., and PALATE, J. (2015). Alternatively, the model-based consistent estimation procedure, resulting in autoregressive spectrum estimator, can be applied.\n\n\nMethod 2: Autoregressive spectrum estimation\nBROCKWELL, P.J., and DAVIS, R.A. (2006) point out that for any real-valued stationary process \\((x_{t})\\) with continuous spectral density \\(f(\\omega)\\) it is possible to find both \\(AR(p)\\) and \\(MA(q)\\) processes which spectral densities are arbitrarily close to \\(f(\\omega)\\). For this reason, in some sense, \\((x_{t})\\) can be approximated by either \\(AR(p)\\) or \\(MA(q)\\) process. This fact is a basis of one of the methods of achieving a consistent estimator of the spectrum, which is called an autoregressive spectrum estimation. It is based on the approximation of the stochastic process \\((x_{t})\\) by an autoregressive process of sufficiently high order \\(p\\):\n\\[\nx_{t} = \\mu + (\\phi_{1}B + \\ldots + \\phi_{p}B^{p})x_{t} + \\varepsilon_{t}\n\\]\nwhere \\(\\varepsilon_{t}\\) is a white-noise variable with mean zero and a constant variance.\nThe autoregressive spectrum estimator for the series \\(x_{t}\\) is defined as: 10\n\\[\n\\widehat{s}(\\omega) = 10\\operatorname{\\times}{\\log_{10}\\frac{\\sigma_{x}^{2}}{2\\pi{|1 - \\sum_{k = 1}^{p}{\\widehat{\\phi}}_{k}e^{- ik\\omega}|}^{2}}}\n\\]\nwhere:\n\n\\(\\omega\\)– frequency, \\(0 \\leq \\omega \\leq \\pi\\);\n\\(\\sigma_{x}^{2}\\) – the innovation variance of the sample residuals;\n\\({\\widehat{\\phi}}_{k}\\) – \\(\\text{AR}(k)\\) coefficient estimates of the linear regression of \\(x_{t} - \\overline{x}\\) on \\(x_{t - k} - \\overline{x}\\), \\(1 \\leq k \\leq p\\).\n\nThe autoregressive spectrum estimator is used in the visual spectral analysis tool for detecting significant peaks in the spectrum. The criterion of visual significance, implemented in JDemetra+, is based on the range \\({\\widehat{s}}^{\\max} - {\\widehat{s}}^{\\min}\\) of the \\(\\widehat{s}(\\omega)\\) values, where \\({\\widehat{s}}^{\\max} = \\max_{k}\\widehat{s}(\\omega_{k})\\); \\({\\widehat{s}}^{\\min} = \\min_{k}\\widehat{s}(\\omega_{k});\\) and \\(\\widehat{s}(\\omega_{k})\\) is \\(k^{\\text{th}}\\) value of autoregressive spectrum estimator.\nThe particular value is considered to be visually significant if, at a trading day or at a seasonal frequency \\(\\omega_{k}\\) (other than the seasonal frequency \\(\\omega_{60} = \\pi\\)), \\(\\widehat{s}(\\omega_{k})\\) is above the median of the plotted values of \\(\\widehat{s}(\\omega_{k})\\) and is larger than both neighbouring values \\(\\widehat{s}(\\omega_{k - 1})\\) and \\(\\widehat{s}(\\omega_{k + 1})\\) by at least \\(\\frac{6}{52}\\) times the range \\({\\widehat{s}}^{\\max} - {\\widehat{s}}^{\\min}\\).\nFollowing the suggestion of SOUKUP, R.J., and FINDLEY, D.F. (1999), JDemetra+ uses an autoregressive model spectral estimator of model order 30. This order yields high resolution of strong components, meaning peaks that are sharply defined in the plot of \\(\\widehat{s}(\\omega)\\) with 61 frequencies. The minimum number of observations needed to compute the spectrum is set to \\(n=80\\) for monthly data and to \\(n=60\\) for quarterly series while the maximum number of observations considered for the estimation is 121. Consequently, with these settings it is possible to identify up to 30 peaks in the plot of 61 frequencies. By choosing \\(\\omega_{k} = \\frac{\\text{πk}}{60}\\) for \\(k=0,1,...,60\\) the density estimates are calculated at exact seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year).\nThe model order can also be selected based on the AIC criterion (in practice it is much lower than 30). A lower order produces the smoother spectrum, but the contrast between the spectral amplitudes at the trading day frequencies and neighbouring frequencies is weaker, and therefore not as suitable for automatic detection.\nSOUKUP, R.J., and FINDLEY, D.F. (1999) also explain that the periodogram can be used in the visual significance test as it has as good as those of the AR(30) spectrum abilities to detect trading day effect, but also has a greater false alarm rate11.\n\n\nMethod 3: Tukey spectrum"
  },
  {
    "objectID": "M-spectral-analysis.html#identification-of-spectral-peaks",
    "href": "M-spectral-analysis.html#identification-of-spectral-peaks",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Identification of spectral peaks",
    "text": "Identification of spectral peaks\nIdentification of seasonal peaks in a Tukey periodogram and in an autoregressive spectrum\nIn order to decide whether a series has a seasonal component that is predictable (stable) enough, these tests use visual criteria and formal tests for the periodogram. The periodogram is calculated using complete years, so that the set of Fourier frequencies contains exactly all seasonal frequencies12.\nThe tests rely on two basic principles:\n\nThe peaks associated with seasonal frequencies should be larger than the median spectrum for all frequencies and;\nThe peaks should exceed the spectrum of the two adjacent values by more than a critical value.\n\n\nJDemetra+ performs this test on the original series. If these two requirements are met, the test results are displayed in green. The statistical significance of each of the seasonal peaks (i.e. frequencies \\(\\frac{\\pi}{6},\\ \\frac{\\pi}{3},\\ \\frac{\\pi}{2},\\ \\frac{2\\pi}{3}\\) and \\(\\frac{5\\pi}{6}\\) corresponding to 1, 2, 3, 4 and 5 cycles per year) is also displayed. The seasonal and trading days frequencies depends on the frequency of time series. They are shown in the table below. The symbol \\(d\\) denotes a default frequency and is described below the table.\n\nThe seasonal and trading day frequencies by time series frequency\n\n\n\n\n\n\n\n\n\n\nNumber of months per fullperiod\nSeasonal frequency\nTrading day frequency (radians)\n\n\n\n\n12\n\\(\\frac{\\pi}{6},\\frac{\\pi}{3},\\ \\frac{\\pi}{2},\\frac{2\\pi}{3},\\ \\frac{5\\pi}{6},\\ \\pi\\)\n\\(d\\),2.714\n\n\n4\n\\(\\frac{\\pi}{2}\\), \\(\\pi\\)\n\\(d\\), 1.292, 1.850, 2.128\n\n\n3\n\\(\\pi\\)\n\\(d\\)\n\n\n2\n\\(\\pi\\)\n\\(d\\)\n\n\n\nThe calendar (trading day or working day) effects, related to the variation in the number of different days of the week per period, can induce periodic patterns in the data that can be similar to those resulting from pure seasonal effects. From the theoretical point of view, trading day variability is mainly due to the fact that the average number of days in the months or quarters is not equal to a multiple of 7 (the average number of days of a month in the year of 365.25 days is equal to \\(\\frac{365.25}{12} = 30.4375 days\\)). This effect occurs \\(\\frac{365.25}{12} \\times \\frac{1}{7} = 4.3482 times per month\\): one time for each one of the four complete weeks of each month, and a residual of 0.3482 cycles per month, i.e. \\(0.3482 \\times 2\\pi = 2.1878 radians\\). This turns out to be a fundamental frequency for the effects associated with monthly data. In JDemetra+ the fundamental frequency corresponding to 0.3482 cycles per month is used in place of the closest frequency \\(\\frac{\\text{πk}}{60}\\). Thus, the quantity \\(\\frac{\\pi \\times 42}{60}\\) is replaced by \\(\\omega_{42} = 0.3482 \\times 2\\pi = 2.1878\\). The frequencies neighbouring \\(\\omega_{42}\\), i.e. \\(\\omega_{41}\\) and \\(\\omega_{43}\\) are set to, respectively, \\(2.1865 - \\frac{1}{60}\\) and \\(2.1865 + \\frac{1}{60}\\).\nThe default frequencies (\\(d\\)) for calendar effect are: 2.188 (monthly series) and 0.280 (quarterly series). They are computed as:\n\\[\n\\omega_{\\text{ce}} = \\frac{2\\pi}{7}\\left( n - 7 \\times \\left\\lbrack \\frac{n}{7} \\right \\rbrack \\right)\n\\tag{9}\\] \nwhere \\(n = \\frac{365.25}{s}\\), \\(s = 4\\) for quarterly series and \\(s = 12\\) for monthly series.\nOther frequencies that correspond to trading day frequencies are: 2.714 (monthly series) and 1.292, 1.850, 2.128 (quarterly series).\nIn particular, the calendar frequency in monthly data (marked in red on the figure below) is very close to the seasonal frequency corresponding to 4 cycles per year \\(\\text{ω}_{40} = \\frac{2}{3}\\pi = 2.0944\\).\n\n\n\nPeriodogram with seasonal (grey) and calendar (red) frequencies highlighted\n\n\nThis implies that it may be hard to disentangle both effects using the frequency domain techniques.\ncomment3: end part theory&gt;spectral analysis&gt;identification of spectral peaks\n\nin Tukey spectrum\ncomes from Identification of seasonal peaks in a Tukey spectrum\n\n\nTukey Spectrum definition\nThe Tukey spectrum belongs to the class of lag-window estimators. A lag window estimator of the spectral density \\(f(\\omega)=\\frac{1}{2\\pi}\\sum_{k&lt;-\\infty}^{\\infty}\\gamma(k)e^{i k \\omega}\\) is defined as follows:\n\\[\n\\hat{f}_{L}(\\omega)=\\frac{1}{2\\pi}\\sum_{\\left| h \\right| \\leq r } w(h/r)\\hat{\\gamma}(h)e^{i h \\omega}\n\\]\nwhere \\(\\hat{\\gamma}(.)\\) is the sample autocovariance function, \\(w(.)\\) is the lag window, and \\(r\\) is the truncation lag. \\(\\left| w(x)\\right|\\) is always less than or equal to one, \\(w(0)=1\\) and \\(w(x)=0\\) for \\(\\left| x \\right| &gt; 1\\). The simple idea behind this formula is to down-weight the autocovariance function for high lags where \\(\\hat{\\gamma}(h)\\) is more unreliable. This estimator requires choosing \\(r\\) as a function of the sample size such that \\(r/n \\rightarrow 0\\) and \\(r\\rightarrow \\infty\\) when \\(n \\rightarrow \\infty\\) . These conditions guarantee that the estimator converges to the true density.\nJDemetra+ implements the so-called Blackman-Tukey (or Tukey-Hanning) estimator, which is given by \\(w(h/r)=0.5(1+cos(\\pi h/r))\\) if \\(\\left| h/r \\right| \\leq 1\\) and \\(0\\) otherwise.\nThe choice of large truncation lags \\(r\\) decreases the bias, of course, but it also increases the variance of the spectral estimate and decreases the bandwidth.\nJDemetra+ allows the user to modify all the parameters of this estimator, including the window function.\n\n\nGraphical Test\nThe current JDemetra+ implementation of the seasonality test is based on a \\(F(d_{1},d_{2})\\) approximation that has been originally proposed by Maravall (2012) for TRAMO-SEATS. This test is has been designed for a Blackman-Tukey window based on a particular choices of the truncation lag \\(r\\) and sample size. Following this approach, we determine visually significant peaks for a frequency \\(\\omega_{j}\\) when\n\\[\n\\frac{2 f_{x}(\\omega_{j})}{\\left[ f_{x}(\\omega_{j+1})+ f_{x}(\\omega_{j-1}) \\right]} \\ge CV(\\omega_{j})\n\\]\nwhere \\(CV(\\omega_{j})\\) is the critical value of a \\(F(d_{1},d_{2})\\) distribution, where the degrees of freedom are determined using simulations. For \\(\\omega_{j}= \\pi\\), we have a significant peak when \\(\\frac{f_{x}(\\omega_{[n/2]})}{\\left[ f_{x}(\\omega_{[(n-1)/2]})\\right]} \\ge CV(\\omega_{j})\\)\nTwo significant levels for this test are considered: \\(\\alpha=0.05\\) (code “t”) and \\(\\alpha=0.01\\) (code “T”).\nAs opposed to the AR spectrum, which is computed on the basis of the last \\(120\\) data points, we will use here all available observations. Those critical values have been calculated given the recommended truncation lag \\(r=79\\) for a sample size within the interval \\(\\in [80,119]\\) and \\(r=112\\) for \\(n \\in [120,300]\\) . The \\(F\\) approximation is less accurate for sample sizes larger than \\(300\\). For quarterly data, \\(r=44\\), but there are no recommendations regarding the required sample size.\n\n\nUse\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\ntktest\n\n\nJDemetra+ considers critical values for \\(\\alpha=1\\%\\) (code “T”) and \\(\\alpha=5\\%\\) (code “t”) at each one of the seasonal frequencies represented in the table below, e.g. frequencies \\(\\frac{\\pi}{6}, \\frac{\\pi}{3}, \\frac{\\pi}{2}, \\frac{2\\pi}{3}\\text{ and } \\frac{5\\pi}{6}\\) corresponding to 1, 2, 3, 4, 5 and 6 cycles per year in this example, since we are dealing with monthly data. The codes “a” and “A” correpond to the so-called AR spectrum, so ignore them for the moment.\nThe seasonal and trading day frequencies by time series frequency\n\n\n\n\n\n\n\n\nNumber of months per full period\nSeasonal frequency\nTrading day frequency (radians)\n\n\n\n\n12\n\\(\\frac{\\pi}{6},\\frac{\\pi}{3},\\ \\frac{\\pi}{2},\\frac{2\\pi}{3},\\ \\frac{5\\pi}{6},\\ \\pi\\)\n\\(d\\), 2.714\n\n\n6\n\\(\\frac{\\pi}{3},\\frac{2\\pi}{3}\\), \\(\\pi\\)\n\\(d\\)\n\n\n4\n\\(\\frac{\\pi}{2}\\), \\(\\pi\\)\n\\(d\\), 1.292, 1.850, 2.128\n\n\n3\n\\(\\pi\\)\n\\(d\\)\n\n\n2\n\\(\\pi\\)\n\\(d\\)\n\n\n\nCurrently, only seasonal frequencies are tested, but the program allows you to manually plot the Tukey spectrum and focus your attention on both seasonal and trading day frequencies.\n\n\nReferences\n\nTukey, J. (1949). The sampling theory of power spectrum estimates., Proceedings Symposium on Applications of Autocorrelation Analysis to Physical Problems, NAVEXOS-P-735, Office of Naval Research, Washington, 47-69\n\n\n\nin AR Spectrum definition\ncomes from: “Identification of seasonal peaks in autoregressive spectrum”\nThe estimator of the spectral density at frequency \\(\\lambda \\in [0,\\pi]\\) will be given by the assumption that the series will follow an AR(p) process with large \\(p\\). The spectral density of such model, with an innovation variance \\(var(x_{t})=\\sigma^2_x\\), is expressed as follows:\n\\[\n10\\times log_{10} f_x(\\lambda)=10\\times log_{10} \\frac{\\sigma^2_x}{2\\pi \\left|\\phi(e^{i\\lambda}) \\right|^2 }=10\\times log_{10} \\frac{\\sigma^2_x}{2\\pi \\left|1-\\sum_{k=1}^{p}\\phi_k e^{i k \\lambda}) \\right|^2 }\n\\]\nwhere:\n\n\\(\\phi_k\\) denotes the AR(k) coefficient ;\n\\(e^{-ik\\lambda}=cos⁡(-ik\\lambda)+i sin⁡(-ik\\lambda)\\).\n\nSoukup and Findely (1999) suggest the use of p=30, which in practice much larger than the order that would result from the AIC criterion. The minimum number of observations needed to compute the spectrum is set to n=80 for monthly data (or n=60) for quarterly series. In turn, the maximum number of observations considered for the estimation is n=121. This choice offers enough resolution, being able to identify a maximum of 30 peaks in a plot of 61 frequencies: by choosing \\(\\lambda_j=\\pi j/60\\),for \\(j=0,1,…,60\\), we are able to calculate our density estimates at exact seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year). Note that \\(x\\) cycles per year can be converted into cycles per month by simply dividing by twelve, \\(x/12\\), and to radians by applying the transformation \\(2\\pi(x/12)\\).\nThe traditional trading day frequency corresponding to 0.348 cycles per month is used in place of the closest frequency \\(\\pi j/60\\). Thus, we replace \\(\\pi 42/60\\) by \\(\\lambda_{42}=0.348\\times 2 \\pi = 2.1865\\). The frequencies neighbouring \\(\\lambda_{42}\\) are set to \\(\\lambda_{41}= 2.1865-1/60\\) and \\(\\lambda_{43}= 2.1865+1/60\\). The periodogram below illustrates the proximity of this trading day frequency \\(\\lambda_{42}\\) (red shade) and the frequency corresponding to 4 cycles per year \\(\\lambda_{40}=2.0944\\). This proximity is precisely what poses the identification problems: the AR spectrum boils down to a smoothed version of the periodogram and the contribution of the of the trading day frequency may be obscured by the leakage resulting from the potential seasonal peak at \\(\\lambda_{40}\\), and vice-versa.\n\n\n\nPeriodogram with seasonal (grey) and calendar (red) frequencies highlighted\n\n\nJDemetra+ allows the user to modify the number of lags of this estimator and to change the number of observations used to determine the AR parameters. These two options can improve the resolution of this estimator.\n\n\nGraphical Test\nThe statistical significance of the peaks associated to a given frequency can be informally tested using a visual criterion, which has proved to perform well in simulation experiments. Visually significant peaks for a frequency \\(\\lambda_{j}\\) satisfy both conditions:\n\n\\(\\frac{f_{x}(\\lambda_{j})- \\max \\left\\{f_{x}(\\lambda_{j+1}),f_{x}(\\lambda_{j-1}) \\right\\}}{\\left[ \\max_{k}f_{x}(\\lambda_{k})-\\min_{i}f_{x}(\\lambda_{i}) \\right]}\\ge CV(\\lambda_{j})\\), where \\(CV(\\lambda_{j})\\) can be set equal to \\(6/52\\) for all \\(j\\)\n\\(f_{x}(\\lambda_{j})&gt; median_{j} \\left\\{ f_{x}(\\lambda_{j}) \\right\\}\\), which guarantees \\(f_{x}(\\lambda_{j})\\) it is not a local peak.\n\nThe first condition implies that if we divide the range \\(\\max_{k}f_{x}(\\lambda_{k})-\\min_{i}f_{x}(\\lambda_{i})\\) in 52 parts (traditionally represented by stars) the height of each pick should be at least 6 stars.\n\n\nUse\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\nartest\n\n\nJDemetra+ considers critical values for \\(\\alpha=1\\%\\) (code “A”) and \\(\\alpha=5\\%\\) (code “a”) at each one of the seasonal frequencies represented in the table below, e.g. frequencies \\(\\frac{\\pi}{6}, \\frac{\\pi}{3}, \\frac{\\pi}{2}, \\frac{2\\pi}{3}\\text{ and } \\frac{5\\pi}{6}\\) corresponding to 1, 2, 3, 4, 5 and 6 cycles per year in this example, since we are dealing with monthly data. The codes “t” and “T” correpond to the so-called Tukey spectrum, so ignore them for the moment.\nThe seasonal and trading day frequencies by time series frequency\n\n\n\n\n\n\n\n\n\n\nNumber of months per full period\nSeasonal frequency\nTrading day frequency (radians)\n\n\n\n\n12\n\\(\\frac{\\pi}{6},\\frac{\\pi}{3},\\ \\frac{\\pi}{2},\\frac{2\\pi}{3},\\ \\frac{5\\pi}{6},\\ \\pi\\)\n\\(d\\), 2.714\n\n\n6\n\\(\\frac{\\pi}{3},\\frac{2\\pi}{3}\\), \\(\\pi\\)\n\\(d\\)\n\n\n4\n\\(\\frac{\\pi}{2}\\), \\(\\pi\\)\n\\(d\\), 1.292, 1.850, 2.128\n\n\n3\n\\(\\pi\\)\n\\(d\\)\n\n\n2\n\\(\\pi\\)\n\\(d\\)\n\n\n\nCurrently, only seasonal frequencies are tested, but the program allows you to manually plot the AR spectrum and focus your attention on both seasonal and trading day frequencies. Agustin Maravall has conducted a simulation experiment to calculate \\(CV(\\lambda_{42})\\) (trading day frequency) and proposes to set for all \\(j\\) equal to the critical value associated to the trading frequency, but this is currently not part of the current automatic testing procedure of JDemetra+.\n\n\nReferences\n\nSoukup, R.J., and D.F. Findley (1999) On the Spectrum Diagnosis used by X12-ARIMA to Indicate the Presence of Trading Day Effects After Modeling or Adjustment. In Proceedengs of the American Statistical Association. Business and Economic Statistics Section, 144-149, Alexandria, VA.\n\n\n\nin a Periodogram\ncomes from: Identification of seasonal peaks in periodogram\nThe periodogram \\(I(\\omega_j)\\) of \\(\\mathbf{X} \\in \\mathbb{C}^n\\) is defined as the squared of the Fourier transform\n\\[\nI(\\omega_{j})=a_{j}^{2}=n^{-1}\\left| \\sum_{t=1}^{n}\\mathbf{X_t} e^{-it\\omega_j} \\right|^{2},\n\\]\nwhere the Fourier frequencies \\(\\omega_{j}\\) are given by multiples of the fundamental frequency \\(\\frac{2\\pi}{n}\\):\n\\[\n\\omega_{j}= \\frac{2\\pi j}{n}, -\\pi &lt; \\omega_{j} \\leq \\pi\n\\]\nAn orthonormal basis in \\(\\mathbb{R}^n\\):\n\\[\n\\left\\{ e_0, ~~~~~~c_1, s_1, ~~~~~\\ldots~~~~~\\ , ~~~~c_{[(n-1)/2]}, s_{[(n-1)/2]}~~~~,~~~~~~ e_{n/2}  \\right\\},\n\\]\nwhere \\(e_{n/2}\\) is excluded if \\(n\\) is odd,\ncan be used to project the data and obtain the spectral decomposition\nThus, the periodogram is given by the projection coefficients and represents the contribution of the jth harmonic to the total sum of squares, as illustrated by Brockwell and Davis (1991):\n\n\n\nSource\nDegrees of freedom\n\n\n\n\nFrequency \\(\\omega_{0}\\)\n1\n\n\nFrequency \\(\\omega_{1}\\)\n2\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\nFrequency \\(\\omega_{k}\\)\n2\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\nFrequency \\(\\omega_{n/2}=\\pi\\)\n1\n\n\n(excluded if \\(n\\) is odd)\n\n\n\n\\(=========\\)\n\\(======\\)\n\n\nTotal\nn\n\n\n\n\\[\n~~~~\n\\]\nIn JDemetra+, the periodogram of \\(\\mathbf{X} \\in \\mathbb{R}^n\\) is computed for the standardized time series.\n\n\nDefining a F-test\nBrockwell and Davis (1991, section 10.2) exploit the fact that the periodogram can be expressed as the projection on the orthonormal basis defined above to derive a test. Thus, under the null hypothesis:\n\n\\(2I(\\omega_{k})= \\| P_{\\bar{sp}_{\\left\\{ c_{k},s_{k} \\right\\}}} \\mathbf{X} \\|^{2} \\sim \\sigma^{2} \\chi^{2}(2)\\), for Fourier frequencies \\(0 &lt; \\omega_{k}=2\\pi k/n &lt; \\pi\\)\n\\(I(\\pi)= \\| P_{\\bar{sp}_{\\left\\{ e_{n/2} \\right\\}}} \\mathbf{X} \\|^{2} \\sim \\sigma^{2} \\chi^{2}(1)\\), for \\(\\pi\\)\n\nBecause \\(I(\\omega_{k})\\) is independent from the projection error sum of squares, we can define our F-test statistic as follows:\n\n\\(\\frac{ 2I(\\omega_{k})}{\\|\\mathbf{X}-P_{\\bar{sp}_{\\left\\{ e_0,c_{k},s_{k} \\right\\}}} \\mathbf{X}\\|^2} \\frac{n-3}{2} \\sim F(2,n-3)\\), for Fourier frequencies \\(0 &lt; \\omega_{k}=2\\pi k/n &lt; \\pi\\)\n\\(\\frac{ I(\\pi)}{\\|\\mathbf{X}-P_{\\bar{sp}_{\\left\\{ e_0,e_{n/2} \\right\\}}} \\mathbf{X}\\|^2} \\frac{n-2}{1} \\sim F(1,n-2)\\), for \\(\\pi\\)\n\nwhere:\n\n\\(\\|\\mathbf{X}-P_{\\bar{sp}_{\\left\\{ e_0,c_{k},s_{k} \\right\\}}} \\mathbf{X}\\|^2 = \\sum_{i=1}^{n}\\mathbf{X^2_i}-I(0)-2I(\\omega_{k}) \\sim \\sigma^{2} \\chi^{2}(n-3)\\) for Fourier frequencies \\(0 &lt; \\omega_{k}=2\\pi k/n &lt; \\pi\\)\n\\(\\|\\mathbf{X}-P_{\\bar{sp}_{\\left\\{ e_0,e_{n/2} \\right\\}}} \\mathbf{X}\\|^2 = \\sum_{i=1}^{n}\\mathbf{X^2_i}-I(0)-I(\\pi) \\sim \\sigma^{2} \\chi^{2}(n-2)\\) for \\(\\pi\\)\n\nThus, we reject the null if our F-test statistic computed at a given seasonal frequency (different from \\(\\pi\\)) is larger than \\(F_{1-α}(2,n-3)\\). If we consider \\(\\pi\\), our test statistic follows a \\(F_{1-α}(1,n-2)\\) distribution.\n\n\nSeasonality test\nThe implementation of JDemetra+ considers simultaneously the whole set of seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year). Thus, the resulting test-statistic is:\n\\[\n\\frac{ 2I(\\pi/6)+ 2I(\\pi/3)+ 2I(2\\pi/3)+ 2I(5\\pi/6)+ \\delta I(\\pi)}{\\left\\|\\mathbf{X}-P_{\\bar{sp}_{\\left\\{ e_0,c_{1},s_{1},c_{2},s_{2},c_{3},s_{3},c_{4},s_{4},c_{5},s_{5}, \\delta e_{n/2} \\right\\}}} \\mathbf{X} \\right\\|^2} \\frac{n-12}{11} \\sim F(11-\\delta,n-12+\\delta)\n\\]\nwhere \\(\\delta=1\\) if \\(n\\) is even and 0 otherwise.\nIn small samples, the test performs better when the periodogram is evaluated as the exact seasonal frequencies. JDemetra+ modifies the sample size to ensure the seasonal frequencies belong to the set of Fourier frequencies. This strategy provides a very simple and effective way to eliminate the leakage problem.\nExample of how results are displayed:\n\n\n\nperiodtest\n\n\n\n\nReferences\nBrockwell, P.J., and R.A. Davis (1991). Times Series: Theory and Methods. Springer Series in Statistics."
  },
  {
    "objectID": "M-spectral-analysis.html#spectral-graphs",
    "href": "M-spectral-analysis.html#spectral-graphs",
    "title": "Spectral Analysis Principles and Tools",
    "section": "Spectral graphs",
    "text": "Spectral graphs\nprobably moove this part to GUI (Tools), just leave a link\ncomment3: start part case studies &gt; spectral graphs\nThis scenario is designed for advanced users interested in an in-depth analysis of time series in the frequency domain using three spectral graphs. Those graphs can also be used as a complementary analysis for a better understanding of the results obtained with some of the tests described above.\nEconomic time series are usually presented in a time domain (X-axis). However, for analytical purposes it is convenient to convert the series to a frequency domain due to the fact that any stationary time series can be expressed as a combination of cosine (or sine) functions. These functions are characterized with different periods (amount of time to complete a full cycle) and amplitudes (maximum/minimum value during the cycle).\nThe tool used for the analysis of a time series in a frequency domain is called a spectrum. The peaks in the spectrum indicate the presence of cyclical movements with periodicity between two months and one year. A seasonal series should have peaks at the seasonal frequencies. Calendar adjusted data are not expected to have peak at with a calendar frequency.\nThe periodicity of the phenomenon at frequency f is \\(\\frac{2\\pi}{f}\\). It means that for a monthly time series the seasonal frequencies \\(\\frac{\\pi}{6}, \\frac{\\pi}{3}, \\frac{\\pi}{2}, \\frac{2\\pi}{3}, \\frac{5\\pi}{6}\\) and \\(\\pi\\) correspond to 1, 2, 3, 4, 5 and 6 cycles per year. For example, the frequency \\(\\frac{\\pi}{3}\\) corresponds to a periodicity of 6 months (2 cycles per year are completed). For the quarterly series there are two seasonal frequencies: \\(\\frac{\\pi}{2}\\) (one cycle per year) and \\(\\pi\\) (two cycles per year). A peak at the zero frequency always corresponds to the trend component of the series. Seasonal frequencies are marked as grey vertical lines, while violet vertical lines represent the trading-days frequencies. The trading day frequency is 0.348 and derives from the fact that a daily component which repeats every seven days goes through 4.348 cycles in a month of average length 30.4375 days. It is therefore seen to advance 0.348 cycles per month when the data are obtained at twelve equally spaced times in 365.25 days (the average length of a year).\nThe interpretation of the spectral graph is rather straightforward. When the values of a spectral graph for low frequencies (i.e. one year and more) are large in relation to its other values it means that the long-term movements dominate in the series. When the values of a spectral graph for high frequencies (i.e. below one year) are large in relation to its other values it means that the series are rather trendless and contains a lot of noise. When the values of a spectral graph are distributed randomly around a constant without any visible peaks, then it is highly probable that the series is a random process. The presence of seasonality in a time series is manifested in a spectral graph by the peaks on the seasonal frequencies.\nSpectral graphs in GUI\n\n\n\nAuto-regressive spectrum’s properties\n\n\n\nThe spectral graphs are available from: Tools → Spectral analysis.\n\nWhen the first option is chosen JDemetra+ displays an empty Auto-regressive spectrum window. To start an analysis drag a single time series from the Providers window and drop it into the Drop data here area.\n\nAn auto-regressive spectrum graph available in JDemetra+ is based on the relevant tool from the X-13ARIMA-SEATS program. It shows the spectral density (spectrum) function, which reformulates the content of the stationary time series’ autocovariances in terms of amplitudes at frequencies of half a cycle per month or less. The number of observations, data transformations and other options such as the specification of the frequency grid and the order of the autoregressive polynomial (30 by default) can be specified by opening the Window → Properties from the main menu.\nThe Auto-regressive - Properties window contains the following options:\n\nLog - a log transformation of a time series;\nDifferencing - transforms a data by calculating a regular (order 1,2..) or seasonal (order 4, 12, depending on the time series frequency) differences;\nDifferencing lag - the number of lags that the program will use to take differences. For example, if Differencing lag = 3 then the differencing filter does not apply to the first lag (default) but to the third lag.\nLast years - a number of years at the end of the time series taken to produce autoregresive spectrum. By default, it is 0, which means that the whole time series is considered.\nAuto-regressive polynomial order - the number of lags in the AR model that is used to estimate the spectral density. By default, the order of the autoregressive polynomial is set to 30 lags.\nResolution - the value 1 plots the spectral density estimate for the frequencies \\(\\omega_{j} = \\frac{2\\pi j}{n}\\), where \\(n \\in ( - \\pi;\\pi)\\) is the size of the sample used to estimate the AR model. Increasing this value, which is set to 5 by default, will increase the precision of this grid.\n\nThe seasonality test described above uses an empirical criterion to check whether the series has a seasonal component that is predictable (stable) enough that it can be estimated with reasonable success. The peak in the auto-regressive spectrum has to be greater than the median of the 61 spectrum ordinates and has to exceed the two adjacent spectral values by more than a critical value. When such a case is detected, the test results are displayed in green.\n\nThe second spectral graph is a periodogram. To perform the analysis of a single time series using this tool, choose Tools →Spectral analysis → Periodogram and drag and drop a series from the Providers window to the empty Periodogram window.\n\nThe sample size and data transformations can be specified by opening the Window → Properties, in the main menu. The Periodogram - Properties window contains the following options:\n\nLog - a log transformation of a time series;\nDifferencing - transforms the data by calculating regular (order 1,2..) or seasonal (order 4, 12, depending on the time series frequency) differences;\nDifferencing lag - the number of lags that you will use to take differences. For example, if Differencing lag = 3 then the differencing filter does not apply to the first lag (default) but to the third lag.\nLast years - the number of years at the end of the time series taken to produce periodogram. By default it is 0, which means that the whole time series is considered.\n\n\nThe periodogram was one of the earliest tools used for the analysis of time series in the frequency domain. It enables the user to identify the dominant periods (or frequencies) of a time series. In general, the periodogram is a wildly fluctuating estimate of the spectrum with a high variance and is less stable than an auto-regressive spectrum.\n\nThe third spectral graph is the Tukey spectrum. To perform the analysis of time series using this tool, choose Tools → Spectral analysis → Tukey spectrum and drag and drop a single series from the Providers window to the empty Periodogram window.\n\nThe Tukey spectrum estimates the spectral density by smoothing the periodogram.\n\nThe options for the Tuckey window can be specified by opening the Window → Properties from the main menu. The Periodogram - Properties window contains the following options:\n\nLog - a log transformation of a time series.\nDifferencing - transforms the data by calculating regular (order 1, 2..) or seasonal (order 4, 12, depending on the time series frequency) differences.\nDifferencing lag - the number of lags that you will use to take differences. For example, if Differencing lag = 3 then the differencing filter does not apply to the first lag (default) but to the third lag.\nTaper part – parameter larger than 0 and smaller or equal to one that shapes the curvature of the smoothing function that is applied to the auto-covariance function.\nWindow length – the size of the window that is used to smooth the auto-covariance function. A value of zero includes the whole series.\nWindow type – it refers to the weighting scheme that it is used to smooth the auto-covariance function. The available windows types (Square, Welch, Tukey, Barlett, Hamming, Parzen) are suitable to estimate the spectral density.\n\n\n\ncomment3: end part case studies &gt; spectral graphs"
  },
  {
    "objectID": "M-spectral-analysis.html#footnotes",
    "href": "M-spectral-analysis.html#footnotes",
    "title": "Spectral Analysis Principles and Tools",
    "section": "",
    "text": "HAMILTON, J.D. (1994).↩︎\nHAMILTON, J.D. (1994).↩︎\nBROCKWELL, P.J., and DAVIS, R.A. (2002).↩︎\nHAMILTON, J.D. (1994).↩︎\nSOKUP, R.J., and FINDLEY, D. F. (1999).↩︎\nBROCKWELL, P.J., and DAVIS, R.A. (2002).↩︎\nFor details see BROCKWELL, P.J., and DAVIS, R.A. (2006).↩︎\nBOX, G.E.P., JENKINS, G.M., and REINSEL, G.C. (2007).↩︎\nThe proof is given in BROCKWELL, P.J., and DAVIS, R.A. (2006).↩︎\nDefinition from ‘X-12-ARIMA Reference Manual’ (2011).↩︎\nThe false alarm rate is defined as the fraction of the 50 replicates for which a visually significant spectral peak occurred at one of the trading day frequencies being considered in the designated output spectra (SOUKUP, R.J., and FINDLEY, D.F. (1999)).↩︎\nFor definition of the periodogram and Fourier frequencies see section Spectral Analysis↩︎"
  },
  {
    "objectID": "M-reg-arima-modelling.html#overview",
    "href": "M-reg-arima-modelling.html#overview",
    "title": "Reg-Arima models",
    "section": "Overview",
    "text": "Overview\nThe primary aim of seasonal adjustment is to remove the unobservable seasonal component from the observed series. The decomposition routines implemented in the seasonal adjustment methods make specific assumptions concerning the input series. One of the crucial assumptions is that the input series is stochastic, i.e. it is clean of deterministic effects. Another important limitation derives from the symmetric linear filter used in TRAMO-SEATS and X-13ARIMA-SEATS. A symmetric linear filter cannot be applied to the first and last observations with the same set of weights as for the central observations[^1]. Therefore, for the most recent observations these filters provide estimates that are subject to revisions.\nTo overcome these constrains both seasonal adjustment methods discussed here include a modelling step that aims to analyse the time series development and provide a better input for decomposition purposes. The tool that is frequently used for this purpose is the ARIMA model, as discussed by BOX, G.E.P., and JENKINS, G.M. (1970). However, time series are often affected by the outliers, other deterministic effects and missing observations. The presence of these effects is not in line with the ARIMA model assumptions. The presence of outliers and other deterministic effects impede the identification of an optimal ARIMA model due to the important bias in the estimation of parameters of sample autocorrelation functions (both global and partial)[^3]. Therefore, the original series need to be corrected for any deterministic effects and missing observations. This process is called linearisation and results in the stochastic series that can be modelled by ARIMA.\nFor this purpose both TRAMO and Reg-ARIMA use regression models with ARIMA errors. With these models TRAMO and Reg-ARIMA also produce forecasts."
  },
  {
    "objectID": "M-X11-decomposition.html#in-this-chapter",
    "href": "M-X11-decomposition.html#in-this-chapter",
    "title": "X-11 decomposition",
    "section": "In this chapter",
    "text": "In this chapter\n\ncontext\nmoving averages\nalgorithm steps\nhigh frequency data (extended features)"
  },
  {
    "objectID": "M-X11-decomposition.html#x-11-in-seasonal-adjustment",
    "href": "M-X11-decomposition.html#x-11-in-seasonal-adjustment",
    "title": "X-11 decomposition",
    "section": "X-11 in seasonal adjustment",
    "text": "X-11 in seasonal adjustment\nThe X-11 program is the result of a long tradition of non-parametric smoothing based on moving averages which have two important drawbacks:\n\nThey are not resistant and might be deeply impacted by outliers;\nThe smoothing of the ends of the series cannot be done except with asymmetric moving averages which introduce phase-shifts and delays in the detection of turning points.\n\nTo overcome these flaws first the series are modelled with a RegARIMA model that removes deterministic effects (calendar, outliers) and computes forecasts.\n\n\n\nThe flow diagram for seasonal adjustment with X-13ARIMA-SEATS using the X-11 algorithm"
  },
  {
    "objectID": "M-X11-decomposition.html#moving-averages",
    "href": "M-X11-decomposition.html#moving-averages",
    "title": "X-11 decomposition",
    "section": "Moving averages",
    "text": "Moving averages\nTo understand the decomposition process, some concepts on moving averages (MA) are necessary\nA moving average of order \\(p+f+1\\) and coefficients \\((\\theta_i)\\) is the operator \\(M\\) defined as: \\[\nMX_t = \\sum_{i=-p}^{f}\\theta_i X_{t+i}\n\\]\nThe series value in \\(t\\) is replaced by a weighted average of \\(p\\) past values, the current value and the \\(f\\) future values. If \\(p=f\\), the moving average is centered and if \\(\\theta_{-i} = \\theta_i\\), it is symmetrical.\nExample of simple moving average of order 3:\n\\[\nMX_t = \\frac{1}{3}(X_{t-1}+X_{t}+ X_{t+1})\n\\]\nA moving average is a linear operator, \\(M(X_t+Y_t) = M(X_t)+M(Y_t)\\).\n\nCombined moving averages\nCentered and symmetrical moving averages preserve linear trends, which is a desirable propriety. They cannot have an even order, thus for even orders they are obtained by combining simple MAs as arithmetic means of p moving averages of same order (ie. length): \\(M_{p\\times order}\\)\nCombination example for order 12:\nThere a are two intuitive ways to create a MA of order 12:\n\\[\nM1X_t = \\frac{1}{12}(X_{t-6}+X_{t-5}+ X_{t-4}+ X_{t-3}+ X_{t-2}+ X_{t-1}\n\\] \\[\n+ X_{t}+ X_{t+1}+ X_{t+2}+ X_{t+3}+ X_{t+4}+X_{t+5})\n\\] The other being: \\[\nM2X_t = \\frac{1}{12}(X_{t-5}+ X_{t-4}+ X_{t-3}+ X_{t-2}+ X_{t-1}+ X_{t}\n\\] \\[\n+ X_{t+1}+ X_{t+2}+ X_{t+3}+ X_{t+4}+X_{t+5}+X_{t+6})\n\\]\nCombining MAs enables us to create a centered and symmetrical MA with an even order:\n\\[\nM_{2\\times 12}= \\frac{1}{2}(M1X_t+M2X_t)\n\\] which is:\n\\[\nM_{2\\times 12} =\\frac{1}{24}(X_{t-6}) +\\frac{1}{12}(X_{t-5}+ X_{t-4}\n\\] \\[\n+X_{t-3}+ X_{t-2}+ X_{t-1}+ X_{t}+X_{t+1}+ X_{t+2}\n\\] \\[\n+ X_{t+3}+ X_{t+4}+X_{t+5})+\\frac{1}{24}(X_{t+6})\n\\]\n\n\nSupressing locally constant seasonality\nApplying a moving average of an order equal to the periodicity of the raw series removes a locally stable seasonality (\\(\\sum_{i=1}^{12}S_{t+i} = 0\\))\nA moving average of order, 12 will remove a locally stable monthly seasonality: \\(M_{1\\times 12}(S)=0\\) and also \\(M_{2\\times 12}(S)=0\\) with linear trend preservation."
  },
  {
    "objectID": "M-X11-decomposition.html#x-11-algorithm-basic-steps",
    "href": "M-X11-decomposition.html#x-11-algorithm-basic-steps",
    "title": "X-11 decomposition",
    "section": "X-11 algorithm basic steps",
    "text": "X-11 algorithm basic steps\nThe seasonal adjustment algorithm can has eight steps. They are outlined below for a monthly time series. (For a quarterly time series a \\(2\\times 4\\) moving average would be used, instead of \\(2\\times 12\\))\nStep 1: Estimation of the trend-cycle with a \\(2\\times 12\\) MA: \\[\nTC_t^{(1)}=M_{2\\times 12}(X_t)\n\\]\nStep 2: Estimation of the seasonal+irregular component: \\[\n(S_t+I_t)^{(1)}= X_t - TC_t^{(1)}\n\\]\nStep 3: Estimation of the seasonal component by applying a \\(3\\times 3\\) MA to each month: \\[\nS_t^{(1)}= M_{3\\times 3}\\left[(S_t+I_t)^{(1)}\\right]\n\\text{ and normalisation }\nSnorm_t^{(1)}=S_t^{(1)} - M_{2\\times 12}\\left(S_t^{(1)}\\right)\n\\]\nStep 4 :First estimation of the seasonally adjusted series: \\[\nXsa_t^{(1)}= (TC_t+I_t)^{(1)} = X_t - Snorm_t^{(1)}\n\\]\nStep 5: Refined estimation of the trend-cycle with a Henderson filter, which yields a better approximation fo trends than \\(2\\times 12\\) MA, but cannot be applied on seasonal series: \\[\nTC_t^{(2)}=H_{13}(Xsa_t^{(1)})\n\\] Step 6: Refined estimation of the seasonal+irregular part: \\[\n(S_t+I_t)^{(2)}= X_t - TC_t^{(2)}\n\\]\nStep 7: Refined estimation of the seasonal component by applying a \\(3\\times 5\\) MA (generally) to each month/quarter: \\[\nS_t^{(2)}= M_{3\\times 5}\\left[(S_t+I_t)^{(2)}\\right]\n\\text{ and normalisation }\nSnorm_t^{(2)}=S_t^{(2)} - M_{2\\times 12}\\left(S_t^{(2)}\\right)\n\\]\nStep 8: Final estimation of the seasonally adjusted series: \\[\nXsa_t^{(2)}= X_t - Snorm_t^{(2)}\n\\]"
  },
  {
    "objectID": "M-X11-decomposition.html#iterative-principle-of-x-11",
    "href": "M-X11-decomposition.html#iterative-principle-of-x-11",
    "title": "X-11 decomposition",
    "section": "Iterative principle of X-11",
    "text": "Iterative principle of X-11\nTo evaluate the different components of a series, while taking into account the possible presence of extreme observations, X-11 will proceed iteratively: estimation of components, search for disruptive effects in the irregular component, estimation of components over a corrected series, search for disruptive effects in the irregular component, and so on.\nThe Census X-11 program presents four processing stages (A, B, C, and D), plus 3 stages, E, F, and G, that propose statistics and charts and are not part of the decomposition per se. In stages B, C and D the basic algorithm is used as is indicated in the figure below.\nA workflow diagram for the X-11 algorithm implemented in JDemetra+. Source: Based upon training material from the Deutsche Bundesbank\n\nPart A: Pre-adjustments\n\nThis part, which is not obligatory, corresponds in X-13ARIMA-SEATS to the first cleaning of the series done using the RegARIMA facilities: detection and estimation of outliers and calendar effects (trading day and Easter), forecasts and backcasts[^61] of the series. Based on these results, the program calculates prior adjustment factors that are applied to the raw series. The series thus corrected, Table B1 of the printouts, then proceeds to part B.\n\nPart B: First automatic correction of the series\n\nThis stage consists of a first estimation and down-weighting of the extreme observations and, if requested, a first estimation of the calendar effects. This stage is performed by applying the basic algorithm detailed earlier. These operations lead to Table B20, adjustment values for extreme observations, used to correct the unadjusted series and result in the series from Table C1.\n\nPart C: Second automatic correction of the series\n\nApplying the basic algorithm once again, this part leads to a more precise estimation of replacement values of the extreme observations (Table C20). The series, finally “cleaned up”, is shown in Table D1 of the printouts.\n\nPart D: Seasonal adjustment\n\nThis part, at which our basic algorithm is applied for the last time, is that of the seasonal adjustment, as it leads to final estimates:\n\nof the seasonal component (Table D10);\nof the seasonally adjusted series (Table D11);\nof the trend component (Table D12);\nof the irregular component (Table D13).\nPart E: Components modified for large extreme values\n\nParts E includes:\n\nComponents modified for large extreme values;\nComparison the annual totals of the raw time series and seasonally adjusted time series;\nChanges in the final seasonally adjusted series;\nChanges in the final trend;\nRobust estimation of the final seasonally adjusted series.\n\nThe results from part E are used in part F to calculate the quality measures.\n\nPart F: Seasonal adjustment quality measures\n\nPart F contains statistics for judging the quality of the seasonal adjustment. JDemetra+ presents selected output for part F, i.e.:\n\nM and Q statistics;\nTables.\n\nThe Henderson moving average and the trend estimation\nIn iteration B (Table B7), iteration C (Table C7) and iteration D (Table D7 and Table D12) the trend component is extracted from an estimate of the seasonally adjusted series using Henderson moving averages. The length of the Henderson filter is chosen automatically by X-13ARIMA-SEATS in a two-step procedure.\nIt is possible to specify the length of the Henderson moving average to be used. X-13ARIMA-SEATS provides an automatic choice between a 9-term, a 13-term or a 23-term moving average. The automatic choice of the order of the moving average is based on the value of an indicator called \\(\\frac{\\overline{I}}{\\overline{C}}\\) ratio which compares the magnitude of period-on-period movements in the irregular component with those in the trend. The larger the ratio, the higher the order of the moving average selected. Moreover, X-13ARIMA-SEATS allows the user to choose manually any odd‑numbered Henderson moving average. The procedure used in each part is very similar; the only differences are the number of options available and the treatment of the observations in the both ends of the series. The procedure below is applied for a monthly time series.\nIn order to calculate \\(\\frac{\\overline{I}}{\\overline{C}}\\) ratio a first decomposition of the SA series (seasonally adjusted) is computed using a 13-term Henderson moving average.\nFor both the trend (\\(C\\)) and irregular (\\(I\\)) components, the average of the absolute values for monthly growth rates (multiplicative model) or for monthly growth (additive model) are computed. They are denoted as \\(\\overline{C}\\) and \\(\\overline{I}\\), receptively, where:\n\n\\(\\overline{C} = \\frac{1}{n - 1}\\sum_{t = 2}^{n}\\left| C_{t} - C_{t - 1} \\right|\\) ;\n\\(\\overline{I} = \\frac{1}{n - 1}\\sum_{t = 2}^{n}\\left| I_{t} - I_{t - 1} \\right|\\).\n\nThen the value of \\(\\frac{\\overline{I}}{\\overline{C}}\\) ratio is checked and in iteration B:\n\nIf the ratio is smaller than 1, a 9-term Henderson moving average is selected;\nOtherwise, a 13-term Henderson moving average is selected.\n\nThen the trend is computed by applying the selected Henderson filter to the seasonally adjusted series from Table B6. The observations at the beginning and at the end of the time series that cannot be computed by means of symmetric Henderson filters are estimated by ad hoc asymmetric moving averages.\nIn iterations C and D:\n\nIf the ratio is smaller than 1, a 9-term Henderson moving average is selected;\nIf the ratio is greater than 3.5, a 23-term Henderson moving average is selected.\nOtherwise, a 13-term Henderson moving average is selected.\n\nThe trend is computed by applying selected Henderson filter to the seasonally adjusted series from Table C6, Table D7 or Table D12, accordingly. At the both ends of the series, where a central Henderson filter cannot be applied, the asymmetric ends weights for the 7 term Henderson filter are used.\n\nChoosing the composite moving averages when estimating the seasonal component\nIn iteration D, Table D10 shows an estimate of the seasonal factors implemented on the basis of the modified SI (Seasonal – Irregular) factors estimated in Tables D4 and D9bis. This component will have to be smoothed to estimate the seasonal component; depending on the importance of the irregular in the SI component, we will have to use moving averages of varying length as in the estimate of the Trend/Cycle where the \\(\\frac{\\overline{I}}{\\overline{C}}\\) ratio was used to select the length of the Henderson moving average. The estimation includes several steps.\nStep 1: Estimating the irregular and seasonal components\nAn estimate of the seasonal component is obtained by smoothing, month by month and therefore column by column, Table D9bis using a simple 7-term moving average, i.e. of coefficients \\(\\frac{1}{7} \\left\\{1,\\ 1,\\ 1,\\ 1,\\ 1,\\ 1,\\ 1\\right\\}\\). In order not to lose three points at the beginning and end of each column, all columns are completed as follows. Let us assume that the column that corresponds to the month is composed of \\(N\\) values \\(\\left\\{ x_{1},\\ x_{2},\\ x_{3},\\ \\ldots x_{N - 1},\\ x_{N} \\right\\}\\). It will be transformed into a series \\(\\left\\{ {x_{- 2},x_{- 1}{,x}_{0},x}_{1},\\ x_{2},\\ x_{3},\\ \\ldots x_{N - 1},\\ x_{N},x_{N + 1},\\ x_{N + 1},\\ x_{N + 2},\\ x_{N + 3} \\right\\}\\) with \\(x_{- 2} = x_{- 1} = x_{0} = \\frac{x_{1} + x_{2} + x_{3}}{3}\\) and \\(x_{N + 1} = x_{N + 2} = x_{N + 3} = \\frac{x_{N} + x_{N - 1} + x_{N - 2}}{3}\\). We then have the required estimates: \\(S = M_{7}(D9bis)\\) and \\(I = D9bis - S\\).\nStep 2: Calculating the Moving Seasonality Ratios\nFor each \\(i^{\\text{th}}\\) month the mean annual changes for each component is obtained by calculating \\[\n{\\overline{S}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}\\left| S_{i,t} - S_{i,t - 1} \\right|\n\\]\nand\n\\[\n{\\overline{I}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}\\left| I_{i,t} - I_{i,t - 1} \\right|\n\\]\nwhere \\(N_{i}\\) refers to the number of months \\(\\text{i}\\)in the data, and the moving seasonality ratio of month \\(i\\):\n\\[\nMSR_{i} = \\frac{\\ {\\overline{I}}_{i}}{ {\\overline{S}}_{i}}\n\\]\nThese ratios are presented in Details of the Quality Measures node under the Decomposition (X11) section. These ratios are used to compare the year-on-year changes in the irregular component with those in the seasonal component. The idea is to obtain, for each month, an indicator capable of selecting the appropriate moving average for the removal of any noise and providing a good estimate of the seasonal factor. The higher the ratio, the more erratic the series, and the greater the order of the moving average should be used. As for the rest, by default the program selects the same moving average for each month, but the user can select different moving averages for each month.\nStep 3: Calculating the overall Moving Seasonality Ratio\nThe overall Moving Seasonality Ratio is calculated as follows:\n\\[\n\\text{MSR}_{i} = \\frac{\\sum_{i}^{}{N_{i}\\ }\\ {\\overline{I}}_{i}}{\\sum_{i}^{}N_{i}{\\overline{S}}_{i}}\n\\] Step 4: Selecting a moving average and estimating the seasonal component\nDepending on the value of the ratio, the program automatically selects a moving average that is applied, column by column (i.e. month by month) to the Seasonal/Irregular component in Table D8 modified, for extreme values, using values in Table D9.\nThe default selection procedure of a moving average is based on the Moving Seasonality Ratio in the following way:\n\nIf this ratio occurs within zone A (MSR &lt; 2.5), a \\(3 \\times 3\\) moving average is used; if it occurs within zone C (3.5 &lt; MSR &lt; 5.5), a \\(3 \\times 5\\) moving average is selected; if it occurs within zone E (MSR  6.5), a \\(3 \\times 9\\) moving average is used;\nIf the MSR occurs within zone B or D, one year of observations is removed from the end of the series, and the MSR is recalculated. If the ratio again occurs within zones B or D, we start over again, removing a maximum of five years of observations. If this does not work, i.e. if we are again within zones B or D, a \\(3 \\times 5\\) moving average is selected.\n\nThe chosen symmetric moving average corresponds, as the case may be 5 (\\(3 \\times 3\\)), 7 (\\(3 \\times 5\\)) or 11 (\\(3 \\times 9\\) \\(3 \\times 9\\)) terms, and therefore does not provide an estimate for the values of seasonal factors in the first 2 (or 3 or 5) and the last 2 (or 3 or 5) years. These are then calculated using associated asymmetric moving averages.\nMoving average selection procedure, source: DAGUM, E. B.(1999)"
  },
  {
    "objectID": "M-X11-decomposition.html#extreme-values-identification-and-replacement",
    "href": "M-X11-decomposition.html#extreme-values-identification-and-replacement",
    "title": "X-11 decomposition",
    "section": "Extreme values: identification and replacement",
    "text": "Extreme values: identification and replacement\nX-13ARIMA-SEATS detects and removes outliers in the RegARIMA part. However, if there is a seasonal heteroscedasticity in a time series i.e. the variance of the irregular component is different in different calendar months. Examples for this effect could be the weather and snow-dependent output of the construction sector in Germany during winter, or changes in Christmas allowances in Germany and resulting from this a transformation in retail trade turnover before Christmas. The ARIMA model is not on its own able to cope with this characteristic. The practical consequence is given by the detection of additional extreme values by X-11. This may not be appropriate if the seasonal heteroscedasticity is produced by political interventions or other influences. The ARIMA models assume a constant variance and are therefore not by themselves able to cope with this problem. Choosing longer (in the case of diverging weather conditions in the winter time for the construction sector) or shorter filters (in the case of a changing pattern of retail trade turnover in the Christmas time) may be reasonable in such cases. It may even be sensible to take into account the possibility of period-specific (e.g. month-specific) standard deviations, which can be done by changing the default settings of the calendarsigma parameter (see Specifications-X13 section). The value of the calendarsigma parameter will have an impact on the method of calculation of the moving standard deviation in the procedure for extreme values detection presented below.\nThough we (should) rely on the pre-adjustment stage to correct for extreme values (transparent method with explicit modelling), X11 has its own (historical) module for identification and treatment of extreme values based on a comparison between the actual and the theoretical value of \\(I\\).\nStages B and C aim only at correcting for extreme values:\nStep 1: \\(I\\) is estimated once \\(S\\) has been extracted from \\(S+I\\)\n\nfor each year the standard deviation \\(\\sigma\\) is computed on the 5 neighbouring years\n\\(I\\) has a theoretical value \\(m\\), for multiplicative model \\(m=1\\), \\(m=0\\) for an additive model\nfor a given year \\(y\\): any point such as \\(\\lvert I_t - m\\rvert &gt;2,5 \\sigma_y\\) is considered as an extreme value and suppressed….\n…all the yearly sigmas (\\(\\sigma_y\\)) are computed without those points (more robust sigmas )\n\nStep 2: The distance \\(\\lvert I_t - m\\rvert\\) is computed for each point and evaluated with \\(\\sigma_{y}\\) as a benchmark, a weight \\(w_t\\) is then assigned to each point, 3 cases:\n\nvalue unchanged \\[\\lvert I_t - m\\rvert &lt;1.5 \\sigma_y \\Rightarrow  w_t=1\\]\nvalue downsized \\[1,5 \\sigma_y&lt;\\lvert I_t - m\\rvert &lt;2,5 \\sigma_y \\Rightarrow w_t=\\frac{2.5 \\sigma_y -\\lvert I_t - m\\rvert}{2.5 \\sigma_y-1.5 \\sigma_y}\\]\nvalue removed and replaced \\[\\lvert I_t - m\\rvert &gt;2,5 \\sigma_y \\Rightarrow w_t=0\\]\n\nStep3: Thanks to this weights, a new value of \\(S+I\\) will be computed:\n\nif \\(w_{t}=1\\), \\(S+I\\) remains unchanged for point {t}\nif \\(w_{t}&lt;1\\) then the new value of \\(S+I\\) will be an average of \\(w_{t}*(S+I)_{t}\\) and the values of \\((S+I)\\) of the two closest neighbors in the future and in the past with \\(w=1\\)\n\nWeight distribution\n\nX-11 output tables\nThe list of tables produced by JDemetra+ is presented below. It is not identical to the output produced by the original X-11 program.\nPart A – Preliminary Estimation of Outliers and Calendar Effects.\nThis part includes prior modifications to the original data made in the RegARIMA part:\n\nTable A1 – Original series;\nTable A1a – Forecast of Original Series;\nTable A2 – Leap year effect;\nTable A6 – Trading Day effect (1 or 6 variables);\nTable A7 – The Easter effect;\nTable A8 – Total Outlier Effect;\nTable A8i – Additive outlier effect;\nTable A8t – Level shift effect;\nTable A8s – Transitory effect;\nTable A9 – Effect of user-defined regression variables assigned to the seasonally adjusted series or for which the component has not been defined;\nTable 9sa – Effect of user-defined regression variables assigned to the seasonally adjusted series;\nTable9u – Effect of user-defined regression variables for which the component has not been defined.\n\nPart B – Preliminary Estimation of the Time Series Components:\n\nTable B1 – Original series after adjustment by the RegARIMA model;\nTable B2 – Unmodified Trend (preliminary estimation using composite moving average);\nTable B3 – Unmodified Seasonal – Irregular Component (preliminary estimation);\nTable B4 – Replacement Values for Extreme SI Values;\nTable B5 – Seasonal Component;\nTable B6 – Seasonally Adjusted Series;\nTable B7 – Trend (estimation using Henderson moving average);\nTable B8 – Unmodified Seasonal – Irregular Component;\nTable B9 – Replacement Values for Extreme SI Values;\nTable B10 – Seasonal Component;\nTable B11 – Seasonally Adjusted Series;\nTable B13 – Irregular Component;\nTable B17 – Preliminary Weights for the Irregular;\nTable B20 – Adjustment Values for Extreme Irregulars.\n\nPart C – Final Estimation of Extreme Values and Calendar Effects:\n\nTable C1 – Modified Raw Series;\nTable C2 – Trend (preliminary estimation using composite moving average);\nTable C4 – Modified Seasonal – Irregular Component;\nTable C5 – Seasonal Component;\nTable C6 – Seasonally Adjusted Series;\nTable C7 – Trend (estimation using Henderson moving average);\nTable C9 – Seasonal – Irregular Component;\nTable C10 – Seasonal Component;\nTable C11 – Seasonally Adjusted Series;\nTable C13 – Irregular Component;\nTable C20 – Adjustment Values for Extreme Irregulars.\n\nPart D – Final Estimation of the Different Components:\n\nTable D1 – Modified Raw Series;\nTable D2 – Trend (preliminary estimation using composite moving average);\nTable D4 – Modified Seasonal – Irregular Component;\nTable D5 – Seasonal Component;\nTable D6 – Seasonally Adjusted Series;\nTable D7 – Trend (estimation using Henderson moving average);\nTable D8 – Unmodified Seasonal – Irregular Component;\nTable D9 – Replacement Values for Extreme SI Values;\nTable D10 – Final Seasonal Factors;\nTable D10A – Forecast of Final Seasonal Factors;\nTable D11 – Final Seasonally Adjusted Series;\nTable D11A – Forecast of Final Seasonally Adjusted Series;\nTable D12 – Final Trend (estimation using Henderson moving average);\nTable D12A – Forecast of Final Trend Component;\n\n\n\nTable D13 – Final Irregular Component;\nTable D16 – Seasonal and Calendar Effects;\nTable D16A – Forecast of Seasonal and Calendar Component;\nTable D18 – Combined Calendar Effects Factors.\n\nPart E – Components Modified for Large Extreme Values:\n\nTable E1 – Raw Series Modified for Large Extreme Values;\nTable E2 – SA Series Modified for Large Extreme Values;\nTable E3 – Final Irregular Component Adjusted for Large Extreme Values;\nTable E11 – Robust Estimation of the Final SA Series.\n\nPart F – Quality indicators:\n\nTable F2A – Changes, in the absolute values, of the principal components;\nTable F2B – Relative contribution of components to changes in the raw series;\nTable F2C – Averages and standard deviations of changes as a function of the time lag;\nTable F2D – Average duration of run;\nTable F2E – I/C ratio for periods span;\nTable F2F – Relative contribution of components to the variance of the stationary part of the original series;\nTable F2G – Autocorrelogram of the irregular component.\n\n\n\nFilter length choice\nA seasonal filter is a weighted average of a moving span of fixed length within a time series that can be used to remove a fixed seasonal pattern. X-13ARIMA-SEATS uses several of these filters, according to the needs of the different stages of the program. As only X-13ARIMA-SEATS allows the user to manually select seasonal filters, this case study can be applied only to the X-13ARIMA-SEATS specifications.\nThe automatic seasonal adjustment procedure uses the default options to select the most appropriate moving average. However there are occasions when the user will need to specify a different seasonal moving\naverage to that identified by the program. For example, if the SI values do not closely follow the seasonal component, it may be appropriate to use a shorter moving average. Also the presence of sudden breaks in the seasonal pattern – e.g. due to changes in the methodology – can negatively impact on the automatic selection of the most appropriate seasonal filter. In such cases the usage of short seasonal filters in the selected months or quarters can be considered. Usually, a shorter seasonal filter \\((3 \\times 1)\\) allows seasonality to change very rapidly over time. However, a very short seasonal filter should not normally be used, as it might often lead to large revisions as new data becomes available. If a short filter is to be used it will usually be limited to one month/quarter with a known reason for wanting to capture a rapidly changing seasonality.\nIn the standard situation one seasonal filter is applied to all individual months/quarters. The estimation of seasonal movements is therefore based on the sample windows of equal lengths for each individual month/quarter (i.e. for each month/quarter the seasonal filter length or the number of years representing the major part of the seasonal filter weights is identical). This approach relies on the assumption that the number of past periods in which the conditions causing seasonal behaviour are sufficiently homogenous is the same in all months/quarters. However, this assumption does not always hold. Seasonal causes may change in one month, while staying the same in others1. For instance, seasonal heteroskedasticity might require different filter lengths in different months or quarters.\nAnother interesting example is industrial production in Germany. It can be influenced by school holidays, since many employees have school-age children, which interrupt their working pattern during these school holidays. Consequently, businesses may temporarily suspend or lower production during these periods. Since school holidays do not occur at the same time throughout Germany and their timing varies from year to year in the individual federal states, the effect is not completely captured by seasonal adjustment. And since school holidays are treated as usual working days, these effects are not captured by calendar adjustment either. The majority of school holidays in Germany can take place either in July or in August. This yields higher variances in the irregular component for these months compared to the rest of the year. Therefore, in this case a longer seasonal filter is used for these months to account for this.\nAnother example might be given by German retail trade. Due to changes in the consumers’ behaviour around Christmas – possibly more gifts of money – the seasonal peak in December has become steadily less pronounced. To account for this moving seasonality, shorter seasonal filters in December than during the rest of the year need to be applied.\nJDemetra+ offers the options to assign a different seasonal filter length to each period (month or quarter). The program offers these options in the single spec mode as well as in the multispec mode, albeit they are available only in the Specifications window, after a document is created.\n\n\nM-stats\nThe details about the measures are given below.\n\n\\(M1\\) measures the contribution of the irregular component to the total variance. When it is above 1 some changes in outlier correction should be considered.\n\\(M2\\), which is a very similar to \\(M1\\), is calculated on the basis of the contribution of the irregular component to the stationary portion of the variance. When it is above 1, some changes in an outlier correction should be considered.\n\\(M3\\) compares the irregular to the trend taken from a preliminary estimate of the seasonally adjusted series. If this ratio is too large, it is difficult to separate the two components from each other. When it is above 1 some changes in outlier correction should be considered.\n\\(M4\\) tests the randomness of the irregular component. A value above 1 denotes a correlation in the irregular component. In such case a shorter seasonal moving average filter should be considered.\n\\(M5\\) is used to compare the significance of changes in the trend with that in the irregular. When it is above 1 some changes in outlier correction should be considered.\n\\(M6\\) checks the \\(\\text{SI}\\) (seasonal – irregular components ratio). If annual changes in the irregular component are too small in relation to the annual changes in the seasonal component, the \\(3 \\times 5\\) seasonal filter used for the estimation of the seasonal component is not flexible enough to follow the seasonal movement. In such case a longer seasonal moving average filter should be considered. It should be stressed that \\(M6\\) is calculated only if the \\(3 \\times 5\\) filter has been applied in the model.\n\\(M7\\) is the combined test for the presence of an identifiable seasonality. The test compares the relative contribution of stable and moving seasonality2.\n\\(M8\\) to \\(M11\\) measure if the movements due to the short-term quasi-random variations and movements due to the long-term changes are not changing too much over the years. If the changes are too strong then the seasonal factors could be erroneous. In such case a correction for a seasonal break or the change of the seasonal filter should be considered.\n\nThe \\(Q\\) statistic is a composite indicator calculated from the \\(M\\) statistics.\nEdit : problem with tables display\n\\[\n\\scriptsize\nQ = \\frac{10M1 + 11M2 + 10M3 + 8M4 + 11M5 + 10M6 + 18M7 + 7M8 + 7M9 + 4M10 + 4M11}{100}\n\\tag{1}\\] \n\\(Q = Q - M2\\) (also called \\(Q2\\)) is the \\(Q\\) statistic for which the \\(M2\\) statistics was excluded from the formula, i.e.:\n\\[\n\\small\nQ - M2 = \\frac{10M1 + 10M3 + 8M4 + 11M5 + 10M6 + 18M7 + 7M8 + 7M9 + 4M10 + 4M11}{89}\n\\tag{2}\\] \nIf a time series does not cover at least 6 years, the \\(M8\\), \\(M9\\), \\(M10\\) and \\(M11\\) statistics cannot be calculated. In this case the \\(Q\\) statistic is computed as:\n\\[\nQ = \\frac{14M1 + 15M2 + 10M3 + 8M4 + 11M5 + 10M6 + 32M7}{100}\n\\]\nThe model has a satisfactory quality if the \\(Q\\) statistic is lower than 1.\nThe tables displayed in the Quality measures → Details node correspond to the F-set of tables produced by the original X-11 algorithm. To facilitate the analysis of the results, the numbers and the names of the tables are given under each table following the convention used in LADIRAY, D., and QUENNEVILLE, B. (1999).\n\nDetailed Quality measures\nIn GUI all the diagnostics below can be displayed expanding the NODE\nDecomposition(X-11) &gt; Quality Measures &gt; Details\nThey are detailed in the X-11 method chapter\nIn R (to be added)\n\nAverage percent change (or Average differences) without regard to sign over the indicated span\nThe first table presents the average percent change without regard to sign of the percent changes (multiplicative model) or average differences (additive model) over several periods (from 1 to 12 for a monthly series, from 1 to 4 for a quarterly series) for the following series:\n\n\\(O\\) – Original series (Table A1);\n\\(\\text{CI}\\) – Final seasonally adjusted series (Table D11);\n\\(I\\) – Final irregular component (Table D13);\n\\(C\\) – Final trend (Table D12);\n\\(S\\) – Final seasonal factors (Table D10);\n\\(P\\) – Preliminary adjustment coefficients, i.e. regressors estimated by the Reg-Arima model (Table A2);\n\\(TD\\& H\\) – Final calendar component (Tables A6 and A7);\n\\(\\text{Mod.O}\\) – Original series adjusted for extreme values (Table E1);\n\\(\\text{Mod.CI}\\) – Final seasonally adjusted series corrected for extreme values (Table E2);\n\\(\\text{Mod.I}\\) – Final irregular component adjusted for extreme values (Table E3).\n\nIn the case of an additive decomposition, for each component the average absolute changes over several periods are calculated as:\n\\[\\text{Component}_{d} = \\frac{1}{n - d}\\sum_{t = d + 1}^{n}|Table_{t} - Table_{t - d}|\\]\nwhere:\n\\(d\\) – time lag in periods (from a monthly time series \\(d\\) varies from to 4 or from 1 to 12);\n\\(n\\) – total number of observations per period;\n\\(\\text{Component}\\) – the name of the component;\n\\(\\text{Table}\\) – the name of the table that corresponds to the component.\n\nFor the multiplicative decomposition the following formula is used: \\[\\text{Component}_{d} = \\frac{1}{n - d}\\sum_{t = d+1}^{n}{|\\frac{\\text{Tabl}e_{t}}{\\text{Table}_{t - d}} - 1|}\\].\n\n\nRelative contribution to the variance of the differences in the components of the original series\nNext, Table F2B of relative contributions of the different components to the differences (additive model) or percent changes (multiplicative model) in the original series is displayed. They express the relative importance of the changes in each component. Assuming that the components are independent, the following relation is valid:\n\\[O_{d}^{2} \\approx C_{d}^{2} + S_{d}^{2} + I_{d}^{2} + P_{d}^{2} + {TD\\& H}_{d}^{2}\\]\nIn order to simplify the analysis, the approximation can be replaced by the following equation:\n\\[O_{d}^{*2} = C_{d}^{2} + S_{d}^{2} + I_{d}^{2} + P_{d}^{2} + {TD\\& H}_{d}^{2}\\]\nThe notation is the same as for Table F2A. The column \\(\\text{Total}\\) denotes total changes in the raw time series.\nData presented in Table F2B indicate the relative contribution of each component to the percent changes (differences) in the original series over each span, and are calculated as:\n\\(\\frac{I_{d}^{2}}{O_{d}^{*2}}\\), \\(\\frac{C_{d}^{2}}{O_{d}^{*2}}\\), \\(\\frac{S_{d}^{2}}{O_{d}^{*2}}\\), \\(\\frac{P_{d}^{2}}{O_{d}^{*2}}\\) and \\(\\frac{TD\\& H_{d}^{2}}{O_{d}^{*2}}\\) where: \\(O_{d}^{*2} = I_{d}^{2} + C_{d}^{2} + S_{d}^{2} + P_{d}^{2}{+ TD\\& H}_{d}^{2}\\).\nThe last column presents the Ratio calculated as: \\(100 \\times\\frac{O_{d}^{*2}}{O_{d}^{2}}\\), which is an indicator of how well the approximation \\({(O_{d}^{*})}^{2} \\approx O_{d}^{2}\\) holds.\n\n\n\nAverage differences with regard to sign and standard deviation over indicated span\nWhen an additive decomposition is used, Table F2C presents the average and standard deviation of changes calculated for each time lag \\(d\\), taking into consideration the sign of the changes of the raw series and its components. In case of a multiplicative decomposition the respective table shows the average percent differences and related standard deviations.\n\n\n\nAverage duration of run\nAverage duration of run is an average number of consecutive monthly (or quarterly) changes in the same direction (no change is counted as a change in the same direction as the preceding change). JDemetra+ displays this indicator for the seasonally adjusted series, for the trend and for the irregular component.\n\n\n\nI/C ratio over indicated span and global\nThe \\(\\frac{I}{C}\\) ratios for each value of time lag \\(d\\), presented in Table F2E, are computed on a basis of the data in Table F2A. Global IC is displayed below the table\n\n\n\nRelative contribution to the stationary part of the variance in the original series\nThe relative contribution of components to the variance of the stationary part of the original series is calculated for the irregular component (\\(I\\)), trend made stationary (\\(C\\)), seasonal component (\\(S\\)) and calendar effects (TD&H).\nThe trend is made stationary by by extracting a linear trend from the trend component presented in Table D12.\n\n\n\nText\n\n\n\n\nAutocorrelations in the irregular\nThe last table shows the autocorrelogram of the irregular component from Table D13. In the case of multiplicative decomposition it is calculated for time lags between 1 and the number of periods per year +2 using the formula:\n\\[\\text{Corr}_{k}I = \\frac{\\sum_{t = k + 1}^{N}{(I_{t} - 1)(I_{t - k} - 1)}}{\\sum_{t = 1}^{N}{(I_{t} - 1)}^{2}}\\] where \\(N\\) is number of observations in the time series and \\(k\\) the lag.\nFor the additive decomposition the formula is: \\[Corr_{k}I_{t} = \\frac{\\sum_{t = k + 1}^{N}{(I_{t} \\times I_{t - k})}}{\\sum_{t = 1}^{N}{(I_{t})}^{2}}\\]\n\n\n\nHeteroskedasticity\nCochran test on equal variances within each period\nThe Cochran test is design to identify the heterogeneity of a series of variances. X-13-ARIMA-SEATS uses this test in the extreme value detection procedure to check if the irregular component is heteroskedastic. In this procedure the standard errors of the irregular component are used for an identification of extreme values. If the null hypothesis that for all the periods (months, quarters) the variances of the irregular component are identical is rejected, the standard errors will be computed separately for each period (in case the option Calendarsigma=signif has been selected).\n\n\n\nText\n\n\n\n\nMoving seasonality ratios (MSR)\nFor each \\(i^{\\text{th}}\\) month we will be looking at the mean annual changes for each component by calculating:\n\\[{\\overline{S}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}|S_{i,t} - S_{i,t - 1}|\\]\nand\n\\[{\\overline{I}}_{i} = \\frac{1}{N_{i} - 1}\\sum_{t = 2}^{N_{i}}| I_{i,t} - I_{i,t - 1}|\\],\nwhere \\(N_{i}\\) refers to the number of months \\(\\text{i}\\) in the data, and the moving seasonality ratio of month \\(i\\):\n\\[MSR_{i} = \\frac{\\overline{I}_{i}}{\\overline{S}_{i}}\\]\nThe Moving Seasonality Ratio (MSR) is used to measure the amount of noise in the Seasonal-Irregular component. By studying these values, the user can select for each period the seasonal filter that is the most suitable given the noisiness of the series.\n\n\n\nText"
  },
  {
    "objectID": "M-X11-decomposition.html#footnotes",
    "href": "M-X11-decomposition.html#footnotes",
    "title": "X-11 decomposition",
    "section": "",
    "text": "When the series are non-stationary differentiation is performed before the seasonality tests.↩︎\nSee section Combined seasonality tests.↩︎"
  },
  {
    "objectID": "M-STL-decomposition.html",
    "href": "M-STL-decomposition.html",
    "title": "STL: Local regression decomposition",
    "section": "",
    "text": "Under construction"
  },
  {
    "objectID": "M-SEATS-decomposition.html#introduction",
    "href": "M-SEATS-decomposition.html#introduction",
    "title": "SEATS decomposition",
    "section": "Introduction",
    "text": "Introduction\nSEATS is a program for estimating unobserved components in a time series. It follows the ARIMA-model-based (AMB) method, developed from the work of CLEVELAND, W.P., and TIAO, G.C. (1976), BURMAN, J.P. (1980), HILLMER, S.C., and TIAO, G.C. (1982), BELL, W.R., and HILLMER, S.C. (1984) and MARAVALL, A., and PIERCE, D.A. (1987).\nIn JDemetra+ the input for the model based signal extraction procedure is always provided by TRAMO and includes the original series \\(y_{t}\\), the linearized series \\(x_{t}\\) (i.e. the original series \\(y_{t}\\) with the deterministic effects removed), the ARIMA model for the stochastic (linearized) time series \\(x_{t}\\) and the deterministic effects (calendar effects, outliers and other regression variable effects)1. SEATS decomposes the linearized series (and the ARIMA model) into trend, seasonal, transitory and irregular components, provides forecasts for these components, together with the associated standard errors, and finally assign the deterministic effects to each component yielding the final components2. The Minimum Mean Square Error (MMSE) estimators of the components are computed with a Wiener-Kolmogorov filter applied to the finite series extended with forecasts and backcasts3."
  },
  {
    "objectID": "M-SEATS-decomposition.html#arima-modellling-of-the-input-series",
    "href": "M-SEATS-decomposition.html#arima-modellling-of-the-input-series",
    "title": "SEATS decomposition",
    "section": "ARIMA modellling of the input series",
    "text": "ARIMA modellling of the input series\nOne of the fundamental assumptions made by SEATS is that the linearized time series \\(x_{t}\\) follows the ARIMA model\n\\[\n\\phi(B)\\delta\\left( B \\right)x_{t} = \\theta(B)a_{t}\n\\tag{1}\\] \nwhere:\n\n\\(B\\) – the backshift operator \\((Bx_{t} = x_{t - 1})\\);\n\\(\\delta\\left( B \\right)\\) – a non-stationary autoregressive (AR) polynomial in \\(B\\) (unit roots);\n\\(\\theta\\left( B \\right)\\) – an invertible moving average (MA) polynomial in \\(B\\) and in \\(B^{S}\\), which can be expressed in the multiplicative form \\(\\left( 1 + \\vartheta_{1}B + \\ldots{+ \\ \\vartheta}{q}B^{q} \\right)\\left( \\ 1 + \\Theta{1}B^{s} + \\ldots{+ \\ \\Theta}_{Q}B^{\\text{sQ}} \\right)\\) ;\n\\(\\phi(B)\\) – a stationary autoregressive (AR) polynomial in \\(B\\) and in \\(B^{S}\\) containing regular and seasonal unit roots, with s representing the number of observations per year;\n\\(a_{t}\\) – a white-noise variable with the variance\\(\\ V(a)\\).\n\nIt should be noted that the stochastic time series can be predicted using its past observations and making an error. The variable \\(a_{t}\\), which is assumed to be white noise, is the fundamental innovation to the series at time t, that is the part that cannot be predicted based on the past history of the series.\nDenoting \\(\\varphi\\left( B \\right) = \\phi\\left( B \\right)\\delta\\left( B \\right)\\), Equation 1  can be written in a more concise form as\n\\[\n\\varphi\\left( B \\right)x_{t} = \\theta(B)a_{t}\n\\tag{2}\\] \nwhere \\(\\varphi\\left( B \\right)\\) contains both the stationary and the nonstationary roots."
  },
  {
    "objectID": "M-SEATS-decomposition.html#derivation-of-the-models-for-the-components",
    "href": "M-SEATS-decomposition.html#derivation-of-the-models-for-the-components",
    "title": "SEATS decomposition",
    "section": "Derivation of the models for the components",
    "text": "Derivation of the models for the components\nLet us consider the additive decomposition model\n\\[\nx_{t} = \\sum_{i = 1}^{k}x_{\\text{it}}\n\\tag{3}\\] \nwhere i refers to the orthogonal components: trend, seasonal, transitory or irregular. Apart from the irregular component, supposed to be a white noise, it is assumed that each component follows the ARIMA model which can be represented, using the notation of Equation 2 , as:\n\\[\n\\varphi_{i}\\left( B \\right)\\ x_{\\text{it}} = \\theta_{i}(B)a_{\\text{it}}\n\\tag{4}\\] \nwhere\n\n\\(\\varphi_{i}\\left( B \\right) = \\phi_{i}\\left( B \\right)\\delta_{i}\\left( B \\right),\\ \\ x_{\\text{it}}\\) is the i-th unobserved component,\n\\(\\varphi_{i}\\left( B \\right)\\) and \\(\\theta_{i}\\left( B \\right)\\) are finite polynomials of order \\(p_{i}\\) and \\(q_{i}\\), respectively,\n\\(a_{\\text{it}}\\), the disturbance associated with such component, is a white noise process with zero mean and constant variance \\(V(a_{i})\\) and \\(a_{\\text{it}}\\) and \\(a_{\\text{jt}}\\) are not correlated for \\(i \\neq j\\) and for any \\(t\\)..\n\nThese disturbances are functions of the innovations in the series and are called “pseudo-innovations” in the literature concerning the AMB decomposition as they refer to the components that are never observed 4. In the JDemetra+ documentation the term “innovations” is used to refer to the “pseudo-innovations”.\nThe following assumptions hold for Equation 4 . For each \\(\\text{i}\\) the polynomials \\(\\phi_{i}\\left( B \\right)\\), \\(\\delta_{i}\\left( B \\right)\\) and \\(\\theta_{i}(B)\\) are prime and of finite order. The roots of \\(\\delta_{i}\\left( B \\right)\\) lies on the unit circle; those of \\(\\phi_{i}\\left( B \\right)\\) lie outside, while all the roots of \\(\\theta_{i}\\left( B \\right)\\) are on or outside the unit circle. This means that nonstationary and noninvertible components are allowed. Since different roots of the AR polynomial induce peaks in the spectrum5 of the series at different frequencies, and given that different components are associated with the spectral peaks for different frequencies, it is assumed that for \\(i \\neq j\\) the polynomials\\(\\ \\phi_{i}\\left( B \\right)\\) and \\(\\phi_{j}\\left( B \\right)\\) do not share any common root (they are coprime). Finally, it is assumed that the polynomials \\(\\theta_{i}\\left( B \\right),\\ i = 1,\\ldots,k\\) are prime share no unit root in common, guaranteeing the invertibility of the overall series. In fact, since the unit root of \\(\\theta_{i}\\left( B \\right)\\) induce a spectral zero, when the polynomials \\(\\theta_{i}\\left( B \\right),\\ i = 1,\\ldots,k\\) share no unit root in common, there is no frequency for which all component spectra become zero6.\nSince aggregation of ARIMA models yields ARIMA models, the series \\(x_{t}\\) will also follow an ARIMA model, as in Equation 2 , and consequently the following identity can be derived:\n\\[\n\\frac{\\theta(B)}{\\varphi(B)}a_{t} = \\sum_{i = 1}^{k}{\\frac{\\theta_{i}(B)}{\\varphi_{i}(B)}a_{\\text{it}}}\n\\tag{5}\\] \nIn the ARIMA model based approach implemented in SEATS, the ARIMA model identified and estimated for the observed series \\(x_{t}\\) is decomposed to derive the models for the components. In particular, the AR polynomials for the components, \\(\\varphi_{i}\\left( B \\right)\\), are easily derived through the factorization of the AR polynomial \\(\\varphi\\left( B \\right)\\):\n\\[\n\\varphi\\left( B \\right) = \\prod_{i = 1}^{k}{\\varphi_{i}\\left( B \\right)}\n\\tag{6}\\] \nwhile the MA polynomials for the components, together with the innovation variances \\(V(a_{i})\\), cannot simply be obtained through the relationship:\n\\[\n\\theta(B)a_{t} = \\sum_{i = 1}^{k}{\\varphi_{\\text{ni}}\\left( B \\right)}\\theta_{i}(B)a_{\\text{it}}\n\\tag{7}\\] \nwhere \\(\\varphi_{\\text{ni}}\\left( B \\right)\\) is the product of all \\(\\varphi_{j}\\left( B \\right),\\ j = 1,\\ldots,k\\), except from \\(\\varphi_{i}\\left( B \\right)\\). Further assumptions are therefore needed to cope with the underidentification problem: i) \\(p_{i} \\geq q_{i}\\) and ii) the canonical decomposition, i.e. the decomposition that allocate all additive white noise to the irregular component (yielding noninvertible components except the irregular).\nTo understand how SEATS factorizes the AR polynomials, first a concept of a root will be explored7.\nThe equation Equation 2  can be expressed as:\n\\[\n\\psi^{- 1}(B)x_{t} = a_{t}(1 + \\varphi_{1}B + \\ldots\\varphi_{p}B^{p})x_{t} =(1 + \\theta_{1}B + \\ldots\\theta_{q}B^{q})a_{t}\n\\tag{8}\\] \nLet us now consider Equation 2  in the inverted form:\n\\[\n\\theta\\left( B \\right)y_{t} = \\varphi(B)a_{t}\n\\tag{9}\\] \nIf both sides of Equation 8  are multiplied by \\(x_{t - k}\\) with \\(k &gt; q\\), and expectations are taken, the right hand side of the equation vanishes and the left hand side becomes:\n\\[\n\\varphi(B)\\gamma_{k} = \\gamma_{k} + \\varphi_{1}\\gamma_{k - 1} + \\ldots\\varphi_{p}\\gamma_{k - p} = 0\n\\tag{10}\\] \nwhere \\(B\\) operates on the subindex \\(k\\).\nThe autocorrelation function \\(\\gamma_{k}\\) is a solution of Equation 10  with the characteristic equation:\n\\[\nz^{p} + \\varphi_{1}z^{p - 1} + \\ldots\\varphi_{p - 1}z + \\varphi_{p} = 0\n\\tag{11}\\] \nIf \\(z_{1}\\),…,\\(\\ z_{p}\\) are the roots of Equation 11 , the solutions of Equation 10  can be expressed as:\n\\[\n\\gamma_{k} = \\sum_{i = 1}^{p}z_{i}^{k}\n\\tag{12}\\] \nand will converge to zero as \\(k \\rightarrow \\infty\\) when \\(\\left| r_{i} \\right| &lt; 1,\\ i = 1,\\ldots,p\\). From Equation 10  and Equation 12  it can be noticed that \\(z_{1} = B_{i}^{- 1}\\), meaning that \\(z_{1}\\),…,\\(\\ z_{p}\\) are the inverses of the roots \\(B_{1},\\ldots,B_{p}\\) of the polynomial \\(\\varphi(B)\\). The convergence of \\(\\gamma_{k}\\) implies that the roots of the \\(\\varphi(B)\\) are larger than 1 in modulus (lie outside the unit circle). Therefore, from the equation\n\\[\n{\\varphi(B)}^{- 1} = \\frac{1}{(1 - z_{1})\\ldots(1 - z_{1})}\n\\tag{13}\\] \nit can be derived that \\({\\varphi(B)}^{- 1}\\) is convergent and all its inverse roots are less than 1 in modulus.\nEquation Equation 11  has real and complex roots (solutions). Complex number \\(x = a + bi\\), with \\(a\\) and \\(\\text{b}\\) both real numbers, can be represented as \\(x = r\\left( cos(\\omega) + i\\ sin(\\omega \\right))\\), where \\(i\\) is the imaginary unit\\({\\ (i}^{2} = - 1)\\), \\(r\\) is the modulus of \\(x\\), that is \\(\\ r = \\left| x \\right| = \\sqrt{a^{2} + b^{2}}\\) and \\(\\omega\\) is the argument (frequency). When roots are complex, they are always in pairs of complex conjugates. The representation of the complex number \\(x = a + bi\\) has a geometric interpretation in the complex plane established by the real axis and the orthogonal imaginary axis.\n\n\n\nGeometric representation of a complex number and of its conjugate\n\n\nRepresenting the roots of the characteristic equation Equation 11  in the complex plane enhances understanding how they are allocated to the components. When the modulus \\(r\\) of the roots in \\(\\text{z}\\) are greater than 1 (i.e. modulus of the roots in \\(\\varphi(B)\\  &lt; 1\\)), the solution of the characteristic equation has a systematic explosive process, which means that the impact of the given impulse on the time series is more and more pronounced in time. This behaviour is not in line with the developments that can be identified in actual economic series. Therefore, the models estimated by TRAMO-SEATS (and X-13ARIMA-SEATS) have never inverse roots in \\(B\\) with modulus greater than 1.\nThe characteristic equations associated with the regular and the seasonal differences have roots in \\(\\varphi(B)\\) with modulus \\(r = 1\\). They are called non-stationary roots and can be represented on the unit circle. Let us consider the seasonal differencing operator applied to a quarterly time series \\((1 - B^{4})\\). Its characteristic equation is \\({(z}^{4} - 1) = 0\\) with solutions given by\\(\\ z = \\sqrt[4]{1}\\), i.e. \\(z_{1,2} = \\pm 1\\) and \\(z_{3,4} = \\pm i1\\). The first two solutions are real and the last two are complex conjugates. They are represented by the black points on the unit circle on the figure below.\n\n\n\nUnit roots on the unit circle\n\n\nFor the seasonal differencing operator \\((1 - B^{12})\\) applied to the monthly time series the characteristic equation \\({\\ (z}^{12} - 1) = 0\\) has twelve non-stationary solutions given by\\(\\ z = \\sqrt[12]{1}:\\) two real and ten complex conjugates, represented by the white circles in unit roots figure above.\nThe complex conjugates roots generate the periodic movements of the type:\n\\[\nz_{t} = A^{t}\\cos\\left( \\omega t + W \\right).\n\\tag{14}\\] \nwhere:\n\n\\(A\\) – amplitude;\n\\(\\omega\\) – angular frequency (in radians);\n\\(W\\) – phase (angle at \\(t = 0)\\).\n\nThe frequency \\(f\\), i.e. the number of cycles per unit time, is \\(\\frac{\\omega}{2\\pi}\\). If it is multiplied by s, the number of observations per year, the number of cycles completed in one year is derived. The period of function Equation 14 , denoted by \\(\\tau\\), is the number of units of time (months/quarters) it takes for a full circle to be completed.\nFor quarterly series the seasonal movements are produced by complex conjugates roots with angular frequencies at \\(\\frac{\\pi}{2}\\) (one cycle per year) and \\(\\pi\\) (two cycles per year). The corresponding number of cycles per year and the length of the movements are presented in the table below.\nSeasonal frequencies for a quarterly time series\n\n\n\n\n\n\n\n\n\n\n\nAngular frequency (\\(\\omega\\))\nFrequency (cycles per unit time) (\\(f\\))\nCycles per year\nLength of the movement measured in quarters (\\(\\tau\\))\n\n\n\n\n\\(\\frac{\\pi}{2}\\)\n0.25\n1\n4\n\n\n\\(\\pi\\)\n0.5\n2\n2\n\n\n\nFor monthly time series the seasonal movements are produced by complex conjugates roots at the angular frequencies: \\(\\frac{\\pi}{6},\\frac{\\pi}{3}, \\frac{\\pi}{2}, \\frac{2\\pi}{3}, \\frac{5\\pi}{6}\\) and \\(\\pi\\). The corresponding number of cycles per year and the length of the movements are presented in the table below:\nSeasonal frequencies for a monthly time series\n\n\n\n\n\n\n\n\n\n\n\nAngular frequency (\\(\\omega\\))\nFrequency (cycles per unit time) (\\(f\\))\nCycles per year\nLength of the movement measured in months (\\(\\tau\\))\n\n\n\n\n\\(\\frac{\\pi}{6}\\)\n0.083\n1\n12\n\n\n\\(\\frac{\\pi}{3}\\)\n0.167\n2\n6\n\n\n\\(\\frac{\\pi}{2}\\)\n0.250\n3\n4\n\n\n\\(\\frac{2\\pi}{3}\\)\n0.333\n4\n3\n\n\n\\(\\frac{5\\pi}{6}\\)\n0.417\n5\n2.4\n\n\n\\(\\pi\\)\n0.500\n6\n2\n\n\n\nIn JDemetra+ SEATS assigns the roots of the AR full polynomial to the components according to their associated modulus and frequency, i.e.:8\n\nRoots of \\(\\left( 1 - B \\right)^{d}\\) are assigned to trend component.\nRoots of \\(\\ \\left( 1 - B^{s} \\right)^{d_{s}} = {((1 - B)(1 + B + \\ldots + B^{s - 1}))}^{d_{s}}\\) are assigned to the trend component (root of \\({\\left( 1 - B \\right)}^{d_{s}}\\)) and to the seasonal component (roots of \\({(1 + B + \\ldots + B^{s - 1})}^{d_{s}}\\)).\nWhen the modulus of the inverse of a real positive root of \\(\\varphi(B)\\) is greater than \\(k\\) or equal to \\(k\\), where \\(k\\) is the threshold value controlled by the Trend boundary parameter(in the original SEATS it is controlled by rmod)9, then the root is assigned to the trend component. Otherwise it is assigned to the transitory component.\nReal negative inverse roots of \\(\\text{ϕ}_{p}\\left( B \\right)\\) associated with the seasonal two-period cycle are assigned to the seasonal component if their modulus is greater than k, where \\(k\\) is the threshold value controlled by the Seasonal boundary and the Seas. boundary (unique) parameters. Otherwise they are assigned to the transitory component.\nComplex roots, for which the argument (angular frequency) is close enough to the seasonal frequency are assigned to the seasonal component. Closeness is controlled by the Seasonal tolerance and Seasonal tolerance (unique) parameters (in the original SEATS it is controlled by epsphi). Otherwise they are assigned to the transitory component.\nIf \\(d_{s}\\) (seasonal differencing order) is present and \\(\\text{Bphi} &lt; 0\\) (\\(\\text{Bphi}\\) is the estimate of the seasonal autoregressive parameter), the real positive inverse root is assigned to the trend component and the other (\\(s - 1\\)) inverse roots are assigned to the seasonal component. When \\(d_{s} = 0\\), the root is assigned to the seasonal when \\(\\text{Bphi} &lt; - 0.2\\) and/or the overall test for seasonality indicates presence of seasonality. Otherwise it goes to the transitory component. Also, when \\(\\text{Bphi} &gt; 0\\), roots are assigned to the transitory component.\n\nFor further details about JDemetra+ parameters see section TramoSeats.\nIt should be highlighted that when\\(\\ Q &gt; P\\), where \\(Q\\) and \\(P\\) denote the orders of the polynomials \\(\\varphi\\left( B \\right)\\) and \\(\\theta(B)\\), the SEATS decomposition yields a pure MA \\((Q - P)\\) component (hence transitory). In this case the transitory component will appear even when there is no AR factor allocated to it.\nOnce these rules are applied, the factorization of the AR polynomial presented by Equation 2  yields to the identification of the AR polynomials for the components which contain, respectively, the AR roots associated with the trend component, the seasonal component and the transitory component.10\nThen with the partial fraction expansion the spectrum of the final components are obtained.\nFor example, the Airline model for a monthly time series:\n\\[\n(1 - B)(1 - B^{12})x_{t} = (1 + \\theta_{1}B)(1 + \\Theta_{1}B^{12})\\ a_{t}\n\\tag{15}\\] \nis decomposed by SEATS into the model for the trend component:\n\\[\n(1 - B)(1 - B)c_{t} = (1 + \\theta_{c,1}B + \\theta_{c,2}B^{2})a_{c,t}\n\\tag{16}\\] \nand the model for the seasonal component:\n\\[\n\\left( 1 + B + \\ldots + B^{11} \\right)s_{t} = \\left( 1 + \\theta_{s,1}B + \\ldots + {\\theta_{s,11}B}^{11} \\right)a_{s,t},\n\\tag{17}\\] \nAs a result, the Airline model is decomposed as follows: \\[\n\\small\n\\frac{(1 + \\theta_{1}B)(1 + \\Theta_{1}B^{12})}{(1 - B)(1 - B)}a_{t} = \\frac{\\left( 1 + \\theta_{s,1}B + \\ldots + {\\theta_{s,11}B}^{11} \\right)}{\\left( 1 + B + \\ldots + B^{11} \\right)}a_{s,t} + \\frac{(1 + \\theta_{c,1}B + \\theta_{c,2}B^{2})}{(1 - B)(1 - B)}a_{c,t} + u_{t}\n\\tag{18}\\] \nThe transitory component is not present in this case and the irregular component is the white noise.\nThe partial fractions decomposition is performed in a frequency domain. In essence, it consists in portioning of the pseudo-spectrum11 of \\(x_{t}\\) into additive spectra of the components. When the AMB decomposition of the ARIMA model results in the non-negative spectra for all components, the decomposition is called admissible12. In such case an infinite number of admissible decompositions exists, i.e. decompositions that yield the non-negative spectra of all components. Therefore, the MA polynomials and the innovation variances cannot be yet identified from the model of \\(x_{t}\\). As sketched above, to solve this underidentification problem and identify a unique decomposition, it is assumed that for each component the order of the MA polynomial is no greater than the order of the AR polynomial and the canonical solution of S.C. Hillmer and G.C. Tiao is applied13, i.e. all additive white noise is added to the irregular component As a consequence all components derived from the canonical decomposition, except from the irregular, have a spectral minimum of zero and are thus noninvertible14. Given the stochastic features of the series, it can be shown by that the canonical decomposition produces as stable as possible trend and seasonal components since it maximizes the variance of the irregular and minimizes the variance of the other components15. However, there is a price to be paid as canonical components can produce larger revisions in the preliminary estimators of the component16 than any other admissible decomposition.\nThe figure below represents the pseudo-spectrum for the canonical trend and an admissible trend.\n\n\n\nA comparison of canonical trend and admissible trend\n\n\nA pseudo-spectrum is denoted by\\(\\ g_{i}(\\omega)\\), where \\(\\omega\\) represents the angular frequency. The pseudo-spectrum of \\(x_{\\text{it}}\\) is defined as the Fourier transform of ACGF of\\(\\ x_{t}\\) which is expressed as:\n\\[\n\\frac{\\psi_{i}\\left( B \\right)\\psi_{i}\\left( F \\right)}{\\delta_{i}\\left( B \\right)\\delta_{i}\\left( F \\right)}V(a_{i})\n\\tag{19}\\] \nwhere:\n\n\\(\\psi_{i}\\left( F \\right) = \\frac{\\theta_{i}\\left( F \\right)}{\\phi_{i}\\left( F \\right)}\\)\n\\(\\psi_{i}\\left( B \\right) = \\frac{\\theta_{i}\\left( B \\right)}{\\phi_{i}\\left( B \\right)}\\)\n\\(B\\) is the backward operator,\n\\(F\\) is the forward operator.\n\nA pseudo-spectrum for a monthly time series \\(x_{t}\\) is presented in the figure below: The pseudo-spectrum for a monthly series. The frequency \\(\\omega = 0\\) is associated with the trend, frequencies in the range [\\(0 + \\epsilon_{1},\\ \\frac{\\pi}{6} - \\epsilon_{2}\\)] with \\(\\left[0 + \\epsilon_{1},\\ \\frac{\\pi}{6} - \\epsilon_{2}\\right]\\) \\(\\epsilon_{1},\\ \\epsilon_{2} &gt; 0\\) and \\(\\epsilon_{1} &lt; \\ \\frac{\\pi}{6} - \\epsilon_{2}\\) are usually associated with the business-cycle and correspond to a period longer than a year and bounded17. The frequencies in the range [\\(\\frac{\\pi}{6},\\pi\\)] are associated with the short term movements, whose cycle is completed in less than a year. If a series contains an important periodic component, its spectrum reveals a peak around the corresponding frequency and in the ARIMA model it is captured by an AR root. In the example below spectral peaks occur at the frequency \\(\\omega = 0\\) and at the seasonal frequencies ( \\(\\frac{\\pi}{6}\\), \\(\\frac{2\\pi}{6},\\ \\frac{3\\pi}{6},\\ \\frac{4\\pi}{6},\\frac{5\\pi}{6},\\pi\\)). 18\n\n\n\nThe pseudo-spectrum for a monthly series\n\n\nIn the decomposition procedure, the pseudo-spectrum of the time series \\(x_{t}\\) is divided into the spectra of its components (in the example figure below, four components were obtained).\n\n\n\nThe pseudo-spectra for the components"
  },
  {
    "objectID": "M-SEATS-decomposition.html#estimation-of-the-components-with-the-wiener-kolmogorow-filter",
    "href": "M-SEATS-decomposition.html#estimation-of-the-components-with-the-wiener-kolmogorow-filter",
    "title": "SEATS decomposition",
    "section": "Estimation of the components with the Wiener-Kolmogorow filter",
    "text": "Estimation of the components with the Wiener-Kolmogorow filter\nThe various components are estimated using Wiener-Kolmogorow (WK) filters. JDemetra+ includes three options to estimate the WK filter, namely Burman, KalmanSmoother and MCElroyMatrix19. Here the first of abovementioned options, proposed by BURMAN, J.P. (1980) will be explained.\nThe estimation procedure and the properties of the WK filter are easier to explain with a two-component model. Let the seasonally adjusted series (\\(s_{t}\\)) be the signal of interest and the seasonal component (\\(n_{t}\\)) be the remainder, “the noise”. The series is given by the model Equation 2  and from Equation 4  the models for theoretical components are:\n\\[\n\\varphi_{s}(B)s_{t} = \\theta_{s}(B)a_{\\text{st}}\n\\tag{20}\\] \nand\n\\[\n\\varphi_{n}(B)n_{t} = \\theta_{n}(B)a_{\\text{nt}}\n\\tag{21}\\] \nFrom Equation 6  and Equation 7  it is clear that \\(\\varphi\\left( B \\right) = \\varphi_{s}(B)\\varphi_{n}(B)\\) and \\(\\theta\\left( B \\right)a_{t} = \\theta_{s}(B)a_{\\text{st}}+\\theta_{n}(B)a_{\\text{nt}}\\).\nAs the time series components are never observed, their estimators have to be used. Let us note \\(X_{T}\\) an infinite realization of the time series \\(x_{t}\\). SEATS computes the Minimum Mean Square Error (MMSE) estimator of \\(s_{t}\\), e.g. the estimator \\(\\widehat{s}_{t}\\) that minimizes \\(E\\lbrack\\left({s_{t}-{\\widehat{s}}_{t})}^{2}|X_{T} \\right)\\rbrack\\). Under the normality assumption \\({\\widehat{s}}_{t|T}\\) is also equal to the conditional expectation \\(E\\left(s_{t}|X_{T}\\right)\\), so it can be presented as a linear function of the elements in \\(X_{T}\\).20 WHITTLE (1963) shows that the MMSE estimator of \\({\\widehat{s}}_{t}\\) is:\n\\[\n{\\widehat{s}}_{t} = k_{s}\\frac{\\psi_{s}(B)\\psi_{s}(F)}{\\psi(B)\\psi(F)}x_{t}\n\\tag{22}\\] \nwhere\n\n\\(\\psi(B)= \\frac{\\theta(B)}{\\phi(B)}\\),\n\\(F = B^{- 1}\\),\n\\(k_{s}=\\frac{V(a_{s})}{V(a)}\\),\n\n\\(V(a_{s})\\) is the variance of \\(a_{st}\\) and \\(V(a)\\) is the variance of \\(a_{t}\\).\nExpressing the \\(\\psi\\left(B\\right)\\) polynomials as functions of the AR and MA polynomials, after cancelation of roots, the estimator of \\(s_{t}\\) can be expressed as:\n\\[\n{\\widehat{s}}_{t} = k_{s}\\frac{\\theta_{s}\\left(B\\right)\\theta_{s}\\left(F\\right)\\varphi_{n}\\left(B \\right)\\delta_{n}\\left(B\\right)\\varphi_{n}\\left(F\\right)\\delta_{n}\\left(F\\right)}{\\theta\\left(B\\right)\\theta\\left(F \\right)}x_{t}\n\\tag{23}\\] \nwhere:\n\\[\n\\nu_{s}\\left( B,F \\right) = k_{s}\\frac{\\theta_{s}\\left( B \\right)\\theta_{s}\\left( F \\right)\\varphi_{n}\\left( B \\right)\\delta_{n}\\left( B \\right)\\varphi_{n}\\left( F \\right)\\delta_{n}\\left( F \\right)}{\\theta\\left( B \\right)\\theta\\left( F \\right)}\n\\tag{24}\\] \nis a WK filter.\nEquation Equation 24  shows that the WK filter is two-sided (uses observations both from the past and from the future), centered (the number of points in the past is the same as in the future) and symmetric (for any \\(k\\) the weight applied to \\(x_{t - k}\\) and \\(x_{t + k}\\) is the same), which allows the phase effect to be avoided. Due to invertibility of \\(\\theta\\left( B \\right)\\) (and \\(\\theta\\left( F \\right)\\)) the filter is convergent in the past and in the future.\nThe estimator can be presented as\n\\[\n{\\widehat{s}}_{t} = \\nu_{i}\\left(B,F\\right)x_{t}\n\\tag{25}\\] \nwhere \\(\\nu_{i}\\left(B,F\\right)=\\nu_{0}+ \\sum_{j = 1}^{\\infty}\\nu_{ij}(B^{j}+F^{j})\\) is the WK filter.\nThe example of the WK filters obtained for the pseudo-spectra of the series illustrated above is shown on the figure below: WK filters for components.\n\n\n\nWK filters for components\n\n\nThe WK filter from Equation 24  can also be expressed as a ratio of two pseudo-autocovariance generating functions (p-ACGF). The p-ACGF function summarizes the sequence of absolutely summable autocovariances of a stationary process \\(x_{t}\\) (see section section Spectral Analysis).\nThe ACGF function of an ARIMA process is expressed as:\n\\[\nacgf(B) = \\frac{\\theta\\left( B \\right)\\theta\\left( F \\right)}{\\phi\\left( B \\right)\\delta\\left( B \\right)\\phi\\left( F \\right)\\delta\\left( F \\right)}V(a)\n\\tag{26}\\] \nAnd, the WK filter can be rewritten as:\n\\[\n\\nu_{s}\\left( B,F \\right) = \\frac{\\gamma_{s}(B,F)}{\\gamma(B,F)}\n\\tag{27}\\] \nwhere:\n\n\\(\\gamma_{s}\\left( B,F \\right) = \\frac{\\theta_{s}\\left( B \\right)\\theta_{s}\\left( F \\right)}{\\phi_{s}\\left( B \\right)\\delta_{s}\\left( B \\right)\\phi_{s}\\left( F \\right)\\delta_{s}\\left( F \\right)}V(a_{s})\\) is the p-ACGF of \\(s_{t}\\);\n\\(\\gamma\\left( B,F \\right) = \\frac{\\theta\\left( B \\right)\\theta\\left( F \\right)}{\\phi\\left( B \\right)\\delta\\left( B \\right)\\phi\\left( F \\right)\\delta\\left( F \\right)}V(a)\\) is the p-ACGF of \\(x_{t}\\).\n\nFrom Equation 24  it can be seen that the WK filter depends on both the component and the series models. Consequently, the estimator of the component and the WK filter reflect the characteristic of data and by construction, the WK filter adapts itself to the series under consideration. Therefore, the ARIMA model is of particular importance for the SEATS method. Its misspecification results in an incorrect decomposition.\nThis adaptability, if the model has been correctly determined, avoids the dangers of under and overestimation with an ad-hoc filtering. For example, for the series with a highly stochastic seasonal component the filter adapts to the width of the seasonal peaks and the seasonally adjusted series does not display any spurious seasonality21. Examples of WK filters for stochastic and stable seasonal components are presented on the figure below.\n\n\n\nWK filters for stable and stochastic seasonal components\n\n\nThe derivation of the components requires an infinite realization of \\(x_{t}\\) in the direction of the past and of the future. However, the convergence of the WK filter guarantees that, in practice, it could be approximated by a truncated (finite) filter and, in most applications, for large \\(k\\) the estimator for the central periods of the series can be safely seen as generated by the WK filter22:\n\\[\n{\\widehat{s}}_{t}=\\nu_{k}x_{t-k} + \\ldots + \\nu_{0}x_{t} + \\ldots + \\nu_{k}x_{t+k}\n\\tag{28}\\] \nWhen \\(T &gt; 2L + 1\\), where \\(T\\) is the last observed period, and \\(L\\) is an a priori number that typically expands between 3 and 5 years, the estimator expressed by Equation 23  can be assumed as the final (historical) estimator for the central observations of the series23. In practice, the Wiener-Kolmogorov filter is applied to \\(x_{t}\\) extended with forecasts and backcasts from the ARIMA model. The final or historical estimator of \\({\\widehat{s}}_{t}\\), is obtained with a doubly infinite filter, and therefore contains an error \\(e_{st}\\) called final estimation error, which is equal \\(e_{st}=s_{t}-{\\widehat{s}}_{t}\\).\nIn the frequency domain, the Wiener-Kolmogorov filter\\(\\ \\nu(B,F)\\) that provides the final estimator of \\(s_{t}\\) is expressed as the ratio of the \\(s_{t}\\) and \\(x_{t}\\) pseudo-spectra:\n\\[\n\\widetilde{\\nu}\\left( \\omega \\right) = \\frac{g_{s}(\\omega)}{g_{x}(\\omega)}\n\\tag{29}\\] \nThe function \\(\\widetilde{\\nu}\\left( \\omega \\right)\\) is also referred as the gain of the filter.24 GÓMEZ, V., and MARAVALL, A. (2001a) show that when for some frequency the signal (the seasonally adjusted series) dominates the noise (seasonal fluctuations) the gain \\(\\widetilde{\\nu}\\left( \\omega \\right)\\) approaches 1. On the contrary, when for some frequency the noise dominates the gain \\(\\widetilde{\\nu}\\left( \\omega \\right)\\) approaches 0.\nThe spectrum of the estimator of the seasonal component is expressed as:\n\\[\ng_{\\widehat{s}}\\left( \\omega \\right) = \\left\\lbrack \\frac{g_{s}(\\omega)}{g_{x}(\\omega)} \\right\\rbrack^{2}g_{x}(\\omega)\n\\tag{30}\\] \nwhere\n\n\\(\\ \\left\\lbrack \\widetilde{\\nu}\\left( \\omega \\right) \\right\\rbrack^{2} = \\left\\lbrack \\frac{g_{s}(\\omega)}{g_{x}(\\omega)} \\right\\rbrack^{2} = \\left\\lbrack \\frac{g_{s}(\\omega)}{g_{s}(\\omega) + g_{n}(\\omega)} \\right\\rbrack^{2} = \\left\\lbrack \\frac{1}{1 + \\frac{1}{r(\\omega)}} \\right\\rbrack^{2}\\) is the squared gain of the filter ;\n\\(r\\left( \\omega \\right) = \\frac{g_{s}(\\omega)}{g_{n}(\\omega)}\\) represents the signal-to-noise ratio.\n\nFor each \\(\\omega\\), the MMSE estimation gives the signal-to-noise ratio. If this ratio is high, then the contribution of that frequency to the estimation of the signal will be also high. Assume that the trend is a signal that needs to be extracted from a seasonal time series. Then \\(R\\left( 0 \\right) = 1\\) and the frequency \\(\\omega = 0\\) will only be used for trend estimations. For seasonal frequencies \\(R\\left( \\omega \\right) = 0\\), so that these frequencies are ignored in computing the trend resulting in spectral zeros in \\(g_{\\widehat{s}}\\left( \\omega \\right)\\). For this reason, unlike the spectrum of the component, the component spectrum contains dips as it can be seen on the figure below: Component spectrum and estimator spectrum for trend.\n\n\n\nComponent spectrum and estimator spectrum for trend\n\n\nFrom the equation Equation 29  it is clear that the squared gain of the filter determines how the variance of the series contributes to the variance of the seasonal component for the different frequencies. When \\(\\widetilde{\\nu}\\left( \\omega \\right) = 1\\), the full variation of \\(x_{t}\\) for that frequency is passed to \\({\\widehat{s}}_{t}\\), while if \\(\\widetilde{\\nu}\\left(\\omega\\right) = 0\\) the variation of \\(x_{t}\\) for that frequency is fully ignored in the computation of \\({\\widehat{s}}_{t}\\). These two cases are well illustrated by the figure below that shows the square gain of the WK filter for two series already analysed in the figure above (Figure: WK filters for stable and stochastic seasonal components).\n\n\n\nThe squared gain of the WK filter for stable and stochastic seasonal components.\n\n\nSince \\(r\\left( \\omega \\right) \\geq 0\\), then \\(\\widetilde{\\nu}\\left( \\omega \\right) \\leq 1\\) and from Equation 29  it can be derived that \\(g_{\\widehat{s}}\\left( \\omega \\right) = \\widetilde{\\nu}\\left( \\omega \\right)g_{s}(\\omega)\\). As a result, the estimator will always underestimate the component, i.e. it will be always more stable that the component.25\nSince \\(g_{\\widehat{n}}\\left( \\omega \\right) &lt; g_{n}\\left( \\omega \\right)\\) and\\(\\ g_{\\widehat{s}}\\left( \\omega \\right) &lt; g_{s}\\left( \\omega \\right)\\) the expression: \\(g_{x}\\left( \\omega \\right) - \\left\\lbrack g_{\\widehat{n}}\\left( \\omega \\right) + g_{\\widehat{s}}\\left( \\omega \\right) \\right\\rbrack \\geq 0\\) is the cross-spectrum. As it is positive, the MMSE yields correlated estimators. This effect emerges since variance of estimator is smaller than the variance of component. Nevertheless, if at least one non-stationary component exists, cross-correlations estimated by TRAMO-SEATS will tend to zero as cross-covariances between estimators of the components are finite. In practice, the inconvenience caused by this property will likely be of little relevance.\nPreliminary estimators for the components\nGÓMEZ, V., and MARAVALL, A. (2001a) point out that the properties of the estimators have been derived for the final (or historical) estimators. For a finite (long enough) realization, they can be assumed to characterize the estimators for the central observations of the series, but for periods close to the beginning of the end the filter cannot be completed and some preliminary estimator has to be used. Indeed, the historical estimator shown in Equation 28 is obtained for the central periods of the series. However, when \\(t\\) approaches \\(T\\) (last observation), the WK filter requires observations, which are not available yet. For this reason a preliminary estimator needs to be used.\nTo introduce preliminary estimators let us consider a semi-finite realization \\(\\lbrack x_{- \\infty}\\),…\\(\\ x_{T}\\)], where \\(T\\) is the last observed period. The preliminary estimator of \\(x_{\\text{it}}\\) obtained at \\(T\\), \\((T - t = k \\geq 0)\\) can be expressed as\n\\[\n{\\widehat{x}}_{it|t + k}=\\nu_{i}\\left(B,F\\right)x_{t|T}^{e}\n\\tag{31}\\] \nwhere\n\n\\(\\nu_{i}\\left(B,F \\right)\\) is the WK filter ;\n\\(x_{t|T}^{e}\\) is the extended series, such that \\(x_{t|T}^{e} = x_{t}\\) for \\(t \\leq T\\) and \\(x_{t|T}^{e}={\\widehat{x}}_{t|T}\\) for \\(t&gt;T\\), where \\({\\widehat{x}}_{t|T}\\) denotes the forecast of \\(x_{t}\\) obtained at period \\(T\\).\n\nThe future \\(k\\) values necessary to apply the filter are not yet available and are replaced by their optimal forecasts from the ARIMA model on \\(x_{t}\\). When \\(k=0\\) the preliminary estimator becomes the concurrent estimator. As the forecasts are linear functions of present and past observations of \\(x_{t}\\), the preliminary estimator \\({\\widehat{x}}_{it}\\) will be a truncated asymmetric filter applied to \\(x_{t}\\) that generates a phase effect26.\nWhen a new observation \\(x_{T + 1}\\) becomes available the forecast \\({\\widehat{x}}_{T + 1|T}\\) is replaced by the observation and the forecast \\({\\widehat{x}}_{iT + j|T}\\), \\(j &gt; 1\\) are updated to \\(x_{T + j|T + 1}\\) resulting in the revision error27. The total error in the preliminary estimator \\(d_{it|t + k}\\) is expressed as a sum of the final estimation error (\\(e_{it}\\)) and the revision error (\\(r_{it|t + k}\\)), i.e.:\n\\[\nd_{it|t + k} = x_{it}-{\\widehat{x}}_{it|t + k} = \\left(x_{it} - {\\widehat{x}}_{it}\\right) + \\left(          {\\widehat{x}}_{it} - {\\widehat{x}}_{it|t + k} \\right) = e_{it} + r_{it|t + k}\n\\tag{32}\\] \nwhere:\n\n\\(x_{it}-i^{th}\\) component;\n\\({\\widehat{x}}_{it|t + k}\\)- the estimator of \\(x_{it}\\) when the last observation is \\(x_{t + k}\\).\n\nTherefore the preliminary estimator is subject not only to the final error but also to a revision error, which are orthogonal to each other28. The revision error decreases as \\(k\\) increases, until it can be assumed equal to 0 for large enough \\(k\\).\nIt’s worth remembering that SEATS estimates the unobservable components of the time series so the “true” components are never observed. Therefore, MARAVALL, A. (2009) stresses that the error in the historical estimator is more of academic rather than practical interest. In practice, interest centres on revisions. (…) the revision standard deviation will be an indicator of how far we can expect to be from the optimal estimator that will be eventually attained, and the speed of convergence of \\({\\theta\\left( B \\right)\\ }^{- 1}\\) will dictate the speed of convergence of the preliminary estimator to the historical one. The analysis of an error is therefore useful for making decision concerning the revision policy, including the policy for revisions and horizon of revisions."
  },
  {
    "objectID": "M-SEATS-decomposition.html#psie-weights",
    "href": "M-SEATS-decomposition.html#psie-weights",
    "title": "SEATS decomposition",
    "section": "PsiE-weights",
    "text": "PsiE-weights\nThe estimator of the component is calculated as \\({\\widehat{x}}_{it} = \\nu_{s}\\left(B,F\\right)x_{t}\\). By replacing \\(x_{it}=\\frac{\\theta(B)}{\\gamma(B)\\delta(B)}a_{t}\\), the component estimator can be expressed as29:\n\\[\n{\\widehat{x}}_{it} = \\xi_{s}\\left(B,F\\right)a_{t}\n\\tag{33}\\] \nwhere \\(\\xi_{s}\\left( B,F \\right) = \\ldots + \\xi_{j}B^{j} + \\ldots + \\xi_{1}B + \\xi_{0} + \\xi_{- 1}F\\ldots\\xi_{- j}F^{j} + \\ldots\\).\nThis representation shows the estimator as a filter applied to the innovation \\(a_{t}\\), rather than on the series \\(x_{t}\\)30. Hence, the filter from Equation 32  can be divided into two components: the first one, i.e. \\(\\ldots + \\xi_{j}B^{j}+ \\ldots+ \\xi_{1}B + \\xi_{0}\\), applies to prior and concurrent innovations, the second one, i.e. \\(\\xi_{- 1}F + \\ldots + \\xi_{- j}F^{j}\\) applies to future (i.e. posterior to \\(t\\)) innovations. Consequently, \\(\\xi_{j}\\) determines the contribution of \\(a_{t - j}\\) to \\({\\widehat{s}}_{t}\\) while \\(\\xi_{- j}\\) determines the contribution of \\(a_{t + j}\\) to \\({\\widehat{s}}_{t}\\). Finally, the estimator of the component can be expressed as:\n\\[\n{\\widehat{x}}_{it} =\\xi_{i}(B)^{-}a_{t} + \\xi_{i}(F)^{+}a_{t + 1}\n\\tag{34}\\] \nwhere:\n\n\\(\\xi_{i}{(B)}^{-}a_{t}\\) is an effect of starting conditions, present and past innovations in series;\n\\(\\xi_{i}{(F)}^{+}a_{t + 1}\\) is an effect of future innovations.\n\nFor the two cases already presented in figure WK filters for stable and stochastic seasonal components and figure The squared gain of the WK filter for stable and stochastic seasonal components above, the psi-weights are shown in the figure below.\n\n\n\nWK filters and squared gain of the WK filter\n\n\nIt can be shown that \\({\\xi}_{- 1},\\ldots,\\xi_{- j}\\) are convergent and \\(\\xi_{j},\\ldots, {\\xi}_{1},\\xi_{0}\\) are divergent. From Equation 33 , the concurrent estimator is equal to\n\\[\n{\\widehat{x}}_{it|t} = E_{t}x_{it}=E_{t}{\\widehat{x}}_{it} = {\\xi}_{i}(B)^{-}a_{t}\n\\tag{35}\\] \nso that the revision\n\\[\nr_{it} = {\\widehat{x}}_{it} - {\\widehat{x}}_{it|t} = \\xi_{i}(F)^{+}a_{t + 1}\n\\tag{36}\\] \nis a zero-mean stationary MA process. As a result, historical and preliminary estimators are cointegrated. From expression Equation 25  the relative size of the full revision and the speed of convergence can be obtained."
  },
  {
    "objectID": "M-SEATS-decomposition.html#footnotes",
    "href": "M-SEATS-decomposition.html#footnotes",
    "title": "SEATS decomposition",
    "section": "",
    "text": "In the original software SEATS can be used either with TRAMO, operating on the input received from the latter, or alone, fitting an ARIMA model to the series.↩︎\nGÓMEZ, V., and MARAVALL, A. (1998).↩︎\nGÓMEZ, V., and MARAVALL, A. (1997).↩︎\nGÓMEZ, V., and MARAVALL, A. (2001a).↩︎\nFor description of the spectrum see section Spectral Analysis.↩︎\nMARAVALL, A. (1995).↩︎\nDescription based on KAISER, R., and MARAVALL, A. (2000) and MARAVALL, A. (2008c).↩︎\nFor details see MARAVALL, A., CAPORELLO, G., PÉREZ, D., and LÓPEZ, R. (2014).↩︎\nIn JDemetra+ this argument is called Trend boundary.↩︎\nThe AR roots close to or at the trading day frequency generates a stochastic trading day component. A stochastic trading day component is always modelled as a stationary ARMA(2,2), where the AR part contains the roots close to the TD frequency, and the MA(2) is obtained from the model decomposition (MARAVALL, A., and PÉREZ, D. (2011)). This component, estimated by SEATS, is not implemented by the current version of JDemetra+.↩︎\nThe term pseudo-spectrum is used for a non-stationary time series, while the term spectrum is used for a stationary time series.↩︎\nIf the ARIMA model estimated in TRAMO does not accept an admissible decomposition, SEATS replaces it with a decomposable approximation. The modified model is therefore used to decompose the series. There are also other rare situations when the ARIMA model chosen by TRAMO is changed by SEATS. It happens when, for example, the ARIMA models generate unstable seasonality or produce a senseless decomposition. Such examples are discussed by MARAVALL, A. (2009).↩︎\nHILLMER, S.C., and TIAO, G.C. (1982).↩︎\nGÓMEZ, V., and MARAVALL, A. (2001a).↩︎\nHILLMER, S.C., and TIAO, G.C. (1982).↩︎\nMARAVALL, A. (1986).↩︎\nKAISER, R., and MARAVALL, A. (2000).↩︎\nKAISER, R., and MARAVALL, A. (2000).↩︎\nThe choice of the estimation method is controlled by the Method parameter, explained in the SEATS specification section.↩︎\nMARAVALL, A. (2008c).↩︎\nMARAVALL, A. (1995).↩︎\nMARAVALL, A., and PLANAS, C. (1999).↩︎\nMARAVALL, A. (1998).↩︎\nGÓMEZ, V., and MARAVALL, A. (2001a).↩︎\nIbid.↩︎\nKAISER, R., and MARAVALL, A. (2000).↩︎\nMARAVALL, A. (1995).↩︎\nMARAVALL, A. (2009).↩︎\nThe section is based on KAISER, R., and MARAVALL, A. (2000).↩︎\nSee section PsiE-weights. For further details see MARAVALL, A. (2008).↩︎"
  },
  {
    "objectID": "M-Trend-Estimation-Local-Polynomials.html",
    "href": "M-Trend-Estimation-Local-Polynomials.html",
    "title": "Trend Estimation",
    "section": "",
    "text": "Under construction."
  },
  {
    "objectID": "M-tests.html#introduction",
    "href": "M-tests.html#introduction",
    "title": "Tests",
    "section": "Introduction",
    "text": "Introduction\nThis chapter describes all the tests available in JDemetra+, via Graphical User interface and/or R packages. An outline of the underlying theoretical principles of each test is provided.\nThe procedure to apply these tests in context is described when their use is relevant in the chapters dedicated to algorithms description, mainly on seasonal adjustment."
  },
  {
    "objectID": "M-tests.html#tests-on-residuals",
    "href": "M-tests.html#tests-on-residuals",
    "title": "Tests",
    "section": "Tests on residuals",
    "text": "Tests on residuals\n\n\n\nTest\nPurpose\nGUI\nR package\n\n\n\n\nLjung-Box\nautocorrelation\nyes\n\n\n\nBox-Pierce\nautocorrelation\nyes\n\n\n\nDoornik-Hansen\nnormality\nyes\nrjd3tookit\n\n\n\n\nLjung-Box\nThe Ljung-Box Q-statistics are given by:\n\\[\n\\text{LB}\\left( k \\right) = n \\times (n + 2) \\times \\sum_{k = 1}^{K}\\frac{\\rho_{a,k}^{2}}{n - k}\n\\tag{1}\\]\nwhere \\(\\rho_{a,k}^{2}\\) is the autocorrelation coefficient at lag \\(k\\) of the residuals \\({\\widehat{a}}_{t}\\), \\(n\\) is the number of terms in differenced (? differenciated ?) series, \\(K\\) is the maximum lag being considered, set in JDemetra+ to \\(24\\) (monthly series) or \\(8\\) (quarterly series).\nIf the residuals are random (which is the case for residuals from a well specified model), they will be distributed as \\(\\chi_{(K - m)}^{2}\\), where \\(m\\) is the number of parameters in the model which has been fitted to the data. (edit: not the residuals, but \\(\\widehat{\\rho}\\) )\nThe Ljung-Box and Box-Pierce tests sometimes fail to reject a poorly fitting model. Therefore, care should be taken not to accept a model on a basis of their results. For the description of autocorrelation concept see section Autocorrelation function and partial autocorrelation function.\n\n\nBox-Pierce\nThe Box-Pierce Q-statistics are given by:\n\\[\n\\text{BP}\\left( k \\right) = n\\sum_{k = 1}^{K}\\rho_{a,k}^{2}\n\\]\nwhere:\n\n\\(\\rho_{a,k}^{2}\\) is the autocorrelation coefficient at lag \\(k\\) of the residuals \\({\\widehat{a}}_{t}\\).\n\\(n\\) is the number of terms in differenced (differenciated?) series;\n\\(K\\) is the maximum lag being considered, set in JDemetra+ to \\(24\\) (monthly series) or \\(8\\) (quarterly series).\n\nIf the residuals are random (which is the case for residuals from a well specified model), they will be distributed as \\(\\chi_{(K - m)}^{2}\\) degrees of freedom, where \\(m\\) is the number of parameters in the model which has been fitted to the data.(edit: same as above)\n\n\nDornik-Hansen\nThe Doornik-Hansen test for multivariate normality (DOORNIK, J.A., and HANSEN, H. (2008)) is based on the skewness and kurtosis of multivariate data that is transformed to ensure independence. It is more powerful than the Shapiro-Wilk test for most tested multivariate distributions1.\nThe skewness and kurtosis are defined, respectively, as: \\(s = \\frac{m_{3}}{\\sqrt{m_{2}}^{3}}\\) and \\(k = \\frac{m_{4}}{m_{2}^{2}}\\),\nwhere:\n\n\\(m_{i} = \\frac{1}{n}\\sum_{i = 1}^{n}{(x_{i}}{- \\overline{x})}^{i}\\) ;\n\\(\\overline{x} = \\frac{1}{n}\\sum_{i = 1}^{n}x_{i}\\) ;\n\\(n\\) is a number of (non-missing) residuals.\n\nThe Doornik-Hansen test statistic derives from SHENTON, L.R., and BOWMAN, K.O. (1977) and uses transformed versions of skewness and kurtosis.\nThe transformation for the skewness \\(s\\) into \\(\\text{z}_{1}\\) is as in D’AGOSTINO, R.B. (1970):\n\\[\n\\beta = \\frac{3(n^{2} + 27n - 70)(n + 1)(n + 3)}{(n - 2)(n + 5)(n + 7)(n + 9)}\n\\]\n\\[\n\\omega^{2} = - 1 + \\sqrt{2(\\beta - 1)}\n\\]\n\\[\n\\delta = \\frac{1}{\\sqrt{\\log{(\\omega}^{2})}}\n\\]\n\\[\ny = s\\sqrt{\\frac{(\\omega^{2} - 1)(n + 1)(n + 3)}{12(n - 2)}}\n\\]\n\\[\nz_{1} = \\delta log(y + \\sqrt{y^{2} - 1})\n\\]\nThe kurtosis \\(k\\) is transformed from a gamma distribution to \\(\\chi^{2}\\), which is then transformed into standard normal \\(z_{2}\\) using the Wilson-Hilferty cubed root transformation:\n\\[\n\\delta = (n - 3)(n + 1)(n^{2} + 15n - 4)\n\\]\n\\[\na = \\frac{(n - 2)(n + 5)(n + 7)(n^{2} + 27n - 70)}{6\\delta}\n\\]\n\\[\nc = \\frac{(n - 7)(n + 5)(n + 7)(n^{2} + 2n - 5)}{6\\delta}\n\\]\n\\[\nl= \\frac{(n + 5)(n + 7)({n^{3} + 37n}^{2} + 11n - 313)}{12\\delta}\n\\]\n\\[\n\\alpha = a + c \\times s^{2}\n\\]\n\\[\n\\chi = 2l(k - 1 - s^{2})\n\\]\n\\[\nz_{2} = \\sqrt{9\\alpha}\\left( \\frac{1}{9\\alpha} - 1 + \\sqrt[3]{\\frac{\\chi}{2\\alpha}} \\right)\n\\]\nFinally, the Doornik-Hansen test statistic is defined as the sum of squared transformations of the skewness and kurtosis. Approximately, the test statistic follows a \\(\\chi^{2}\\) distribution, i.e.:\n\\[\nDH = z_{1}^{2} + z_{2}^{2}\\sim\\chi^{2}(2)\n\\]"
  },
  {
    "objectID": "M-tests.html#seasonality-tests",
    "href": "M-tests.html#seasonality-tests",
    "title": "Tests",
    "section": "Seasonality tests",
    "text": "Seasonality tests\ntable with all tests by purpose and accessibility\n\n\n\n\n\n\n\n\n\nTest\nPurpose\nGUI\nR package\n\n\n\n\nQS test\nAutocorrelation at seasonal lags\nyes\n\n\n\nF-test with seasonal dummies\nStable seasonality\nyes\nrjd3sa\n\n\nIdentification of spectral peaks\nSeasonal frequencies\nyes\nrjd3sa\n\n\nFriedman test\nStable seasonality\nyes\nrjd3sa\n\n\nTwo-way variance analysis\nMoving seasonality\nyes\n\n\n\n\n\nQS Test on autocorrelation at seasonal lags\nThe QS test is a variant of the Ljung-Box test computed on seasonal lags, where we only consider positive auto-correlations\nMore exactly,\n\\[\nQS=n \\left(n+2\\right)\\sum_{i=1}^k\\frac{\\left[ \\max  \\left(0, \\hat\\gamma_{i \\cdot l}\\right)\\right]^2}{n-i \\cdot l}\n\\]\nwhere \\(k=2\\), so only the first and second seasonal lags are considered. Thus, the test would checks the correlation between the actual observation and the observations lagged by one and two years. Note that \\(l=12\\) when dealing with monthly observations, so we consider the autocovariances \\(\\hat\\gamma_{12}\\) and \\(\\hat\\gamma_{24}\\) alone. In turn, \\(k=4\\) in the case of quarterly data.\nUnder H0, which states that the data are independently distributed, the statistics follows a \\(\\chi \\left(k\\right)\\) distribution. However, the elimination of negative correlations makes it a bad approximation. The p-values would be given by \\(P(\\chi^{2}\\left( k \\right) &gt; Q)\\) for \\(k = 2\\). As \\({P(\\chi}^{2}(2)) &gt; 0.05 = 5.99146\\) and \\({P(\\chi}^{2}(2)) &gt; 0.01 = 9.21034\\), \\(QS &gt; 5.99146\\) and \\(QS &gt; 9.21034\\) would suggest rejecting the null hypothesis at \\(95\\%\\) and \\(99\\%\\) significance levels, respectively.\n\n\nModification\nMaravall (2012) proposes approximate the correct distribution (p-values) of the QS statistic using simulation techniques. Using 1000K replications of sample size 240, the correct critical values would be 3.83 and 7.09 with confidence levels of \\(95\\%\\) and \\(99\\%\\), respectively (lower than the 5.99146 and 9.21034 shown above). For each of the simulated series, he obtains the distribution by assuming \\(QS=0\\) when \\(\\hat\\gamma_{12}\\), so in practice this test will detect seasonality only when any of these conditions hold: - Statistically significant positive autocorrelation at lag 12 - Non-negative sample autocorrelation at lag 12 and statistically significant positive autocorrelation at lag 24\n\n\nUse\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\nqs\n\n\nThe test can be applied to the input series before any seasonal adjustment method has been applied. It can also be applied to the seasonally adjusted series or to the irregular component.\n\n\nReferences\n\nLJUNG G. M. and G. E. P. BOX (1978). “On a Measure of a Lack of Fit in Time Series Models”. Biometrika 65 (2): 297–303. doi:10.1093/biomet/65.2.297\nMARAVALL, A. (2011). “Seasonality Tests and Automatic Model Identification in Tramo-Seats”. Manuscript\nMARAVALL, A. (2012). “Update of Seasonality Tests and Automatic Model Identification in TRAMO-SEATS”. Bank of Spain (November 2012)\n\n\n\nF-test on seasonal dummies\nThe F-test on seasonal dummies checks for the presence of deterministic seasonality. The model used here uses seasonal dummies (mean effect and 11 seasonal dummies for monthly data, mean effect and 3 for quarterly data) to describe the (possibly transformed) time series behaviour. The test statistic checks if the seasonal dummies are jointly statistically not significant. When this hypothesis is rejected, it is assumed that the deterministic seasonality is present and the test results are displayed in green.\nThis test refers to Model-Based \\(\\chi^{2}\\ \\) and F-tests for Fixed Seasonal Effects proposed by LYTRAS, D.P., FELDPAUSCH, R.M., and BELL, W.R. (2007) that is based on the estimates of the regression dummy variables and the corresponding t-statistics of the Reg-Arima model, in which the ARIMA part of the model has a form (0,1,1)(0,0,0). The consequences of a misspecification of a model are discussed in LYTRAS, D.P., FELDPAUSCH, R.M., and BELL, W.R. (2007).\nFor a monthly time series the Reg-Arima model structure is as follows:\n\\[\n\\left( 1 - B \\right)\\left( y_{t} - \\beta_{1}M_{1,t} - \\ldots - \\beta_{11}M_{11,t} - \\gamma X_{t} \\right) = \\mu + (1 - B)a_{t}\n\\] \nwhere:\n\n\\(M_{j,t} =\\begin{cases}1 & \\text{ in month } j = 1, \\ldots, 11 \\\\- 1 & \\text{ in December}\\\\0 & \\text{ otherwise}\\end{cases} \\text{ - dummy variables;}\\)\n\\(y_{t}\\) – the original time series;\n\\(B\\) – a backshift operator;\n\\(X_{t}\\) – other regression variables used in the model (e.g. outliers, calendar effects, user-defined regression variables, intervention variables);\n\\(\\mu\\) – a mean effect;\n\\(a_{t}\\) – a white-noise variable with mean zero and a constant variance.\n\nIn the case of a quarterly series the estimated model has a form:\n\\[\n\\left( 1 - B \\right)\\left( y_{t} - \\beta_{1}M_{1,t} - \\ldots - \\beta_{3}M_{3,t} - \\gamma X_{t} \\right) = \\mu + (1 - B)a_{t}\n\\tag{2}\\] \nwhere:\n\\[\nM_{j,t} =\n\\begin{cases}\n1 & \\text{ in quarter} j = 1, \\ldots, 3 \\\\\n- 1 & \\text{ in the fourth quarter}\\\\\n0 & \\text{ otherwise}\n\\end{cases} \\text{ - dummy variables;}\n\\]\nOne can use the individual t-statistics to assess whether seasonality for a given month is significant, or a chi-squared test statistic if the null hypothesis is that the parameters are collectively all zero. The chi-squared test statistic is \\({\\widehat{\\chi}}^{2} = {\\widehat{\\beta}}^{'}{\\lbrack Var(\\widehat{\\beta})}^{\\ })^{- 1}\\rbrack{\\widehat{\\beta}}^{\\ }\\) in this case compared to critical values from a \\(\\chi^{2}\\left( \\text{df} \\right)\\)-distribution, with degrees of freedom \\(df = 11\\) (monthly series) or \\(df = 3\\) (quarterly series). Since the \\({Var(\\widehat{\\beta})}^{\\ }\\) computed using the estimated variance of \\(\\alpha_{t}\\) may be very different from the actual variance in small samples, this test is corrected using the proposed \\(\\text{F}\\) statistic:\n\\[\nF = \\frac{ {\\widehat{\\chi}}^{2}}{s - 1} \\times \\frac{n - d - k}{n - d}\n\\]\nwhere \\(n\\) is the sample size, \\(d\\) is the degree of differencing, s is time series frequency (12 for a monthly series, 4 for a quarterly series) and \\(k\\) is the total number of regressors in the Reg-Arima model (including the seasonal dummies \\(\\text{M}_{j,t}\\) and the intercept).\nThis statistic follows a \\(F_{s - 1,n - d - k}\\) distribution under the null hypothesis.\n\n\nIdentification of spectral peaks\n\n\nFriedman test for stable seasonality test\nThe Friedman test is a non-parametric method for testing that samples are drawn from the same population or from populations with equal medians. The significance of the month (or quarter) effect is tested. The Friedman test requires no distributional assumptions. It uses the rankings of the observations. If the null hypothesis of no stable seasonality is rejected at the 0.10% significance level then the series is considered to be seasonal and the test’s outcome is displayed in green.\nThe test statistic is constructed as follows. Consider first the matrix of data \\(\\left\\{x_{ij}\\right\\}_{n \\times k}\\) with \\(n\\) rows (the blocks, i.e. number of years in the sample), \\(k\\) columns (the treatments, i.e. either 12 months or 4 quarters, depending on the frequency of the data).\nThe data matrix needs to be replaced by a new matrix \\(\\left\\{r_{ij}\\right\\}_{n \\times k}\\), where the entry \\(r_{ij}\\) is the rank of \\(x_{ij}\\) within block \\(i\\) .\nThe test statistic is given by\n\\[\nQ=\\frac{SS_t}{SS_e}\n\\]\nwhere \\(SS_t=n \\sum_{j=1}^{k}(\\bar{r}_{.j}-\\bar{r})^2\\) and \\(SS_e=\\frac{1}{n(k-1)} \\sum*{i=1}^{n}*\\sum{j=1}^{k}(r_{ij}-^\\bar{r})2\\). It represents the variance of the average ranking across treatments j relative to the total.\nUnder the hypothesis of no seasonality, all months can be equally treated. For the sake of completeness: - \\(\\bar{r}*{.j}\\) is the average ranks of each treatment (month) j within each block (year) - The average rank is given by \\(* \\bar{r}=\\frac{1}{nk}\\sum{i=1}^{n}\\sum*{j=1}^{k}(r*{ij})\\)\nFor large \\(n\\) or \\(k\\) , i.e. \\(n &gt; 15\\) or \\(k &gt; 4\\), the probability distribution of \\(Q\\) can be approximated by that of a chi-squared distribution. Thus, the p-value is given by \\(P( \\chi^2_{k-1}&gt;Q)\\).\n\nUse\nThe test can be applied directly to any series by selecting the option Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests. This is an example of how results are displayed for the case of a monthly series:\n\n\n\nfriedman\n\n\nIf the null hypothesis of no stable seasonality is rejected at the 1% significance level, then the series is considered to be seasonal and the outcome of the test is displayed in green.\nThe test can be applied to the input series before any seasonal adjustment method has been applied. It can also be applied to the seasonally adjusted series or to the irreguar component. In the case of X-13ARIMA-SEATS, the test is applied to the preliminary estimate of the unmodified Seasonal-Irregular component2 (time series shown in Table B3). In this estimate, the number of observations is lower than in the final estimate of the unmodified Seasonal-Irregular component. Thus, the number of degrees of freedom in the stable seasonality test is lower than the number of degrees of freedom in the test for the presence of seasonality assuming stability. For example, X-13ARIMA-SEATS uses a centred moving average of order 12 to calculate the preliminary estimation of trend. Consequently, the first six and last six points in the series are not computed at this stage of calculation. The preliminary estimation of the trend is then used for the calculation of the preliminary estimation of the unmodified Seasonal-Irregular.\n\n\nRelated tests\n\nWhen using this kind of design for a binary response, one instead uses the Cochran’s Q test.\nKendall’s W is a normalization of the Friedman statistic between 0 and 1.\nThe Wilcoxon signed-rank test is a nonparametric test of non-independent data from only two groups.\n\n\n\nReferences\n\nFriedman, Milton (December 1937). “The use of ranks to avoid the assumption of normality implicit in the analysis of variance”. Journal of the American Statistical Association (American Statistical Association) 32 (200): 675–701. doi:10.2307/2279372. JSTOR 2279372.\nFriedman, Milton (March 1939). “A correction: The use of ranks to avoid the assumption of normality implicit in the analysis of variance”. Journal of the American Statistical Association (American Statistical Association) 34 (205): 109. doi:10.2307/2279169. JSTOR\n\n\n\nFriedman, Milton (March 1940). “A comparison of alternative tests of significance for the problem of m rankings”. The Annals of Mathematical Statistics 11 (1): 86–92. doi:10.1214/aoms/1177731944. JSTOR 2235971.\n\n\n\n\nMoving seasonality test\nThe evolutive seasonality test is based on a two-way analysis of variance model. The model uses the values from complete years only. Depending on the decomposition type for the Seasonal – Irregular component it uses Equation 1 (in the case of a multiplicative model) or Equation 2 (in the case of an additive model):\n\\[\n\\left|\\text{SI}_{\\text{ij}} - 1 \\right| = X_{\\text{ij}} = b_{i} + m_{j} + e_{\\text{ij}}\n\\] \n\\[\n\\left| \\text{SI}_{\\text{ij}} \\right| = X_{\\text{ij}} = b_{i} + m_{j} + e_{\\text{ij}}\n\\] \nwhere:\n\n\\(m_{j}\\) – the monthly or quarterly effect for \\(j\\)-th period, \\(j = (1,\\ldots,k)\\), where \\(k = 12\\) for a monthly series and \\(k = 4\\) for a quarterly series;\n\\(b_{j}\\) – the annual effect \\(i\\), \\((i = 1,\\ldots,N)\\) where \\(N\\) is the number of complete years;\n\\(e_{\\text{ij}}\\) – the residual effect.\n\nThe test is based on the following decomposition:\n\\[\nS^{2} = S_{A}^{2} + S_{B}^{2} + S_{R}^{2},\n\\tag{3}\\] \nwhere:\n\n\\(S^{2} = \\sum_{j = 1}^{k}{\\sum_{i = 1}^{N}\\left( {\\overline{X}}_{\\text{ij}} - {\\overline{X}}_{\\bullet \\bullet} \\right)^{2}}\\) –the total sum of squares;\n\\(S_{A}^{2} = N\\sum_{j = 1}^{k}\\left( {\\overline{X}}_{\\bullet j} - {\\overline{X}}_{\\bullet \\bullet} \\right)^{2}\\) – the inter-month (inter-quarter, respectively) sum of squares, which mainly measures the magnitude of the seasonality;\n\\(S_{B}^{2} = k\\sum_{i = 1}^{N}\\left( {\\overline{X}}_{i \\bullet} - {\\overline{X}}_{\\bullet \\bullet} \\right)^{2}\\) – the inter-year sum of squares, which mainly measures the year-to-year movement of seasonality;\n\\(S_{R}^{2} = \\sum_{i = 1}^{N}{\\sum_{j = 1}^{k}\\left( {\\overline{X}}_{\\text{ij}} - {\\overline{X}}_{i \\bullet} - {\\overline{X}}_{\\bullet j} - {\\overline{X}}_{\\bullet \\bullet} \\right)^{2}}\\) – the residual sum of squares.\n\nThe null hypothesis \\(H_{0}\\) is that \\(b_{1} = b_{2} = ... = b_{N}\\) which means that there is no change in seasonality over the years. This hypothesis is verified by the following test statistic:\n\\[\nF_{M} = \\frac{\\frac{S_{B}^{2}}{(n - 1)}}{\\frac{S_{R}^{2}}{(n - 1)(k - 1)}}\n\\]\nwhich follows an \\(F\\)-distribution with \\(k - 1\\) and \\(n - k\\) degrees of freedom.\n\n\nCombined seasonality test\nThis test combines the Kruskal-Wallis test along with test for the presence of seasonality assuming stability (\\(F_{S}\\)), and evaluative seasonality test for detecting the presence of identifiable seasonality (\\(F_{M}\\)). Those three tests are calculated using the final unmodified SI component. The main purpose of the combined seasonality test is to check whether the seasonality of the series is identifiable. For example, the identification of the seasonal pattern is problematic if the process is dominated by highly moving seasonality3. The testing procedure is shown in the figure below.\n\n\n\nCombined seasonality test, source: LADIRAY, D., QUENNEVILLE, B. (2001)"
  },
  {
    "objectID": "M-tests.html#footnotes",
    "href": "M-tests.html#footnotes",
    "title": "Tests",
    "section": "",
    "text": "The description of the test derives from DOORNIK, J.A., and HANSEN, H. (2008).↩︎\nThe unmodified Seasonal-Irregular component corresponds to the Seasonal-Irregular factors with the extreme values.↩︎\nDAGUM, E.B. (1987).↩︎"
  },
  {
    "objectID": "M-state-space-framework.html",
    "href": "M-state-space-framework.html",
    "title": "State space modelling",
    "section": "",
    "text": "Under construction."
  },
  {
    "objectID": "M-Temp-Disagg-Bench.html#benchmarking-underlying-theory",
    "href": "M-Temp-Disagg-Bench.html#benchmarking-underlying-theory",
    "title": "Temporal disaggregation and benchmarking",
    "section": "Benchmarking Underlying Theory",
    "text": "Benchmarking Underlying Theory\nBenchmarking1 is a procedure widely used when for the same target variable the two or more sources of data with different frequency are available. Generally, the two sources of data rarely agree, as an aggregate of higher-frequency measurements is not necessarily equal to the less-aggregated measurement. Moreover, the sources of data may have different reliability. Usually it is thought that less frequent data are more trustworthy as they are based on larger samples and compiled more precisely. The more reliable measurement is considered as a benchmark.\nBenchmarking also occurs in the context of seasonal adjustment. Seasonal adjustment causes discrepancies between the annual totals of the seasonally unadjusted (raw) and the corresponding annual totals of the seasonally adjusted series. Therefore, seasonally adjusted series are benchmarked to the annual totals of the raw time series2. Therefore, in such a case benchmarking means the procedure that ensures the consistency over the year between adjusted and non-seasonally adjusted data. It should be noted that the ‘ESS Guidelines on Seasonal Adjustment’ (2015) do not recommend benchmarking as it introduces a bias in the seasonally adjusted data. Also the U.S. Census Bureau points out that: Forcing the seasonal adjustment totals to be the same as the original series annual totals can degrade the quality of the seasonal adjustment, especially when the seasonal pattern is undergoing change. It is not natural if trading day adjustment is performed because the aggregate trading day effect over a year is variable and moderately different from zero.3 Nevertheless, some users may prefer the annual totals for the seasonally adjusted series to match the annual totals for the original, non-seasonally adjusted series4. According to the ‘ESS Guidelines on Seasonal Adjustment’ (2015), the only benefit of this approach is that there is consistency over the year between adjusted and non-seasonally adjusted data; this can be of particular interest when low-frequency (e.g. annual) benchmarking figures officially exist (e.g. National Accounts, Balance of Payments, External Trade, etc.) where user needs for time consistency are stronger.\nThe benchmarking procedure in JDemetra+ is available for a single seasonally adjusted series and for an indirect seasonal adjustment of an aggregated series. In the first case, univariate benchmarking ensures consistency between the raw and seasonally adjusted series. In the second case, the multivariate benchmarking aims for consistency between the seasonally adjusted aggregate and its seasonally adjusted components.\nGiven a set of initial time series \\[\\left\\{ z_{i,t} \\right\\}_{i \\in I}\\], the aim of the benchmarking procedure is to find the corresponding \\[\\left\\{ x_{i,t} \\right\\}_{i \\in I}\\] that respect temporal aggregation constraints, represented by \\[X_{i,T} = \\sum_{t \\in T}^{}x_{i,t}\\] and contemporaneous constraints given by \\[q_{k,t} = \\sum_{j \\in J_{k}}^{}{w_{\\text{kj}}x_{j,t}}\\] or, in matrix form: \\[q_{k,t} = w_{k}x_{t}\\].\nThe underlying benchmarking method implemented in JDemetra+ is an extension of Cholette’s5 method, which generalises, amongst others, the additive and the multiplicative Denton procedure as well as simple proportional benchmarking.\nThe JDemetra+ solution uses the following routines that are described in DURBIN, J., and KOOPMAN, S.J. (2001):\n\nThe multivariate model is handled through its univariate transformation,\nThe smoothed states are computed by means of the disturbance smoother.\n\nThe performance of the resulting algorithm is highly dependent on the number of variables involved in the model (\\(\\propto \\ n^{3}\\)). The other components of the problem (number of constraints, frequency of the series, and length of the series) are much less important (\\(\\propto \\ n\\)).\nFrom a theoretical point of view, it should be noted that this approach may handle any set of linear restrictions (equalities), endogenous (between variables) or exogenous (related to external values), provided that they don’t contain incompatible equations. The restrictions can also be relaxed for any period by considering their “observation” as missing. However, in practice, it appears that several kinds of contemporaneous constraints yield unstable results. This is more especially true for constraints that contain differences (which is the case for non-binding constraints). The use of a special square root initializer improves in a significant way the stability of the algorithm."
  },
  {
    "objectID": "M-Temp-Disagg-Bench.html#footnotes",
    "href": "M-Temp-Disagg-Bench.html#footnotes",
    "title": "Temporal disaggregation and benchmarking",
    "section": "",
    "text": "Description of the idea of benchmarking is based on DAGUM, B.E., and CHOLETTE, P.A. (1994) and QUENNEVILLE, B. et all (2003). Detailed information can be found in: DAGUM, B.E., and CHOLETTE, P.A. (2006).↩︎\nDAGUM, B.E., and CHOLETTE, P.A. (2006).↩︎\n’X-12-ARIMA Reference Manual’ (2011).↩︎\nHOOD, C.C.H. (2005).↩︎\nCHOLETTE, P.A. (1979).↩︎"
  }
]